{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.5000, 14.0000, 15.0000, 28.0000, 11.0000,  8.0000,  3.0000, -4.0000,\n",
       "          6.0000, 13.0000, 21.0000]),\n",
       " tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "         48.4000, 60.4000, 68.4000]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u =  [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "t_c, t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_c, t_pred_u):\n",
    "    sd = (t_c - t_pred_u) ** 2\n",
    "    return sd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "         48.4000, 60.4000, 68.4000]),\n",
       " tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "         48.4000, 60.4000, 68.4000]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones(())\n",
    "b = torch.zeros(())\n",
    "\n",
    "t_p = model(t_u, w, b)\n",
    "t_p, t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1763.8848)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(t_c, t_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: x: torch.Size([]), y: torch.Size([3, 1])\n",
      "z: torch.Size([1, 3]), a: torch.Size([2, 1, 1])\n",
      "x * y: torch.Size([3, 1])\n",
      "y * z: torch.Size([3, 3])\n",
      "y * z * a: torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(())\n",
    "y = torch.ones(3,1)\n",
    "z = torch.ones(1,3)\n",
    "\n",
    "a = torch.ones(2, 1, 1)\n",
    "print(f\"shapes: x: {x.shape}, y: {y.shape}\")\n",
    "print(f\"z: {z.shape}, a: {a.shape}\")\n",
    "\n",
    "print(\"x * y:\", (x * y).shape)\n",
    "print(\"y * z:\", (y * z).shape)\n",
    "print(\"y * z * a:\", (y * z * a).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1,\n",
       " 0.0001,\n",
       " tensor(-989.5288),\n",
       " tensor(1.0990),\n",
       " tensor(-80.5225),\n",
       " tensor(0.0081))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = 0.1\n",
    "learning_rate = 1e-4\n",
    "\n",
    "loss_rate_of_change_w = (loss_fn(model(t_u, w + delta, b), t_c) - loss_fn(model(t_u, w - delta, b), t_c)) / (2.0 * delta)\n",
    "loss_rate_of_change_w\n",
    "\n",
    "w = w - learning_rate * loss_rate_of_change_w\n",
    "\n",
    "\n",
    "loss_rate_of_change_b = (loss_fn(model(t_u, w, b + delta), t_c) - loss_fn(model(t_u, w, b - delta), t_c)) / (2.0 * delta)\n",
    "loss_rate_of_change_b\n",
    "\n",
    "b = b - learning_rate * loss_rate_of_change_b\n",
    "\n",
    "delta, learning_rate, loss_rate_of_change_w, w, loss_rate_of_change_b, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 80.364342, Params tensor([1.0008e+00, 1.0640e-04])\n",
      "Epoch 2, Loss 80.302986, Params tensor([1.0016e+00, 2.1272e-04])\n",
      "Epoch 3, Loss 80.241707, Params tensor([1.0023e+00, 3.1895e-04])\n",
      "Epoch 4, Loss 80.180511, Params tensor([1.0031e+00, 4.2510e-04])\n",
      "Epoch 5, Loss 80.119377, Params tensor([1.0039e+00, 5.3118e-04])\n",
      "Epoch 6, Loss 80.058304, Params tensor([1.0046e+00, 6.3716e-04])\n",
      "Epoch 7, Loss 79.997330, Params tensor([1.0054e+00, 7.4307e-04])\n",
      "Epoch 8, Loss 79.936432, Params tensor([1.0062e+00, 8.4889e-04])\n",
      "Epoch 9, Loss 79.875603, Params tensor([1.0070e+00, 9.5463e-04])\n",
      "Epoch 10, Loss 79.814835, Params tensor([1.0077, 0.0011])\n",
      "Epoch 11, Loss 79.754143, Params tensor([1.0085, 0.0012])\n",
      "Epoch 12, Loss 79.693520, Params tensor([1.0093, 0.0013])\n",
      "Epoch 13, Loss 79.632988, Params tensor([1.0101, 0.0014])\n",
      "Epoch 14, Loss 79.572517, Params tensor([1.0108, 0.0015])\n",
      "Epoch 15, Loss 79.512115, Params tensor([1.0116, 0.0016])\n",
      "Epoch 16, Loss 79.451805, Params tensor([1.0124, 0.0017])\n",
      "Epoch 17, Loss 79.391556, Params tensor([1.0131, 0.0018])\n",
      "Epoch 18, Loss 79.331383, Params tensor([1.0139, 0.0019])\n",
      "Epoch 19, Loss 79.271294, Params tensor([1.0147, 0.0020])\n",
      "Epoch 20, Loss 79.211250, Params tensor([1.0154, 0.0021])\n",
      "Epoch 21, Loss 79.151299, Params tensor([1.0162, 0.0022])\n",
      "Epoch 22, Loss 79.091408, Params tensor([1.0170, 0.0023])\n",
      "Epoch 23, Loss 79.031586, Params tensor([1.0177, 0.0024])\n",
      "Epoch 24, Loss 78.971848, Params tensor([1.0185, 0.0025])\n",
      "Epoch 25, Loss 78.912178, Params tensor([1.0193, 0.0026])\n",
      "Epoch 26, Loss 78.852592, Params tensor([1.0200, 0.0027])\n",
      "Epoch 27, Loss 78.793068, Params tensor([1.0208, 0.0028])\n",
      "Epoch 28, Loss 78.733612, Params tensor([1.0216, 0.0029])\n",
      "Epoch 29, Loss 78.674225, Params tensor([1.0223, 0.0031])\n",
      "Epoch 30, Loss 78.614922, Params tensor([1.0231, 0.0032])\n",
      "Epoch 31, Loss 78.555695, Params tensor([1.0238, 0.0033])\n",
      "Epoch 32, Loss 78.496536, Params tensor([1.0246, 0.0034])\n",
      "Epoch 33, Loss 78.437431, Params tensor([1.0254, 0.0035])\n",
      "Epoch 34, Loss 78.378426, Params tensor([1.0261, 0.0036])\n",
      "Epoch 35, Loss 78.319473, Params tensor([1.0269, 0.0037])\n",
      "Epoch 36, Loss 78.260590, Params tensor([1.0276, 0.0038])\n",
      "Epoch 37, Loss 78.201790, Params tensor([1.0284, 0.0039])\n",
      "Epoch 38, Loss 78.143059, Params tensor([1.0292, 0.0040])\n",
      "Epoch 39, Loss 78.084396, Params tensor([1.0299, 0.0041])\n",
      "Epoch 40, Loss 78.025795, Params tensor([1.0307, 0.0042])\n",
      "Epoch 41, Loss 77.967278, Params tensor([1.0314, 0.0043])\n",
      "Epoch 42, Loss 77.908821, Params tensor([1.0322, 0.0044])\n",
      "Epoch 43, Loss 77.850441, Params tensor([1.0330, 0.0045])\n",
      "Epoch 44, Loss 77.792130, Params tensor([1.0337, 0.0046])\n",
      "Epoch 45, Loss 77.733894, Params tensor([1.0345, 0.0047])\n",
      "Epoch 46, Loss 77.675728, Params tensor([1.0352, 0.0048])\n",
      "Epoch 47, Loss 77.617630, Params tensor([1.0360, 0.0049])\n",
      "Epoch 48, Loss 77.559601, Params tensor([1.0367, 0.0050])\n",
      "Epoch 49, Loss 77.501648, Params tensor([1.0375, 0.0051])\n",
      "Epoch 50, Loss 77.443756, Params tensor([1.0382, 0.0052])\n",
      "Epoch 51, Loss 77.385941, Params tensor([1.0390, 0.0053])\n",
      "Epoch 52, Loss 77.328194, Params tensor([1.0397, 0.0054])\n",
      "Epoch 53, Loss 77.270515, Params tensor([1.0405, 0.0055])\n",
      "Epoch 54, Loss 77.212898, Params tensor([1.0412, 0.0056])\n",
      "Epoch 55, Loss 77.155365, Params tensor([1.0420, 0.0057])\n",
      "Epoch 56, Loss 77.097900, Params tensor([1.0428, 0.0058])\n",
      "Epoch 57, Loss 77.040504, Params tensor([1.0435, 0.0059])\n",
      "Epoch 58, Loss 76.983170, Params tensor([1.0443, 0.0060])\n",
      "Epoch 59, Loss 76.925911, Params tensor([1.0450, 0.0061])\n",
      "Epoch 60, Loss 76.868721, Params tensor([1.0458, 0.0062])\n",
      "Epoch 61, Loss 76.811607, Params tensor([1.0465, 0.0063])\n",
      "Epoch 62, Loss 76.754547, Params tensor([1.0472, 0.0064])\n",
      "Epoch 63, Loss 76.697563, Params tensor([1.0480, 0.0065])\n",
      "Epoch 64, Loss 76.640648, Params tensor([1.0487, 0.0066])\n",
      "Epoch 65, Loss 76.583809, Params tensor([1.0495, 0.0067])\n",
      "Epoch 66, Loss 76.527039, Params tensor([1.0502, 0.0068])\n",
      "Epoch 67, Loss 76.470329, Params tensor([1.0510, 0.0069])\n",
      "Epoch 68, Loss 76.413689, Params tensor([1.0517, 0.0070])\n",
      "Epoch 69, Loss 76.357117, Params tensor([1.0525, 0.0072])\n",
      "Epoch 70, Loss 76.300629, Params tensor([1.0532, 0.0073])\n",
      "Epoch 71, Loss 76.244179, Params tensor([1.0540, 0.0074])\n",
      "Epoch 72, Loss 76.187813, Params tensor([1.0547, 0.0075])\n",
      "Epoch 73, Loss 76.131523, Params tensor([1.0554, 0.0076])\n",
      "Epoch 74, Loss 76.075302, Params tensor([1.0562, 0.0077])\n",
      "Epoch 75, Loss 76.019135, Params tensor([1.0569, 0.0078])\n",
      "Epoch 76, Loss 75.963036, Params tensor([1.0577, 0.0079])\n",
      "Epoch 77, Loss 75.907021, Params tensor([1.0584, 0.0080])\n",
      "Epoch 78, Loss 75.851067, Params tensor([1.0592, 0.0081])\n",
      "Epoch 79, Loss 75.795181, Params tensor([1.0599, 0.0082])\n",
      "Epoch 80, Loss 75.739349, Params tensor([1.0606, 0.0083])\n",
      "Epoch 81, Loss 75.683594, Params tensor([1.0614, 0.0084])\n",
      "Epoch 82, Loss 75.627922, Params tensor([1.0621, 0.0085])\n",
      "Epoch 83, Loss 75.572296, Params tensor([1.0629, 0.0086])\n",
      "Epoch 84, Loss 75.516739, Params tensor([1.0636, 0.0087])\n",
      "Epoch 85, Loss 75.461250, Params tensor([1.0643, 0.0088])\n",
      "Epoch 86, Loss 75.405838, Params tensor([1.0651, 0.0089])\n",
      "Epoch 87, Loss 75.350502, Params tensor([1.0658, 0.0090])\n",
      "Epoch 88, Loss 75.295219, Params tensor([1.0665, 0.0091])\n",
      "Epoch 89, Loss 75.239998, Params tensor([1.0673, 0.0092])\n",
      "Epoch 90, Loss 75.184845, Params tensor([1.0680, 0.0093])\n",
      "Epoch 91, Loss 75.129768, Params tensor([1.0687, 0.0094])\n",
      "Epoch 92, Loss 75.074745, Params tensor([1.0695, 0.0094])\n",
      "Epoch 93, Loss 75.019791, Params tensor([1.0702, 0.0095])\n",
      "Epoch 94, Loss 74.964912, Params tensor([1.0710, 0.0096])\n",
      "Epoch 95, Loss 74.910103, Params tensor([1.0717, 0.0097])\n",
      "Epoch 96, Loss 74.855347, Params tensor([1.0724, 0.0098])\n",
      "Epoch 97, Loss 74.800667, Params tensor([1.0732, 0.0099])\n",
      "Epoch 98, Loss 74.746040, Params tensor([1.0739, 0.0100])\n",
      "Epoch 99, Loss 74.691498, Params tensor([1.0746, 0.0101])\n",
      "Epoch 100, Loss 74.637016, Params tensor([1.0753, 0.0102])\n",
      "Epoch 101, Loss 74.582588, Params tensor([1.0761, 0.0103])\n",
      "Epoch 102, Loss 74.528244, Params tensor([1.0768, 0.0104])\n",
      "Epoch 103, Loss 74.473946, Params tensor([1.0775, 0.0105])\n",
      "Epoch 104, Loss 74.419731, Params tensor([1.0783, 0.0106])\n",
      "Epoch 105, Loss 74.365570, Params tensor([1.0790, 0.0107])\n",
      "Epoch 106, Loss 74.311485, Params tensor([1.0797, 0.0108])\n",
      "Epoch 107, Loss 74.257462, Params tensor([1.0805, 0.0109])\n",
      "Epoch 108, Loss 74.203499, Params tensor([1.0812, 0.0110])\n",
      "Epoch 109, Loss 74.149612, Params tensor([1.0819, 0.0111])\n",
      "Epoch 110, Loss 74.095787, Params tensor([1.0826, 0.0112])\n",
      "Epoch 111, Loss 74.042023, Params tensor([1.0834, 0.0113])\n",
      "Epoch 112, Loss 73.988319, Params tensor([1.0841, 0.0114])\n",
      "Epoch 113, Loss 73.934692, Params tensor([1.0848, 0.0115])\n",
      "Epoch 114, Loss 73.881104, Params tensor([1.0855, 0.0116])\n",
      "Epoch 115, Loss 73.827606, Params tensor([1.0863, 0.0117])\n",
      "Epoch 116, Loss 73.774162, Params tensor([1.0870, 0.0118])\n",
      "Epoch 117, Loss 73.720779, Params tensor([1.0877, 0.0119])\n",
      "Epoch 118, Loss 73.667488, Params tensor([1.0884, 0.0120])\n",
      "Epoch 119, Loss 73.614243, Params tensor([1.0892, 0.0121])\n",
      "Epoch 120, Loss 73.561066, Params tensor([1.0899, 0.0122])\n",
      "Epoch 121, Loss 73.507942, Params tensor([1.0906, 0.0123])\n",
      "Epoch 122, Loss 73.454880, Params tensor([1.0913, 0.0124])\n",
      "Epoch 123, Loss 73.401901, Params tensor([1.0920, 0.0125])\n",
      "Epoch 124, Loss 73.348984, Params tensor([1.0928, 0.0126])\n",
      "Epoch 125, Loss 73.296120, Params tensor([1.0935, 0.0127])\n",
      "Epoch 126, Loss 73.243317, Params tensor([1.0942, 0.0128])\n",
      "Epoch 127, Loss 73.190598, Params tensor([1.0949, 0.0129])\n",
      "Epoch 128, Loss 73.137932, Params tensor([1.0956, 0.0130])\n",
      "Epoch 129, Loss 73.085320, Params tensor([1.0964, 0.0131])\n",
      "Epoch 130, Loss 73.032768, Params tensor([1.0971, 0.0132])\n",
      "Epoch 131, Loss 72.980293, Params tensor([1.0978, 0.0133])\n",
      "Epoch 132, Loss 72.927887, Params tensor([1.0985, 0.0133])\n",
      "Epoch 133, Loss 72.875542, Params tensor([1.0992, 0.0134])\n",
      "Epoch 134, Loss 72.823250, Params tensor([1.0999, 0.0135])\n",
      "Epoch 135, Loss 72.771027, Params tensor([1.1007, 0.0136])\n",
      "Epoch 136, Loss 72.718872, Params tensor([1.1014, 0.0137])\n",
      "Epoch 137, Loss 72.666779, Params tensor([1.1021, 0.0138])\n",
      "Epoch 138, Loss 72.614731, Params tensor([1.1028, 0.0139])\n",
      "Epoch 139, Loss 72.562767, Params tensor([1.1035, 0.0140])\n",
      "Epoch 140, Loss 72.510857, Params tensor([1.1042, 0.0141])\n",
      "Epoch 141, Loss 72.459015, Params tensor([1.1049, 0.0142])\n",
      "Epoch 142, Loss 72.407234, Params tensor([1.1057, 0.0143])\n",
      "Epoch 143, Loss 72.355515, Params tensor([1.1064, 0.0144])\n",
      "Epoch 144, Loss 72.303864, Params tensor([1.1071, 0.0145])\n",
      "Epoch 145, Loss 72.252258, Params tensor([1.1078, 0.0146])\n",
      "Epoch 146, Loss 72.200729, Params tensor([1.1085, 0.0147])\n",
      "Epoch 147, Loss 72.149261, Params tensor([1.1092, 0.0148])\n",
      "Epoch 148, Loss 72.097847, Params tensor([1.1099, 0.0149])\n",
      "Epoch 149, Loss 72.046501, Params tensor([1.1106, 0.0150])\n",
      "Epoch 150, Loss 71.995216, Params tensor([1.1113, 0.0151])\n",
      "Epoch 151, Loss 71.944000, Params tensor([1.1121, 0.0152])\n",
      "Epoch 152, Loss 71.892845, Params tensor([1.1128, 0.0153])\n",
      "Epoch 153, Loss 71.841743, Params tensor([1.1135, 0.0153])\n",
      "Epoch 154, Loss 71.790718, Params tensor([1.1142, 0.0154])\n",
      "Epoch 155, Loss 71.739723, Params tensor([1.1149, 0.0155])\n",
      "Epoch 156, Loss 71.688812, Params tensor([1.1156, 0.0156])\n",
      "Epoch 157, Loss 71.637970, Params tensor([1.1163, 0.0157])\n",
      "Epoch 158, Loss 71.587189, Params tensor([1.1170, 0.0158])\n",
      "Epoch 159, Loss 71.536446, Params tensor([1.1177, 0.0159])\n",
      "Epoch 160, Loss 71.485779, Params tensor([1.1184, 0.0160])\n",
      "Epoch 161, Loss 71.435173, Params tensor([1.1191, 0.0161])\n",
      "Epoch 162, Loss 71.384636, Params tensor([1.1198, 0.0162])\n",
      "Epoch 163, Loss 71.334160, Params tensor([1.1205, 0.0163])\n",
      "Epoch 164, Loss 71.283722, Params tensor([1.1212, 0.0164])\n",
      "Epoch 165, Loss 71.233368, Params tensor([1.1219, 0.0165])\n",
      "Epoch 166, Loss 71.183075, Params tensor([1.1226, 0.0166])\n",
      "Epoch 167, Loss 71.132835, Params tensor([1.1233, 0.0167])\n",
      "Epoch 168, Loss 71.082664, Params tensor([1.1240, 0.0168])\n",
      "Epoch 169, Loss 71.032539, Params tensor([1.1247, 0.0168])\n",
      "Epoch 170, Loss 70.982491, Params tensor([1.1255, 0.0169])\n",
      "Epoch 171, Loss 70.932487, Params tensor([1.1262, 0.0170])\n",
      "Epoch 172, Loss 70.882561, Params tensor([1.1269, 0.0171])\n",
      "Epoch 173, Loss 70.832672, Params tensor([1.1276, 0.0172])\n",
      "Epoch 174, Loss 70.782867, Params tensor([1.1283, 0.0173])\n",
      "Epoch 175, Loss 70.733109, Params tensor([1.1289, 0.0174])\n",
      "Epoch 176, Loss 70.683411, Params tensor([1.1296, 0.0175])\n",
      "Epoch 177, Loss 70.633781, Params tensor([1.1303, 0.0176])\n",
      "Epoch 178, Loss 70.584213, Params tensor([1.1310, 0.0177])\n",
      "Epoch 179, Loss 70.534698, Params tensor([1.1317, 0.0178])\n",
      "Epoch 180, Loss 70.485245, Params tensor([1.1324, 0.0179])\n",
      "Epoch 181, Loss 70.435844, Params tensor([1.1331, 0.0180])\n",
      "Epoch 182, Loss 70.386520, Params tensor([1.1338, 0.0181])\n",
      "Epoch 183, Loss 70.337242, Params tensor([1.1345, 0.0181])\n",
      "Epoch 184, Loss 70.288033, Params tensor([1.1352, 0.0182])\n",
      "Epoch 185, Loss 70.238876, Params tensor([1.1359, 0.0183])\n",
      "Epoch 186, Loss 70.189789, Params tensor([1.1366, 0.0184])\n",
      "Epoch 187, Loss 70.140747, Params tensor([1.1373, 0.0185])\n",
      "Epoch 188, Loss 70.091766, Params tensor([1.1380, 0.0186])\n",
      "Epoch 189, Loss 70.042847, Params tensor([1.1387, 0.0187])\n",
      "Epoch 190, Loss 69.993996, Params tensor([1.1394, 0.0188])\n",
      "Epoch 191, Loss 69.945183, Params tensor([1.1401, 0.0189])\n",
      "Epoch 192, Loss 69.896454, Params tensor([1.1408, 0.0190])\n",
      "Epoch 193, Loss 69.847771, Params tensor([1.1415, 0.0191])\n",
      "Epoch 194, Loss 69.799141, Params tensor([1.1421, 0.0192])\n",
      "Epoch 195, Loss 69.750580, Params tensor([1.1428, 0.0192])\n",
      "Epoch 196, Loss 69.702072, Params tensor([1.1435, 0.0193])\n",
      "Epoch 197, Loss 69.653625, Params tensor([1.1442, 0.0194])\n",
      "Epoch 198, Loss 69.605240, Params tensor([1.1449, 0.0195])\n",
      "Epoch 199, Loss 69.556915, Params tensor([1.1456, 0.0196])\n",
      "Epoch 200, Loss 69.508659, Params tensor([1.1463, 0.0197])\n",
      "Epoch 201, Loss 69.460442, Params tensor([1.1470, 0.0198])\n",
      "Epoch 202, Loss 69.412285, Params tensor([1.1477, 0.0199])\n",
      "Epoch 203, Loss 69.364189, Params tensor([1.1483, 0.0200])\n",
      "Epoch 204, Loss 69.316147, Params tensor([1.1490, 0.0201])\n",
      "Epoch 205, Loss 69.268181, Params tensor([1.1497, 0.0202])\n",
      "Epoch 206, Loss 69.220261, Params tensor([1.1504, 0.0202])\n",
      "Epoch 207, Loss 69.172386, Params tensor([1.1511, 0.0203])\n",
      "Epoch 208, Loss 69.124588, Params tensor([1.1518, 0.0204])\n",
      "Epoch 209, Loss 69.076843, Params tensor([1.1525, 0.0205])\n",
      "Epoch 210, Loss 69.029144, Params tensor([1.1531, 0.0206])\n",
      "Epoch 211, Loss 68.981514, Params tensor([1.1538, 0.0207])\n",
      "Epoch 212, Loss 68.933937, Params tensor([1.1545, 0.0208])\n",
      "Epoch 213, Loss 68.886421, Params tensor([1.1552, 0.0209])\n",
      "Epoch 214, Loss 68.838966, Params tensor([1.1559, 0.0210])\n",
      "Epoch 215, Loss 68.791573, Params tensor([1.1566, 0.0211])\n",
      "Epoch 216, Loss 68.744232, Params tensor([1.1572, 0.0211])\n",
      "Epoch 217, Loss 68.696945, Params tensor([1.1579, 0.0212])\n",
      "Epoch 218, Loss 68.649712, Params tensor([1.1586, 0.0213])\n",
      "Epoch 219, Loss 68.602539, Params tensor([1.1593, 0.0214])\n",
      "Epoch 220, Loss 68.555412, Params tensor([1.1600, 0.0215])\n",
      "Epoch 221, Loss 68.508354, Params tensor([1.1606, 0.0216])\n",
      "Epoch 222, Loss 68.461357, Params tensor([1.1613, 0.0217])\n",
      "Epoch 223, Loss 68.414413, Params tensor([1.1620, 0.0218])\n",
      "Epoch 224, Loss 68.367523, Params tensor([1.1627, 0.0219])\n",
      "Epoch 225, Loss 68.320702, Params tensor([1.1634, 0.0220])\n",
      "Epoch 226, Loss 68.273926, Params tensor([1.1640, 0.0220])\n",
      "Epoch 227, Loss 68.227203, Params tensor([1.1647, 0.0221])\n",
      "Epoch 228, Loss 68.180534, Params tensor([1.1654, 0.0222])\n",
      "Epoch 229, Loss 68.133934, Params tensor([1.1661, 0.0223])\n",
      "Epoch 230, Loss 68.087395, Params tensor([1.1667, 0.0224])\n",
      "Epoch 231, Loss 68.040909, Params tensor([1.1674, 0.0225])\n",
      "Epoch 232, Loss 67.994461, Params tensor([1.1681, 0.0226])\n",
      "Epoch 233, Loss 67.948090, Params tensor([1.1688, 0.0227])\n",
      "Epoch 234, Loss 67.901756, Params tensor([1.1694, 0.0227])\n",
      "Epoch 235, Loss 67.855492, Params tensor([1.1701, 0.0228])\n",
      "Epoch 236, Loss 67.809288, Params tensor([1.1708, 0.0229])\n",
      "Epoch 237, Loss 67.763123, Params tensor([1.1715, 0.0230])\n",
      "Epoch 238, Loss 67.717033, Params tensor([1.1721, 0.0231])\n",
      "Epoch 239, Loss 67.670975, Params tensor([1.1728, 0.0232])\n",
      "Epoch 240, Loss 67.625000, Params tensor([1.1735, 0.0233])\n",
      "Epoch 241, Loss 67.579056, Params tensor([1.1742, 0.0234])\n",
      "Epoch 242, Loss 67.533173, Params tensor([1.1748, 0.0235])\n",
      "Epoch 243, Loss 67.487358, Params tensor([1.1755, 0.0235])\n",
      "Epoch 244, Loss 67.441597, Params tensor([1.1762, 0.0236])\n",
      "Epoch 245, Loss 67.395882, Params tensor([1.1768, 0.0237])\n",
      "Epoch 246, Loss 67.350243, Params tensor([1.1775, 0.0238])\n",
      "Epoch 247, Loss 67.304626, Params tensor([1.1782, 0.0239])\n",
      "Epoch 248, Loss 67.259087, Params tensor([1.1789, 0.0240])\n",
      "Epoch 249, Loss 67.213593, Params tensor([1.1795, 0.0241])\n",
      "Epoch 250, Loss 67.168167, Params tensor([1.1802, 0.0242])\n",
      "Epoch 251, Loss 67.122787, Params tensor([1.1809, 0.0242])\n",
      "Epoch 252, Loss 67.077461, Params tensor([1.1815, 0.0243])\n",
      "Epoch 253, Loss 67.032196, Params tensor([1.1822, 0.0244])\n",
      "Epoch 254, Loss 66.986984, Params tensor([1.1829, 0.0245])\n",
      "Epoch 255, Loss 66.941826, Params tensor([1.1835, 0.0246])\n",
      "Epoch 256, Loss 66.896721, Params tensor([1.1842, 0.0247])\n",
      "Epoch 257, Loss 66.851662, Params tensor([1.1849, 0.0248])\n",
      "Epoch 258, Loss 66.806656, Params tensor([1.1855, 0.0249])\n",
      "Epoch 259, Loss 66.761726, Params tensor([1.1862, 0.0249])\n",
      "Epoch 260, Loss 66.716843, Params tensor([1.1868, 0.0250])\n",
      "Epoch 261, Loss 66.672005, Params tensor([1.1875, 0.0251])\n",
      "Epoch 262, Loss 66.627220, Params tensor([1.1882, 0.0252])\n",
      "Epoch 263, Loss 66.582497, Params tensor([1.1888, 0.0253])\n",
      "Epoch 264, Loss 66.537834, Params tensor([1.1895, 0.0254])\n",
      "Epoch 265, Loss 66.493217, Params tensor([1.1902, 0.0255])\n",
      "Epoch 266, Loss 66.448654, Params tensor([1.1908, 0.0255])\n",
      "Epoch 267, Loss 66.404144, Params tensor([1.1915, 0.0256])\n",
      "Epoch 268, Loss 66.359688, Params tensor([1.1921, 0.0257])\n",
      "Epoch 269, Loss 66.315285, Params tensor([1.1928, 0.0258])\n",
      "Epoch 270, Loss 66.270950, Params tensor([1.1935, 0.0259])\n",
      "Epoch 271, Loss 66.226654, Params tensor([1.1941, 0.0260])\n",
      "Epoch 272, Loss 66.182411, Params tensor([1.1948, 0.0261])\n",
      "Epoch 273, Loss 66.138222, Params tensor([1.1954, 0.0261])\n",
      "Epoch 274, Loss 66.094086, Params tensor([1.1961, 0.0262])\n",
      "Epoch 275, Loss 66.050018, Params tensor([1.1968, 0.0263])\n",
      "Epoch 276, Loss 66.005981, Params tensor([1.1974, 0.0264])\n",
      "Epoch 277, Loss 65.962013, Params tensor([1.1981, 0.0265])\n",
      "Epoch 278, Loss 65.918098, Params tensor([1.1987, 0.0266])\n",
      "Epoch 279, Loss 65.874229, Params tensor([1.1994, 0.0267])\n",
      "Epoch 280, Loss 65.830414, Params tensor([1.2000, 0.0267])\n",
      "Epoch 281, Loss 65.786652, Params tensor([1.2007, 0.0268])\n",
      "Epoch 282, Loss 65.742950, Params tensor([1.2014, 0.0269])\n",
      "Epoch 283, Loss 65.699287, Params tensor([1.2020, 0.0270])\n",
      "Epoch 284, Loss 65.655693, Params tensor([1.2027, 0.0271])\n",
      "Epoch 285, Loss 65.612137, Params tensor([1.2033, 0.0272])\n",
      "Epoch 286, Loss 65.568634, Params tensor([1.2040, 0.0273])\n",
      "Epoch 287, Loss 65.525192, Params tensor([1.2046, 0.0273])\n",
      "Epoch 288, Loss 65.481804, Params tensor([1.2053, 0.0274])\n",
      "Epoch 289, Loss 65.438469, Params tensor([1.2059, 0.0275])\n",
      "Epoch 290, Loss 65.395180, Params tensor([1.2066, 0.0276])\n",
      "Epoch 291, Loss 65.351952, Params tensor([1.2072, 0.0277])\n",
      "Epoch 292, Loss 65.308762, Params tensor([1.2079, 0.0278])\n",
      "Epoch 293, Loss 65.265633, Params tensor([1.2085, 0.0278])\n",
      "Epoch 294, Loss 65.222565, Params tensor([1.2092, 0.0279])\n",
      "Epoch 295, Loss 65.179527, Params tensor([1.2098, 0.0280])\n",
      "Epoch 296, Loss 65.136566, Params tensor([1.2105, 0.0281])\n",
      "Epoch 297, Loss 65.093643, Params tensor([1.2111, 0.0282])\n",
      "Epoch 298, Loss 65.050766, Params tensor([1.2118, 0.0283])\n",
      "Epoch 299, Loss 65.007965, Params tensor([1.2124, 0.0283])\n",
      "Epoch 300, Loss 64.965179, Params tensor([1.2131, 0.0284])\n",
      "Epoch 301, Loss 64.922478, Params tensor([1.2137, 0.0285])\n",
      "Epoch 302, Loss 64.879799, Params tensor([1.2144, 0.0286])\n",
      "Epoch 303, Loss 64.837212, Params tensor([1.2150, 0.0287])\n",
      "Epoch 304, Loss 64.794647, Params tensor([1.2157, 0.0288])\n",
      "Epoch 305, Loss 64.752136, Params tensor([1.2163, 0.0288])\n",
      "Epoch 306, Loss 64.709686, Params tensor([1.2170, 0.0289])\n",
      "Epoch 307, Loss 64.667274, Params tensor([1.2176, 0.0290])\n",
      "Epoch 308, Loss 64.624924, Params tensor([1.2183, 0.0291])\n",
      "Epoch 309, Loss 64.582626, Params tensor([1.2189, 0.0292])\n",
      "Epoch 310, Loss 64.540367, Params tensor([1.2195, 0.0293])\n",
      "Epoch 311, Loss 64.498161, Params tensor([1.2202, 0.0293])\n",
      "Epoch 312, Loss 64.456024, Params tensor([1.2208, 0.0294])\n",
      "Epoch 313, Loss 64.413925, Params tensor([1.2215, 0.0295])\n",
      "Epoch 314, Loss 64.371880, Params tensor([1.2221, 0.0296])\n",
      "Epoch 315, Loss 64.329887, Params tensor([1.2228, 0.0297])\n",
      "Epoch 316, Loss 64.287933, Params tensor([1.2234, 0.0298])\n",
      "Epoch 317, Loss 64.246048, Params tensor([1.2240, 0.0298])\n",
      "Epoch 318, Loss 64.204193, Params tensor([1.2247, 0.0299])\n",
      "Epoch 319, Loss 64.162407, Params tensor([1.2253, 0.0300])\n",
      "Epoch 320, Loss 64.120674, Params tensor([1.2260, 0.0301])\n",
      "Epoch 321, Loss 64.078972, Params tensor([1.2266, 0.0302])\n",
      "Epoch 322, Loss 64.037323, Params tensor([1.2272, 0.0303])\n",
      "Epoch 323, Loss 63.995754, Params tensor([1.2279, 0.0303])\n",
      "Epoch 324, Loss 63.954197, Params tensor([1.2285, 0.0304])\n",
      "Epoch 325, Loss 63.912708, Params tensor([1.2292, 0.0305])\n",
      "Epoch 326, Loss 63.871273, Params tensor([1.2298, 0.0306])\n",
      "Epoch 327, Loss 63.829880, Params tensor([1.2304, 0.0307])\n",
      "Epoch 328, Loss 63.788540, Params tensor([1.2311, 0.0308])\n",
      "Epoch 329, Loss 63.747253, Params tensor([1.2317, 0.0308])\n",
      "Epoch 330, Loss 63.706009, Params tensor([1.2323, 0.0309])\n",
      "Epoch 331, Loss 63.664822, Params tensor([1.2330, 0.0310])\n",
      "Epoch 332, Loss 63.623684, Params tensor([1.2336, 0.0311])\n",
      "Epoch 333, Loss 63.582584, Params tensor([1.2343, 0.0312])\n",
      "Epoch 334, Loss 63.541553, Params tensor([1.2349, 0.0312])\n",
      "Epoch 335, Loss 63.500561, Params tensor([1.2355, 0.0313])\n",
      "Epoch 336, Loss 63.459610, Params tensor([1.2362, 0.0314])\n",
      "Epoch 337, Loss 63.418736, Params tensor([1.2368, 0.0315])\n",
      "Epoch 338, Loss 63.377892, Params tensor([1.2374, 0.0316])\n",
      "Epoch 339, Loss 63.337097, Params tensor([1.2381, 0.0316])\n",
      "Epoch 340, Loss 63.296341, Params tensor([1.2387, 0.0317])\n",
      "Epoch 341, Loss 63.255650, Params tensor([1.2393, 0.0318])\n",
      "Epoch 342, Loss 63.215015, Params tensor([1.2400, 0.0319])\n",
      "Epoch 343, Loss 63.174416, Params tensor([1.2406, 0.0320])\n",
      "Epoch 344, Loss 63.133873, Params tensor([1.2412, 0.0321])\n",
      "Epoch 345, Loss 63.093372, Params tensor([1.2419, 0.0321])\n",
      "Epoch 346, Loss 63.052921, Params tensor([1.2425, 0.0322])\n",
      "Epoch 347, Loss 63.012516, Params tensor([1.2431, 0.0323])\n",
      "Epoch 348, Loss 62.972168, Params tensor([1.2437, 0.0324])\n",
      "Epoch 349, Loss 62.931862, Params tensor([1.2444, 0.0325])\n",
      "Epoch 350, Loss 62.891613, Params tensor([1.2450, 0.0325])\n",
      "Epoch 351, Loss 62.851418, Params tensor([1.2456, 0.0326])\n",
      "Epoch 352, Loss 62.811253, Params tensor([1.2463, 0.0327])\n",
      "Epoch 353, Loss 62.771152, Params tensor([1.2469, 0.0328])\n",
      "Epoch 354, Loss 62.731091, Params tensor([1.2475, 0.0329])\n",
      "Epoch 355, Loss 62.691090, Params tensor([1.2481, 0.0329])\n",
      "Epoch 356, Loss 62.651119, Params tensor([1.2488, 0.0330])\n",
      "Epoch 357, Loss 62.611210, Params tensor([1.2494, 0.0331])\n",
      "Epoch 358, Loss 62.571335, Params tensor([1.2500, 0.0332])\n",
      "Epoch 359, Loss 62.531521, Params tensor([1.2506, 0.0333])\n",
      "Epoch 360, Loss 62.491764, Params tensor([1.2513, 0.0333])\n",
      "Epoch 361, Loss 62.452030, Params tensor([1.2519, 0.0334])\n",
      "Epoch 362, Loss 62.412365, Params tensor([1.2525, 0.0335])\n",
      "Epoch 363, Loss 62.372738, Params tensor([1.2531, 0.0336])\n",
      "Epoch 364, Loss 62.333164, Params tensor([1.2538, 0.0337])\n",
      "Epoch 365, Loss 62.293629, Params tensor([1.2544, 0.0337])\n",
      "Epoch 366, Loss 62.254150, Params tensor([1.2550, 0.0338])\n",
      "Epoch 367, Loss 62.214722, Params tensor([1.2556, 0.0339])\n",
      "Epoch 368, Loss 62.175331, Params tensor([1.2563, 0.0340])\n",
      "Epoch 369, Loss 62.135990, Params tensor([1.2569, 0.0341])\n",
      "Epoch 370, Loss 62.096695, Params tensor([1.2575, 0.0341])\n",
      "Epoch 371, Loss 62.057457, Params tensor([1.2581, 0.0342])\n",
      "Epoch 372, Loss 62.018253, Params tensor([1.2587, 0.0343])\n",
      "Epoch 373, Loss 61.979111, Params tensor([1.2594, 0.0344])\n",
      "Epoch 374, Loss 61.940006, Params tensor([1.2600, 0.0344])\n",
      "Epoch 375, Loss 61.900963, Params tensor([1.2606, 0.0345])\n",
      "Epoch 376, Loss 61.861961, Params tensor([1.2612, 0.0346])\n",
      "Epoch 377, Loss 61.822987, Params tensor([1.2618, 0.0347])\n",
      "Epoch 378, Loss 61.784084, Params tensor([1.2625, 0.0348])\n",
      "Epoch 379, Loss 61.745213, Params tensor([1.2631, 0.0348])\n",
      "Epoch 380, Loss 61.706387, Params tensor([1.2637, 0.0349])\n",
      "Epoch 381, Loss 61.667625, Params tensor([1.2643, 0.0350])\n",
      "Epoch 382, Loss 61.628902, Params tensor([1.2649, 0.0351])\n",
      "Epoch 383, Loss 61.590225, Params tensor([1.2656, 0.0352])\n",
      "Epoch 384, Loss 61.551601, Params tensor([1.2662, 0.0352])\n",
      "Epoch 385, Loss 61.513004, Params tensor([1.2668, 0.0353])\n",
      "Epoch 386, Loss 61.474476, Params tensor([1.2674, 0.0354])\n",
      "Epoch 387, Loss 61.435986, Params tensor([1.2680, 0.0355])\n",
      "Epoch 388, Loss 61.397545, Params tensor([1.2686, 0.0355])\n",
      "Epoch 389, Loss 61.359131, Params tensor([1.2692, 0.0356])\n",
      "Epoch 390, Loss 61.320797, Params tensor([1.2699, 0.0357])\n",
      "Epoch 391, Loss 61.282497, Params tensor([1.2705, 0.0358])\n",
      "Epoch 392, Loss 61.244228, Params tensor([1.2711, 0.0359])\n",
      "Epoch 393, Loss 61.206020, Params tensor([1.2717, 0.0359])\n",
      "Epoch 394, Loss 61.167870, Params tensor([1.2723, 0.0360])\n",
      "Epoch 395, Loss 61.129738, Params tensor([1.2729, 0.0361])\n",
      "Epoch 396, Loss 61.091663, Params tensor([1.2735, 0.0362])\n",
      "Epoch 397, Loss 61.053638, Params tensor([1.2741, 0.0362])\n",
      "Epoch 398, Loss 61.015659, Params tensor([1.2748, 0.0363])\n",
      "Epoch 399, Loss 60.977711, Params tensor([1.2754, 0.0364])\n",
      "Epoch 400, Loss 60.939823, Params tensor([1.2760, 0.0365])\n",
      "Epoch 401, Loss 60.901974, Params tensor([1.2766, 0.0366])\n",
      "Epoch 402, Loss 60.864193, Params tensor([1.2772, 0.0366])\n",
      "Epoch 403, Loss 60.826439, Params tensor([1.2778, 0.0367])\n",
      "Epoch 404, Loss 60.788731, Params tensor([1.2784, 0.0368])\n",
      "Epoch 405, Loss 60.751072, Params tensor([1.2790, 0.0369])\n",
      "Epoch 406, Loss 60.713463, Params tensor([1.2796, 0.0369])\n",
      "Epoch 407, Loss 60.675892, Params tensor([1.2802, 0.0370])\n",
      "Epoch 408, Loss 60.638367, Params tensor([1.2808, 0.0371])\n",
      "Epoch 409, Loss 60.600891, Params tensor([1.2815, 0.0372])\n",
      "Epoch 410, Loss 60.563450, Params tensor([1.2821, 0.0372])\n",
      "Epoch 411, Loss 60.526051, Params tensor([1.2827, 0.0373])\n",
      "Epoch 412, Loss 60.488720, Params tensor([1.2833, 0.0374])\n",
      "Epoch 413, Loss 60.451405, Params tensor([1.2839, 0.0375])\n",
      "Epoch 414, Loss 60.414162, Params tensor([1.2845, 0.0375])\n",
      "Epoch 415, Loss 60.376942, Params tensor([1.2851, 0.0376])\n",
      "Epoch 416, Loss 60.339783, Params tensor([1.2857, 0.0377])\n",
      "Epoch 417, Loss 60.302662, Params tensor([1.2863, 0.0378])\n",
      "Epoch 418, Loss 60.265591, Params tensor([1.2869, 0.0379])\n",
      "Epoch 419, Loss 60.228573, Params tensor([1.2875, 0.0379])\n",
      "Epoch 420, Loss 60.191601, Params tensor([1.2881, 0.0380])\n",
      "Epoch 421, Loss 60.154652, Params tensor([1.2887, 0.0381])\n",
      "Epoch 422, Loss 60.117760, Params tensor([1.2893, 0.0382])\n",
      "Epoch 423, Loss 60.080917, Params tensor([1.2899, 0.0382])\n",
      "Epoch 424, Loss 60.044106, Params tensor([1.2905, 0.0383])\n",
      "Epoch 425, Loss 60.007351, Params tensor([1.2911, 0.0384])\n",
      "Epoch 426, Loss 59.970627, Params tensor([1.2917, 0.0385])\n",
      "Epoch 427, Loss 59.933956, Params tensor([1.2923, 0.0385])\n",
      "Epoch 428, Loss 59.897327, Params tensor([1.2929, 0.0386])\n",
      "Epoch 429, Loss 59.860752, Params tensor([1.2935, 0.0387])\n",
      "Epoch 430, Loss 59.824219, Params tensor([1.2941, 0.0388])\n",
      "Epoch 431, Loss 59.787724, Params tensor([1.2947, 0.0388])\n",
      "Epoch 432, Loss 59.751266, Params tensor([1.2953, 0.0389])\n",
      "Epoch 433, Loss 59.714867, Params tensor([1.2959, 0.0390])\n",
      "Epoch 434, Loss 59.678493, Params tensor([1.2965, 0.0391])\n",
      "Epoch 435, Loss 59.642185, Params tensor([1.2971, 0.0391])\n",
      "Epoch 436, Loss 59.605900, Params tensor([1.2977, 0.0392])\n",
      "Epoch 437, Loss 59.569679, Params tensor([1.2983, 0.0393])\n",
      "Epoch 438, Loss 59.533482, Params tensor([1.2989, 0.0394])\n",
      "Epoch 439, Loss 59.497341, Params tensor([1.2995, 0.0394])\n",
      "Epoch 440, Loss 59.461243, Params tensor([1.3001, 0.0395])\n",
      "Epoch 441, Loss 59.425182, Params tensor([1.3007, 0.0396])\n",
      "Epoch 442, Loss 59.389172, Params tensor([1.3013, 0.0397])\n",
      "Epoch 443, Loss 59.353207, Params tensor([1.3019, 0.0397])\n",
      "Epoch 444, Loss 59.317276, Params tensor([1.3025, 0.0398])\n",
      "Epoch 445, Loss 59.281387, Params tensor([1.3031, 0.0399])\n",
      "Epoch 446, Loss 59.245544, Params tensor([1.3037, 0.0400])\n",
      "Epoch 447, Loss 59.209763, Params tensor([1.3043, 0.0400])\n",
      "Epoch 448, Loss 59.174007, Params tensor([1.3048, 0.0401])\n",
      "Epoch 449, Loss 59.138294, Params tensor([1.3054, 0.0402])\n",
      "Epoch 450, Loss 59.102638, Params tensor([1.3060, 0.0402])\n",
      "Epoch 451, Loss 59.067017, Params tensor([1.3066, 0.0403])\n",
      "Epoch 452, Loss 59.031429, Params tensor([1.3072, 0.0404])\n",
      "Epoch 453, Loss 58.995884, Params tensor([1.3078, 0.0405])\n",
      "Epoch 454, Loss 58.960403, Params tensor([1.3084, 0.0405])\n",
      "Epoch 455, Loss 58.924953, Params tensor([1.3090, 0.0406])\n",
      "Epoch 456, Loss 58.889542, Params tensor([1.3096, 0.0407])\n",
      "Epoch 457, Loss 58.854172, Params tensor([1.3102, 0.0408])\n",
      "Epoch 458, Loss 58.818851, Params tensor([1.3108, 0.0408])\n",
      "Epoch 459, Loss 58.783573, Params tensor([1.3113, 0.0409])\n",
      "Epoch 460, Loss 58.748337, Params tensor([1.3119, 0.0410])\n",
      "Epoch 461, Loss 58.713146, Params tensor([1.3125, 0.0411])\n",
      "Epoch 462, Loss 58.677994, Params tensor([1.3131, 0.0411])\n",
      "Epoch 463, Loss 58.642895, Params tensor([1.3137, 0.0412])\n",
      "Epoch 464, Loss 58.607822, Params tensor([1.3143, 0.0413])\n",
      "Epoch 465, Loss 58.572803, Params tensor([1.3149, 0.0414])\n",
      "Epoch 466, Loss 58.537819, Params tensor([1.3155, 0.0414])\n",
      "Epoch 467, Loss 58.502892, Params tensor([1.3160, 0.0415])\n",
      "Epoch 468, Loss 58.467995, Params tensor([1.3166, 0.0416])\n",
      "Epoch 469, Loss 58.433144, Params tensor([1.3172, 0.0416])\n",
      "Epoch 470, Loss 58.398331, Params tensor([1.3178, 0.0417])\n",
      "Epoch 471, Loss 58.363571, Params tensor([1.3184, 0.0418])\n",
      "Epoch 472, Loss 58.328846, Params tensor([1.3190, 0.0419])\n",
      "Epoch 473, Loss 58.294144, Params tensor([1.3196, 0.0419])\n",
      "Epoch 474, Loss 58.259510, Params tensor([1.3201, 0.0420])\n",
      "Epoch 475, Loss 58.224903, Params tensor([1.3207, 0.0421])\n",
      "Epoch 476, Loss 58.190342, Params tensor([1.3213, 0.0421])\n",
      "Epoch 477, Loss 58.155823, Params tensor([1.3219, 0.0422])\n",
      "Epoch 478, Loss 58.121338, Params tensor([1.3225, 0.0423])\n",
      "Epoch 479, Loss 58.086899, Params tensor([1.3231, 0.0424])\n",
      "Epoch 480, Loss 58.052517, Params tensor([1.3236, 0.0424])\n",
      "Epoch 481, Loss 58.018166, Params tensor([1.3242, 0.0425])\n",
      "Epoch 482, Loss 57.983852, Params tensor([1.3248, 0.0426])\n",
      "Epoch 483, Loss 57.949574, Params tensor([1.3254, 0.0427])\n",
      "Epoch 484, Loss 57.915367, Params tensor([1.3260, 0.0427])\n",
      "Epoch 485, Loss 57.881168, Params tensor([1.3265, 0.0428])\n",
      "Epoch 486, Loss 57.847031, Params tensor([1.3271, 0.0429])\n",
      "Epoch 487, Loss 57.812931, Params tensor([1.3277, 0.0429])\n",
      "Epoch 488, Loss 57.778870, Params tensor([1.3283, 0.0430])\n",
      "Epoch 489, Loss 57.744846, Params tensor([1.3289, 0.0431])\n",
      "Epoch 490, Loss 57.710854, Params tensor([1.3294, 0.0432])\n",
      "Epoch 491, Loss 57.676926, Params tensor([1.3300, 0.0432])\n",
      "Epoch 492, Loss 57.643021, Params tensor([1.3306, 0.0433])\n",
      "Epoch 493, Loss 57.609177, Params tensor([1.3312, 0.0434])\n",
      "Epoch 494, Loss 57.575356, Params tensor([1.3317, 0.0434])\n",
      "Epoch 495, Loss 57.541580, Params tensor([1.3323, 0.0435])\n",
      "Epoch 496, Loss 57.507839, Params tensor([1.3329, 0.0436])\n",
      "Epoch 497, Loss 57.474159, Params tensor([1.3335, 0.0437])\n",
      "Epoch 498, Loss 57.440506, Params tensor([1.3341, 0.0437])\n",
      "Epoch 499, Loss 57.406895, Params tensor([1.3346, 0.0438])\n",
      "Epoch 500, Loss 57.373318, Params tensor([1.3352, 0.0439])\n",
      "Epoch 501, Loss 57.339794, Params tensor([1.3358, 0.0439])\n",
      "Epoch 502, Loss 57.306309, Params tensor([1.3364, 0.0440])\n",
      "Epoch 503, Loss 57.272854, Params tensor([1.3369, 0.0441])\n",
      "Epoch 504, Loss 57.239437, Params tensor([1.3375, 0.0441])\n",
      "Epoch 505, Loss 57.206070, Params tensor([1.3381, 0.0442])\n",
      "Epoch 506, Loss 57.172745, Params tensor([1.3386, 0.0443])\n",
      "Epoch 507, Loss 57.139462, Params tensor([1.3392, 0.0444])\n",
      "Epoch 508, Loss 57.106228, Params tensor([1.3398, 0.0444])\n",
      "Epoch 509, Loss 57.073002, Params tensor([1.3404, 0.0445])\n",
      "Epoch 510, Loss 57.039833, Params tensor([1.3409, 0.0446])\n",
      "Epoch 511, Loss 57.006710, Params tensor([1.3415, 0.0446])\n",
      "Epoch 512, Loss 56.973629, Params tensor([1.3421, 0.0447])\n",
      "Epoch 513, Loss 56.940578, Params tensor([1.3426, 0.0448])\n",
      "Epoch 514, Loss 56.907566, Params tensor([1.3432, 0.0449])\n",
      "Epoch 515, Loss 56.874611, Params tensor([1.3438, 0.0449])\n",
      "Epoch 516, Loss 56.841675, Params tensor([1.3444, 0.0450])\n",
      "Epoch 517, Loss 56.808788, Params tensor([1.3449, 0.0451])\n",
      "Epoch 518, Loss 56.775940, Params tensor([1.3455, 0.0451])\n",
      "Epoch 519, Loss 56.743130, Params tensor([1.3461, 0.0452])\n",
      "Epoch 520, Loss 56.710354, Params tensor([1.3466, 0.0453])\n",
      "Epoch 521, Loss 56.677628, Params tensor([1.3472, 0.0453])\n",
      "Epoch 522, Loss 56.644947, Params tensor([1.3478, 0.0454])\n",
      "Epoch 523, Loss 56.612293, Params tensor([1.3483, 0.0455])\n",
      "Epoch 524, Loss 56.579697, Params tensor([1.3489, 0.0455])\n",
      "Epoch 525, Loss 56.547119, Params tensor([1.3495, 0.0456])\n",
      "Epoch 526, Loss 56.514584, Params tensor([1.3500, 0.0457])\n",
      "Epoch 527, Loss 56.482094, Params tensor([1.3506, 0.0458])\n",
      "Epoch 528, Loss 56.449646, Params tensor([1.3512, 0.0458])\n",
      "Epoch 529, Loss 56.417225, Params tensor([1.3517, 0.0459])\n",
      "Epoch 530, Loss 56.384853, Params tensor([1.3523, 0.0460])\n",
      "Epoch 531, Loss 56.352516, Params tensor([1.3528, 0.0460])\n",
      "Epoch 532, Loss 56.320225, Params tensor([1.3534, 0.0461])\n",
      "Epoch 533, Loss 56.287968, Params tensor([1.3540, 0.0462])\n",
      "Epoch 534, Loss 56.255741, Params tensor([1.3545, 0.0462])\n",
      "Epoch 535, Loss 56.223560, Params tensor([1.3551, 0.0463])\n",
      "Epoch 536, Loss 56.191433, Params tensor([1.3557, 0.0464])\n",
      "Epoch 537, Loss 56.159336, Params tensor([1.3562, 0.0464])\n",
      "Epoch 538, Loss 56.127281, Params tensor([1.3568, 0.0465])\n",
      "Epoch 539, Loss 56.095242, Params tensor([1.3574, 0.0466])\n",
      "Epoch 540, Loss 56.063259, Params tensor([1.3579, 0.0467])\n",
      "Epoch 541, Loss 56.031315, Params tensor([1.3585, 0.0467])\n",
      "Epoch 542, Loss 55.999405, Params tensor([1.3590, 0.0468])\n",
      "Epoch 543, Loss 55.967533, Params tensor([1.3596, 0.0469])\n",
      "Epoch 544, Loss 55.935707, Params tensor([1.3602, 0.0469])\n",
      "Epoch 545, Loss 55.903919, Params tensor([1.3607, 0.0470])\n",
      "Epoch 546, Loss 55.872166, Params tensor([1.3613, 0.0471])\n",
      "Epoch 547, Loss 55.840450, Params tensor([1.3618, 0.0471])\n",
      "Epoch 548, Loss 55.808777, Params tensor([1.3624, 0.0472])\n",
      "Epoch 549, Loss 55.777134, Params tensor([1.3629, 0.0473])\n",
      "Epoch 550, Loss 55.745533, Params tensor([1.3635, 0.0473])\n",
      "Epoch 551, Loss 55.713966, Params tensor([1.3641, 0.0474])\n",
      "Epoch 552, Loss 55.682446, Params tensor([1.3646, 0.0475])\n",
      "Epoch 553, Loss 55.650967, Params tensor([1.3652, 0.0475])\n",
      "Epoch 554, Loss 55.619507, Params tensor([1.3657, 0.0476])\n",
      "Epoch 555, Loss 55.588097, Params tensor([1.3663, 0.0477])\n",
      "Epoch 556, Loss 55.556736, Params tensor([1.3668, 0.0477])\n",
      "Epoch 557, Loss 55.525394, Params tensor([1.3674, 0.0478])\n",
      "Epoch 558, Loss 55.494095, Params tensor([1.3680, 0.0479])\n",
      "Epoch 559, Loss 55.462845, Params tensor([1.3685, 0.0479])\n",
      "Epoch 560, Loss 55.431625, Params tensor([1.3691, 0.0480])\n",
      "Epoch 561, Loss 55.400452, Params tensor([1.3696, 0.0481])\n",
      "Epoch 562, Loss 55.369297, Params tensor([1.3702, 0.0481])\n",
      "Epoch 563, Loss 55.338196, Params tensor([1.3707, 0.0482])\n",
      "Epoch 564, Loss 55.307117, Params tensor([1.3713, 0.0483])\n",
      "Epoch 565, Loss 55.276085, Params tensor([1.3718, 0.0483])\n",
      "Epoch 566, Loss 55.245090, Params tensor([1.3724, 0.0484])\n",
      "Epoch 567, Loss 55.214146, Params tensor([1.3729, 0.0485])\n",
      "Epoch 568, Loss 55.183224, Params tensor([1.3735, 0.0485])\n",
      "Epoch 569, Loss 55.152340, Params tensor([1.3740, 0.0486])\n",
      "Epoch 570, Loss 55.121483, Params tensor([1.3746, 0.0487])\n",
      "Epoch 571, Loss 55.090687, Params tensor([1.3751, 0.0487])\n",
      "Epoch 572, Loss 55.059914, Params tensor([1.3757, 0.0488])\n",
      "Epoch 573, Loss 55.029179, Params tensor([1.3762, 0.0489])\n",
      "Epoch 574, Loss 54.998486, Params tensor([1.3768, 0.0489])\n",
      "Epoch 575, Loss 54.967823, Params tensor([1.3773, 0.0490])\n",
      "Epoch 576, Loss 54.937210, Params tensor([1.3779, 0.0491])\n",
      "Epoch 577, Loss 54.906620, Params tensor([1.3784, 0.0491])\n",
      "Epoch 578, Loss 54.876064, Params tensor([1.3790, 0.0492])\n",
      "Epoch 579, Loss 54.845558, Params tensor([1.3795, 0.0493])\n",
      "Epoch 580, Loss 54.815090, Params tensor([1.3801, 0.0493])\n",
      "Epoch 581, Loss 54.784664, Params tensor([1.3806, 0.0494])\n",
      "Epoch 582, Loss 54.754250, Params tensor([1.3812, 0.0495])\n",
      "Epoch 583, Loss 54.723881, Params tensor([1.3817, 0.0495])\n",
      "Epoch 584, Loss 54.693558, Params tensor([1.3823, 0.0496])\n",
      "Epoch 585, Loss 54.663269, Params tensor([1.3828, 0.0497])\n",
      "Epoch 586, Loss 54.633007, Params tensor([1.3834, 0.0497])\n",
      "Epoch 587, Loss 54.602795, Params tensor([1.3839, 0.0498])\n",
      "Epoch 588, Loss 54.572620, Params tensor([1.3845, 0.0499])\n",
      "Epoch 589, Loss 54.542484, Params tensor([1.3850, 0.0499])\n",
      "Epoch 590, Loss 54.512367, Params tensor([1.3855, 0.0500])\n",
      "Epoch 591, Loss 54.482288, Params tensor([1.3861, 0.0501])\n",
      "Epoch 592, Loss 54.452267, Params tensor([1.3866, 0.0501])\n",
      "Epoch 593, Loss 54.422253, Params tensor([1.3872, 0.0502])\n",
      "Epoch 594, Loss 54.392296, Params tensor([1.3877, 0.0503])\n",
      "Epoch 595, Loss 54.362370, Params tensor([1.3883, 0.0503])\n",
      "Epoch 596, Loss 54.332485, Params tensor([1.3888, 0.0504])\n",
      "Epoch 597, Loss 54.302628, Params tensor([1.3893, 0.0505])\n",
      "Epoch 598, Loss 54.272812, Params tensor([1.3899, 0.0505])\n",
      "Epoch 599, Loss 54.243031, Params tensor([1.3904, 0.0506])\n",
      "Epoch 600, Loss 54.213295, Params tensor([1.3910, 0.0507])\n",
      "Epoch 601, Loss 54.183582, Params tensor([1.3915, 0.0507])\n",
      "Epoch 602, Loss 54.153904, Params tensor([1.3921, 0.0508])\n",
      "Epoch 603, Loss 54.124271, Params tensor([1.3926, 0.0508])\n",
      "Epoch 604, Loss 54.094666, Params tensor([1.3931, 0.0509])\n",
      "Epoch 605, Loss 54.065098, Params tensor([1.3937, 0.0510])\n",
      "Epoch 606, Loss 54.035572, Params tensor([1.3942, 0.0510])\n",
      "Epoch 607, Loss 54.006081, Params tensor([1.3948, 0.0511])\n",
      "Epoch 608, Loss 53.976624, Params tensor([1.3953, 0.0512])\n",
      "Epoch 609, Loss 53.947193, Params tensor([1.3958, 0.0512])\n",
      "Epoch 610, Loss 53.917801, Params tensor([1.3964, 0.0513])\n",
      "Epoch 611, Loss 53.888462, Params tensor([1.3969, 0.0514])\n",
      "Epoch 612, Loss 53.859127, Params tensor([1.3974, 0.0514])\n",
      "Epoch 613, Loss 53.829857, Params tensor([1.3980, 0.0515])\n",
      "Epoch 614, Loss 53.800610, Params tensor([1.3985, 0.0516])\n",
      "Epoch 615, Loss 53.771400, Params tensor([1.3991, 0.0516])\n",
      "Epoch 616, Loss 53.742214, Params tensor([1.3996, 0.0517])\n",
      "Epoch 617, Loss 53.713078, Params tensor([1.4001, 0.0517])\n",
      "Epoch 618, Loss 53.683975, Params tensor([1.4007, 0.0518])\n",
      "Epoch 619, Loss 53.654903, Params tensor([1.4012, 0.0519])\n",
      "Epoch 620, Loss 53.625866, Params tensor([1.4017, 0.0519])\n",
      "Epoch 621, Loss 53.596874, Params tensor([1.4023, 0.0520])\n",
      "Epoch 622, Loss 53.567898, Params tensor([1.4028, 0.0521])\n",
      "Epoch 623, Loss 53.538975, Params tensor([1.4033, 0.0521])\n",
      "Epoch 624, Loss 53.510082, Params tensor([1.4039, 0.0522])\n",
      "Epoch 625, Loss 53.481216, Params tensor([1.4044, 0.0523])\n",
      "Epoch 626, Loss 53.452404, Params tensor([1.4049, 0.0523])\n",
      "Epoch 627, Loss 53.423618, Params tensor([1.4055, 0.0524])\n",
      "Epoch 628, Loss 53.394859, Params tensor([1.4060, 0.0524])\n",
      "Epoch 629, Loss 53.366138, Params tensor([1.4065, 0.0525])\n",
      "Epoch 630, Loss 53.337452, Params tensor([1.4071, 0.0526])\n",
      "Epoch 631, Loss 53.308811, Params tensor([1.4076, 0.0526])\n",
      "Epoch 632, Loss 53.280178, Params tensor([1.4081, 0.0527])\n",
      "Epoch 633, Loss 53.251598, Params tensor([1.4087, 0.0528])\n",
      "Epoch 634, Loss 53.223061, Params tensor([1.4092, 0.0528])\n",
      "Epoch 635, Loss 53.194546, Params tensor([1.4097, 0.0529])\n",
      "Epoch 636, Loss 53.166061, Params tensor([1.4102, 0.0530])\n",
      "Epoch 637, Loss 53.137638, Params tensor([1.4108, 0.0530])\n",
      "Epoch 638, Loss 53.109215, Params tensor([1.4113, 0.0531])\n",
      "Epoch 639, Loss 53.080833, Params tensor([1.4118, 0.0531])\n",
      "Epoch 640, Loss 53.052494, Params tensor([1.4124, 0.0532])\n",
      "Epoch 641, Loss 53.024197, Params tensor([1.4129, 0.0533])\n",
      "Epoch 642, Loss 52.995914, Params tensor([1.4134, 0.0533])\n",
      "Epoch 643, Loss 52.967678, Params tensor([1.4139, 0.0534])\n",
      "Epoch 644, Loss 52.939465, Params tensor([1.4145, 0.0535])\n",
      "Epoch 645, Loss 52.911304, Params tensor([1.4150, 0.0535])\n",
      "Epoch 646, Loss 52.883175, Params tensor([1.4155, 0.0536])\n",
      "Epoch 647, Loss 52.855076, Params tensor([1.4160, 0.0536])\n",
      "Epoch 648, Loss 52.827000, Params tensor([1.4166, 0.0537])\n",
      "Epoch 649, Loss 52.798962, Params tensor([1.4171, 0.0538])\n",
      "Epoch 650, Loss 52.770973, Params tensor([1.4176, 0.0538])\n",
      "Epoch 651, Loss 52.743008, Params tensor([1.4181, 0.0539])\n",
      "Epoch 652, Loss 52.715076, Params tensor([1.4187, 0.0539])\n",
      "Epoch 653, Loss 52.687172, Params tensor([1.4192, 0.0540])\n",
      "Epoch 654, Loss 52.659306, Params tensor([1.4197, 0.0541])\n",
      "Epoch 655, Loss 52.631481, Params tensor([1.4202, 0.0541])\n",
      "Epoch 656, Loss 52.603676, Params tensor([1.4208, 0.0542])\n",
      "Epoch 657, Loss 52.575916, Params tensor([1.4213, 0.0543])\n",
      "Epoch 658, Loss 52.548195, Params tensor([1.4218, 0.0543])\n",
      "Epoch 659, Loss 52.520485, Params tensor([1.4223, 0.0544])\n",
      "Epoch 660, Loss 52.492825, Params tensor([1.4229, 0.0544])\n",
      "Epoch 661, Loss 52.465187, Params tensor([1.4234, 0.0545])\n",
      "Epoch 662, Loss 52.437595, Params tensor([1.4239, 0.0546])\n",
      "Epoch 663, Loss 52.410034, Params tensor([1.4244, 0.0546])\n",
      "Epoch 664, Loss 52.382504, Params tensor([1.4249, 0.0547])\n",
      "Epoch 665, Loss 52.355015, Params tensor([1.4255, 0.0548])\n",
      "Epoch 666, Loss 52.327541, Params tensor([1.4260, 0.0548])\n",
      "Epoch 667, Loss 52.300114, Params tensor([1.4265, 0.0549])\n",
      "Epoch 668, Loss 52.272717, Params tensor([1.4270, 0.0549])\n",
      "Epoch 669, Loss 52.245350, Params tensor([1.4275, 0.0550])\n",
      "Epoch 670, Loss 52.218021, Params tensor([1.4281, 0.0551])\n",
      "Epoch 671, Loss 52.190720, Params tensor([1.4286, 0.0551])\n",
      "Epoch 672, Loss 52.163456, Params tensor([1.4291, 0.0552])\n",
      "Epoch 673, Loss 52.136230, Params tensor([1.4296, 0.0552])\n",
      "Epoch 674, Loss 52.109032, Params tensor([1.4301, 0.0553])\n",
      "Epoch 675, Loss 52.081860, Params tensor([1.4307, 0.0554])\n",
      "Epoch 676, Loss 52.054722, Params tensor([1.4312, 0.0554])\n",
      "Epoch 677, Loss 52.027626, Params tensor([1.4317, 0.0555])\n",
      "Epoch 678, Loss 52.000565, Params tensor([1.4322, 0.0555])\n",
      "Epoch 679, Loss 51.973526, Params tensor([1.4327, 0.0556])\n",
      "Epoch 680, Loss 51.946522, Params tensor([1.4332, 0.0557])\n",
      "Epoch 681, Loss 51.919559, Params tensor([1.4338, 0.0557])\n",
      "Epoch 682, Loss 51.892624, Params tensor([1.4343, 0.0558])\n",
      "Epoch 683, Loss 51.865719, Params tensor([1.4348, 0.0558])\n",
      "Epoch 684, Loss 51.838840, Params tensor([1.4353, 0.0559])\n",
      "Epoch 685, Loss 51.812012, Params tensor([1.4358, 0.0560])\n",
      "Epoch 686, Loss 51.785206, Params tensor([1.4363, 0.0560])\n",
      "Epoch 687, Loss 51.758423, Params tensor([1.4368, 0.0561])\n",
      "Epoch 688, Loss 51.731693, Params tensor([1.4374, 0.0561])\n",
      "Epoch 689, Loss 51.704979, Params tensor([1.4379, 0.0562])\n",
      "Epoch 690, Loss 51.678284, Params tensor([1.4384, 0.0563])\n",
      "Epoch 691, Loss 51.651646, Params tensor([1.4389, 0.0563])\n",
      "Epoch 692, Loss 51.625027, Params tensor([1.4394, 0.0564])\n",
      "Epoch 693, Loss 51.598454, Params tensor([1.4399, 0.0564])\n",
      "Epoch 694, Loss 51.571903, Params tensor([1.4404, 0.0565])\n",
      "Epoch 695, Loss 51.545383, Params tensor([1.4409, 0.0566])\n",
      "Epoch 696, Loss 51.518906, Params tensor([1.4414, 0.0566])\n",
      "Epoch 697, Loss 51.492435, Params tensor([1.4420, 0.0567])\n",
      "Epoch 698, Loss 51.466030, Params tensor([1.4425, 0.0567])\n",
      "Epoch 699, Loss 51.439640, Params tensor([1.4430, 0.0568])\n",
      "Epoch 700, Loss 51.413284, Params tensor([1.4435, 0.0569])\n",
      "Epoch 701, Loss 51.386959, Params tensor([1.4440, 0.0569])\n",
      "Epoch 702, Loss 51.360668, Params tensor([1.4445, 0.0570])\n",
      "Epoch 703, Loss 51.334408, Params tensor([1.4450, 0.0570])\n",
      "Epoch 704, Loss 51.308170, Params tensor([1.4455, 0.0571])\n",
      "Epoch 705, Loss 51.281967, Params tensor([1.4460, 0.0572])\n",
      "Epoch 706, Loss 51.255802, Params tensor([1.4465, 0.0572])\n",
      "Epoch 707, Loss 51.229675, Params tensor([1.4470, 0.0573])\n",
      "Epoch 708, Loss 51.203568, Params tensor([1.4476, 0.0573])\n",
      "Epoch 709, Loss 51.177502, Params tensor([1.4481, 0.0574])\n",
      "Epoch 710, Loss 51.151463, Params tensor([1.4486, 0.0575])\n",
      "Epoch 711, Loss 51.125450, Params tensor([1.4491, 0.0575])\n",
      "Epoch 712, Loss 51.099472, Params tensor([1.4496, 0.0576])\n",
      "Epoch 713, Loss 51.073513, Params tensor([1.4501, 0.0576])\n",
      "Epoch 714, Loss 51.047607, Params tensor([1.4506, 0.0577])\n",
      "Epoch 715, Loss 51.021717, Params tensor([1.4511, 0.0577])\n",
      "Epoch 716, Loss 50.995872, Params tensor([1.4516, 0.0578])\n",
      "Epoch 717, Loss 50.970047, Params tensor([1.4521, 0.0579])\n",
      "Epoch 718, Loss 50.944263, Params tensor([1.4526, 0.0579])\n",
      "Epoch 719, Loss 50.918503, Params tensor([1.4531, 0.0580])\n",
      "Epoch 720, Loss 50.892776, Params tensor([1.4536, 0.0580])\n",
      "Epoch 721, Loss 50.867081, Params tensor([1.4541, 0.0581])\n",
      "Epoch 722, Loss 50.841415, Params tensor([1.4546, 0.0582])\n",
      "Epoch 723, Loss 50.815781, Params tensor([1.4551, 0.0582])\n",
      "Epoch 724, Loss 50.790176, Params tensor([1.4556, 0.0583])\n",
      "Epoch 725, Loss 50.764603, Params tensor([1.4561, 0.0583])\n",
      "Epoch 726, Loss 50.739059, Params tensor([1.4566, 0.0584])\n",
      "Epoch 727, Loss 50.713547, Params tensor([1.4571, 0.0584])\n",
      "Epoch 728, Loss 50.688065, Params tensor([1.4576, 0.0585])\n",
      "Epoch 729, Loss 50.662613, Params tensor([1.4581, 0.0586])\n",
      "Epoch 730, Loss 50.637196, Params tensor([1.4586, 0.0586])\n",
      "Epoch 731, Loss 50.611813, Params tensor([1.4591, 0.0587])\n",
      "Epoch 732, Loss 50.586460, Params tensor([1.4596, 0.0587])\n",
      "Epoch 733, Loss 50.561123, Params tensor([1.4601, 0.0588])\n",
      "Epoch 734, Loss 50.535831, Params tensor([1.4606, 0.0588])\n",
      "Epoch 735, Loss 50.510574, Params tensor([1.4611, 0.0589])\n",
      "Epoch 736, Loss 50.485336, Params tensor([1.4616, 0.0590])\n",
      "Epoch 737, Loss 50.460133, Params tensor([1.4621, 0.0590])\n",
      "Epoch 738, Loss 50.434959, Params tensor([1.4626, 0.0591])\n",
      "Epoch 739, Loss 50.409817, Params tensor([1.4631, 0.0591])\n",
      "Epoch 740, Loss 50.384705, Params tensor([1.4636, 0.0592])\n",
      "Epoch 741, Loss 50.359631, Params tensor([1.4641, 0.0592])\n",
      "Epoch 742, Loss 50.334568, Params tensor([1.4646, 0.0593])\n",
      "Epoch 743, Loss 50.309547, Params tensor([1.4651, 0.0594])\n",
      "Epoch 744, Loss 50.284561, Params tensor([1.4656, 0.0594])\n",
      "Epoch 745, Loss 50.259594, Params tensor([1.4661, 0.0595])\n",
      "Epoch 746, Loss 50.234676, Params tensor([1.4666, 0.0595])\n",
      "Epoch 747, Loss 50.209774, Params tensor([1.4671, 0.0596])\n",
      "Epoch 748, Loss 50.184891, Params tensor([1.4676, 0.0596])\n",
      "Epoch 749, Loss 50.160061, Params tensor([1.4681, 0.0597])\n",
      "Epoch 750, Loss 50.135242, Params tensor([1.4686, 0.0598])\n",
      "Epoch 751, Loss 50.110462, Params tensor([1.4691, 0.0598])\n",
      "Epoch 752, Loss 50.085709, Params tensor([1.4696, 0.0599])\n",
      "Epoch 753, Loss 50.060997, Params tensor([1.4701, 0.0599])\n",
      "Epoch 754, Loss 50.036304, Params tensor([1.4706, 0.0600])\n",
      "Epoch 755, Loss 50.011642, Params tensor([1.4711, 0.0600])\n",
      "Epoch 756, Loss 49.987003, Params tensor([1.4715, 0.0601])\n",
      "Epoch 757, Loss 49.962406, Params tensor([1.4720, 0.0602])\n",
      "Epoch 758, Loss 49.937840, Params tensor([1.4725, 0.0602])\n",
      "Epoch 759, Loss 49.913296, Params tensor([1.4730, 0.0603])\n",
      "Epoch 760, Loss 49.888783, Params tensor([1.4735, 0.0603])\n",
      "Epoch 761, Loss 49.864296, Params tensor([1.4740, 0.0604])\n",
      "Epoch 762, Loss 49.839840, Params tensor([1.4745, 0.0604])\n",
      "Epoch 763, Loss 49.815414, Params tensor([1.4750, 0.0605])\n",
      "Epoch 764, Loss 49.791027, Params tensor([1.4755, 0.0605])\n",
      "Epoch 765, Loss 49.766659, Params tensor([1.4760, 0.0606])\n",
      "Epoch 766, Loss 49.742313, Params tensor([1.4765, 0.0607])\n",
      "Epoch 767, Loss 49.718018, Params tensor([1.4770, 0.0607])\n",
      "Epoch 768, Loss 49.693737, Params tensor([1.4774, 0.0608])\n",
      "Epoch 769, Loss 49.669495, Params tensor([1.4779, 0.0608])\n",
      "Epoch 770, Loss 49.645267, Params tensor([1.4784, 0.0609])\n",
      "Epoch 771, Loss 49.621082, Params tensor([1.4789, 0.0609])\n",
      "Epoch 772, Loss 49.596920, Params tensor([1.4794, 0.0610])\n",
      "Epoch 773, Loss 49.572792, Params tensor([1.4799, 0.0611])\n",
      "Epoch 774, Loss 49.548695, Params tensor([1.4804, 0.0611])\n",
      "Epoch 775, Loss 49.524620, Params tensor([1.4809, 0.0612])\n",
      "Epoch 776, Loss 49.500576, Params tensor([1.4813, 0.0612])\n",
      "Epoch 777, Loss 49.476562, Params tensor([1.4818, 0.0613])\n",
      "Epoch 778, Loss 49.452576, Params tensor([1.4823, 0.0613])\n",
      "Epoch 779, Loss 49.428616, Params tensor([1.4828, 0.0614])\n",
      "Epoch 780, Loss 49.404690, Params tensor([1.4833, 0.0614])\n",
      "Epoch 781, Loss 49.380787, Params tensor([1.4838, 0.0615])\n",
      "Epoch 782, Loss 49.356922, Params tensor([1.4843, 0.0615])\n",
      "Epoch 783, Loss 49.333084, Params tensor([1.4847, 0.0616])\n",
      "Epoch 784, Loss 49.309269, Params tensor([1.4852, 0.0617])\n",
      "Epoch 785, Loss 49.285484, Params tensor([1.4857, 0.0617])\n",
      "Epoch 786, Loss 49.261734, Params tensor([1.4862, 0.0618])\n",
      "Epoch 787, Loss 49.238003, Params tensor([1.4867, 0.0618])\n",
      "Epoch 788, Loss 49.214310, Params tensor([1.4872, 0.0619])\n",
      "Epoch 789, Loss 49.190628, Params tensor([1.4876, 0.0619])\n",
      "Epoch 790, Loss 49.166996, Params tensor([1.4881, 0.0620])\n",
      "Epoch 791, Loss 49.143394, Params tensor([1.4886, 0.0620])\n",
      "Epoch 792, Loss 49.119797, Params tensor([1.4891, 0.0621])\n",
      "Epoch 793, Loss 49.096249, Params tensor([1.4896, 0.0622])\n",
      "Epoch 794, Loss 49.072720, Params tensor([1.4901, 0.0622])\n",
      "Epoch 795, Loss 49.049217, Params tensor([1.4905, 0.0623])\n",
      "Epoch 796, Loss 49.025753, Params tensor([1.4910, 0.0623])\n",
      "Epoch 797, Loss 49.002316, Params tensor([1.4915, 0.0624])\n",
      "Epoch 798, Loss 48.978897, Params tensor([1.4920, 0.0624])\n",
      "Epoch 799, Loss 48.955517, Params tensor([1.4925, 0.0625])\n",
      "Epoch 800, Loss 48.932152, Params tensor([1.4929, 0.0625])\n",
      "Epoch 801, Loss 48.908836, Params tensor([1.4934, 0.0626])\n",
      "Epoch 802, Loss 48.885532, Params tensor([1.4939, 0.0626])\n",
      "Epoch 803, Loss 48.862255, Params tensor([1.4944, 0.0627])\n",
      "Epoch 804, Loss 48.839016, Params tensor([1.4949, 0.0627])\n",
      "Epoch 805, Loss 48.815800, Params tensor([1.4953, 0.0628])\n",
      "Epoch 806, Loss 48.792606, Params tensor([1.4958, 0.0629])\n",
      "Epoch 807, Loss 48.769455, Params tensor([1.4963, 0.0629])\n",
      "Epoch 808, Loss 48.746326, Params tensor([1.4968, 0.0630])\n",
      "Epoch 809, Loss 48.723221, Params tensor([1.4973, 0.0630])\n",
      "Epoch 810, Loss 48.700146, Params tensor([1.4977, 0.0631])\n",
      "Epoch 811, Loss 48.677097, Params tensor([1.4982, 0.0631])\n",
      "Epoch 812, Loss 48.654079, Params tensor([1.4987, 0.0632])\n",
      "Epoch 813, Loss 48.631092, Params tensor([1.4992, 0.0632])\n",
      "Epoch 814, Loss 48.608120, Params tensor([1.4996, 0.0633])\n",
      "Epoch 815, Loss 48.585190, Params tensor([1.5001, 0.0633])\n",
      "Epoch 816, Loss 48.562279, Params tensor([1.5006, 0.0634])\n",
      "Epoch 817, Loss 48.539402, Params tensor([1.5011, 0.0634])\n",
      "Epoch 818, Loss 48.516544, Params tensor([1.5015, 0.0635])\n",
      "Epoch 819, Loss 48.493717, Params tensor([1.5020, 0.0635])\n",
      "Epoch 820, Loss 48.470921, Params tensor([1.5025, 0.0636])\n",
      "Epoch 821, Loss 48.448147, Params tensor([1.5030, 0.0637])\n",
      "Epoch 822, Loss 48.425404, Params tensor([1.5034, 0.0637])\n",
      "Epoch 823, Loss 48.402687, Params tensor([1.5039, 0.0638])\n",
      "Epoch 824, Loss 48.380005, Params tensor([1.5044, 0.0638])\n",
      "Epoch 825, Loss 48.357338, Params tensor([1.5049, 0.0639])\n",
      "Epoch 826, Loss 48.334705, Params tensor([1.5053, 0.0639])\n",
      "Epoch 827, Loss 48.312107, Params tensor([1.5058, 0.0640])\n",
      "Epoch 828, Loss 48.289524, Params tensor([1.5063, 0.0640])\n",
      "Epoch 829, Loss 48.266968, Params tensor([1.5067, 0.0641])\n",
      "Epoch 830, Loss 48.244446, Params tensor([1.5072, 0.0641])\n",
      "Epoch 831, Loss 48.221947, Params tensor([1.5077, 0.0642])\n",
      "Epoch 832, Loss 48.199467, Params tensor([1.5082, 0.0642])\n",
      "Epoch 833, Loss 48.177025, Params tensor([1.5086, 0.0643])\n",
      "Epoch 834, Loss 48.154606, Params tensor([1.5091, 0.0643])\n",
      "Epoch 835, Loss 48.132217, Params tensor([1.5096, 0.0644])\n",
      "Epoch 836, Loss 48.109859, Params tensor([1.5100, 0.0644])\n",
      "Epoch 837, Loss 48.087528, Params tensor([1.5105, 0.0645])\n",
      "Epoch 838, Loss 48.065224, Params tensor([1.5110, 0.0646])\n",
      "Epoch 839, Loss 48.042934, Params tensor([1.5114, 0.0646])\n",
      "Epoch 840, Loss 48.020679, Params tensor([1.5119, 0.0647])\n",
      "Epoch 841, Loss 47.998463, Params tensor([1.5124, 0.0647])\n",
      "Epoch 842, Loss 47.976257, Params tensor([1.5128, 0.0648])\n",
      "Epoch 843, Loss 47.954067, Params tensor([1.5133, 0.0648])\n",
      "Epoch 844, Loss 47.931934, Params tensor([1.5138, 0.0649])\n",
      "Epoch 845, Loss 47.909817, Params tensor([1.5142, 0.0649])\n",
      "Epoch 846, Loss 47.887722, Params tensor([1.5147, 0.0650])\n",
      "Epoch 847, Loss 47.865658, Params tensor([1.5152, 0.0650])\n",
      "Epoch 848, Loss 47.843613, Params tensor([1.5156, 0.0651])\n",
      "Epoch 849, Loss 47.821598, Params tensor([1.5161, 0.0651])\n",
      "Epoch 850, Loss 47.799618, Params tensor([1.5166, 0.0652])\n",
      "Epoch 851, Loss 47.777653, Params tensor([1.5170, 0.0652])\n",
      "Epoch 852, Loss 47.755726, Params tensor([1.5175, 0.0653])\n",
      "Epoch 853, Loss 47.733822, Params tensor([1.5180, 0.0653])\n",
      "Epoch 854, Loss 47.711937, Params tensor([1.5184, 0.0654])\n",
      "Epoch 855, Loss 47.690079, Params tensor([1.5189, 0.0654])\n",
      "Epoch 856, Loss 47.668251, Params tensor([1.5194, 0.0655])\n",
      "Epoch 857, Loss 47.646450, Params tensor([1.5198, 0.0655])\n",
      "Epoch 858, Loss 47.624672, Params tensor([1.5203, 0.0656])\n",
      "Epoch 859, Loss 47.602932, Params tensor([1.5208, 0.0656])\n",
      "Epoch 860, Loss 47.581203, Params tensor([1.5212, 0.0657])\n",
      "Epoch 861, Loss 47.559505, Params tensor([1.5217, 0.0657])\n",
      "Epoch 862, Loss 47.537842, Params tensor([1.5222, 0.0658])\n",
      "Epoch 863, Loss 47.516190, Params tensor([1.5226, 0.0658])\n",
      "Epoch 864, Loss 47.494572, Params tensor([1.5231, 0.0659])\n",
      "Epoch 865, Loss 47.472977, Params tensor([1.5235, 0.0659])\n",
      "Epoch 866, Loss 47.451416, Params tensor([1.5240, 0.0660])\n",
      "Epoch 867, Loss 47.429886, Params tensor([1.5245, 0.0660])\n",
      "Epoch 868, Loss 47.408363, Params tensor([1.5249, 0.0661])\n",
      "Epoch 869, Loss 47.386875, Params tensor([1.5254, 0.0661])\n",
      "Epoch 870, Loss 47.365417, Params tensor([1.5258, 0.0662])\n",
      "Epoch 871, Loss 47.343990, Params tensor([1.5263, 0.0662])\n",
      "Epoch 872, Loss 47.322571, Params tensor([1.5268, 0.0663])\n",
      "Epoch 873, Loss 47.301193, Params tensor([1.5272, 0.0663])\n",
      "Epoch 874, Loss 47.279835, Params tensor([1.5277, 0.0664])\n",
      "Epoch 875, Loss 47.258499, Params tensor([1.5281, 0.0664])\n",
      "Epoch 876, Loss 47.237194, Params tensor([1.5286, 0.0665])\n",
      "Epoch 877, Loss 47.215916, Params tensor([1.5291, 0.0665])\n",
      "Epoch 878, Loss 47.194656, Params tensor([1.5295, 0.0666])\n",
      "Epoch 879, Loss 47.173424, Params tensor([1.5300, 0.0666])\n",
      "Epoch 880, Loss 47.152222, Params tensor([1.5304, 0.0667])\n",
      "Epoch 881, Loss 47.131046, Params tensor([1.5309, 0.0667])\n",
      "Epoch 882, Loss 47.109890, Params tensor([1.5313, 0.0668])\n",
      "Epoch 883, Loss 47.088768, Params tensor([1.5318, 0.0668])\n",
      "Epoch 884, Loss 47.067665, Params tensor([1.5323, 0.0669])\n",
      "Epoch 885, Loss 47.046585, Params tensor([1.5327, 0.0669])\n",
      "Epoch 886, Loss 47.025528, Params tensor([1.5332, 0.0670])\n",
      "Epoch 887, Loss 47.004513, Params tensor([1.5336, 0.0670])\n",
      "Epoch 888, Loss 46.983509, Params tensor([1.5341, 0.0671])\n",
      "Epoch 889, Loss 46.962536, Params tensor([1.5345, 0.0671])\n",
      "Epoch 890, Loss 46.941589, Params tensor([1.5350, 0.0672])\n",
      "Epoch 891, Loss 46.920658, Params tensor([1.5354, 0.0672])\n",
      "Epoch 892, Loss 46.899757, Params tensor([1.5359, 0.0673])\n",
      "Epoch 893, Loss 46.878880, Params tensor([1.5364, 0.0673])\n",
      "Epoch 894, Loss 46.858044, Params tensor([1.5368, 0.0674])\n",
      "Epoch 895, Loss 46.837215, Params tensor([1.5373, 0.0674])\n",
      "Epoch 896, Loss 46.816410, Params tensor([1.5377, 0.0675])\n",
      "Epoch 897, Loss 46.795643, Params tensor([1.5382, 0.0675])\n",
      "Epoch 898, Loss 46.774891, Params tensor([1.5386, 0.0676])\n",
      "Epoch 899, Loss 46.754166, Params tensor([1.5391, 0.0676])\n",
      "Epoch 900, Loss 46.733471, Params tensor([1.5395, 0.0677])\n",
      "Epoch 901, Loss 46.712791, Params tensor([1.5400, 0.0677])\n",
      "Epoch 902, Loss 46.692154, Params tensor([1.5404, 0.0678])\n",
      "Epoch 903, Loss 46.671524, Params tensor([1.5409, 0.0678])\n",
      "Epoch 904, Loss 46.650928, Params tensor([1.5413, 0.0679])\n",
      "Epoch 905, Loss 46.630360, Params tensor([1.5418, 0.0679])\n",
      "Epoch 906, Loss 46.609814, Params tensor([1.5422, 0.0680])\n",
      "Epoch 907, Loss 46.589291, Params tensor([1.5427, 0.0680])\n",
      "Epoch 908, Loss 46.568787, Params tensor([1.5431, 0.0681])\n",
      "Epoch 909, Loss 46.548306, Params tensor([1.5436, 0.0681])\n",
      "Epoch 910, Loss 46.527859, Params tensor([1.5440, 0.0682])\n",
      "Epoch 911, Loss 46.507442, Params tensor([1.5445, 0.0682])\n",
      "Epoch 912, Loss 46.487038, Params tensor([1.5449, 0.0683])\n",
      "Epoch 913, Loss 46.466663, Params tensor([1.5454, 0.0683])\n",
      "Epoch 914, Loss 46.446304, Params tensor([1.5458, 0.0684])\n",
      "Epoch 915, Loss 46.425980, Params tensor([1.5463, 0.0684])\n",
      "Epoch 916, Loss 46.405693, Params tensor([1.5467, 0.0685])\n",
      "Epoch 917, Loss 46.385410, Params tensor([1.5472, 0.0685])\n",
      "Epoch 918, Loss 46.365150, Params tensor([1.5476, 0.0686])\n",
      "Epoch 919, Loss 46.344913, Params tensor([1.5481, 0.0686])\n",
      "Epoch 920, Loss 46.324722, Params tensor([1.5485, 0.0687])\n",
      "Epoch 921, Loss 46.304539, Params tensor([1.5490, 0.0687])\n",
      "Epoch 922, Loss 46.284389, Params tensor([1.5494, 0.0688])\n",
      "Epoch 923, Loss 46.264256, Params tensor([1.5498, 0.0688])\n",
      "Epoch 924, Loss 46.244156, Params tensor([1.5503, 0.0689])\n",
      "Epoch 925, Loss 46.224064, Params tensor([1.5507, 0.0689])\n",
      "Epoch 926, Loss 46.204006, Params tensor([1.5512, 0.0690])\n",
      "Epoch 927, Loss 46.183975, Params tensor([1.5516, 0.0690])\n",
      "Epoch 928, Loss 46.163963, Params tensor([1.5521, 0.0691])\n",
      "Epoch 929, Loss 46.143978, Params tensor([1.5525, 0.0691])\n",
      "Epoch 930, Loss 46.124020, Params tensor([1.5530, 0.0691])\n",
      "Epoch 931, Loss 46.104080, Params tensor([1.5534, 0.0692])\n",
      "Epoch 932, Loss 46.084167, Params tensor([1.5538, 0.0692])\n",
      "Epoch 933, Loss 46.064281, Params tensor([1.5543, 0.0693])\n",
      "Epoch 934, Loss 46.044418, Params tensor([1.5547, 0.0693])\n",
      "Epoch 935, Loss 46.024570, Params tensor([1.5552, 0.0694])\n",
      "Epoch 936, Loss 46.004749, Params tensor([1.5556, 0.0694])\n",
      "Epoch 937, Loss 45.984959, Params tensor([1.5561, 0.0695])\n",
      "Epoch 938, Loss 45.965195, Params tensor([1.5565, 0.0695])\n",
      "Epoch 939, Loss 45.945442, Params tensor([1.5569, 0.0696])\n",
      "Epoch 940, Loss 45.925720, Params tensor([1.5574, 0.0696])\n",
      "Epoch 941, Loss 45.906033, Params tensor([1.5578, 0.0697])\n",
      "Epoch 942, Loss 45.886353, Params tensor([1.5583, 0.0697])\n",
      "Epoch 943, Loss 45.866703, Params tensor([1.5587, 0.0698])\n",
      "Epoch 944, Loss 45.847073, Params tensor([1.5591, 0.0698])\n",
      "Epoch 945, Loss 45.827473, Params tensor([1.5596, 0.0699])\n",
      "Epoch 946, Loss 45.807896, Params tensor([1.5600, 0.0699])\n",
      "Epoch 947, Loss 45.788342, Params tensor([1.5605, 0.0700])\n",
      "Epoch 948, Loss 45.768806, Params tensor([1.5609, 0.0700])\n",
      "Epoch 949, Loss 45.749294, Params tensor([1.5613, 0.0700])\n",
      "Epoch 950, Loss 45.729805, Params tensor([1.5618, 0.0701])\n",
      "Epoch 951, Loss 45.710354, Params tensor([1.5622, 0.0701])\n",
      "Epoch 952, Loss 45.690914, Params tensor([1.5627, 0.0702])\n",
      "Epoch 953, Loss 45.671497, Params tensor([1.5631, 0.0702])\n",
      "Epoch 954, Loss 45.652103, Params tensor([1.5635, 0.0703])\n",
      "Epoch 955, Loss 45.632736, Params tensor([1.5640, 0.0703])\n",
      "Epoch 956, Loss 45.613396, Params tensor([1.5644, 0.0704])\n",
      "Epoch 957, Loss 45.594078, Params tensor([1.5648, 0.0704])\n",
      "Epoch 958, Loss 45.574783, Params tensor([1.5653, 0.0705])\n",
      "Epoch 959, Loss 45.555508, Params tensor([1.5657, 0.0705])\n",
      "Epoch 960, Loss 45.536255, Params tensor([1.5662, 0.0706])\n",
      "Epoch 961, Loss 45.517029, Params tensor([1.5666, 0.0706])\n",
      "Epoch 962, Loss 45.497826, Params tensor([1.5670, 0.0707])\n",
      "Epoch 963, Loss 45.478642, Params tensor([1.5675, 0.0707])\n",
      "Epoch 964, Loss 45.459484, Params tensor([1.5679, 0.0707])\n",
      "Epoch 965, Loss 45.440350, Params tensor([1.5683, 0.0708])\n",
      "Epoch 966, Loss 45.421230, Params tensor([1.5688, 0.0708])\n",
      "Epoch 967, Loss 45.402145, Params tensor([1.5692, 0.0709])\n",
      "Epoch 968, Loss 45.383083, Params tensor([1.5696, 0.0709])\n",
      "Epoch 969, Loss 45.364037, Params tensor([1.5701, 0.0710])\n",
      "Epoch 970, Loss 45.345016, Params tensor([1.5705, 0.0710])\n",
      "Epoch 971, Loss 45.326019, Params tensor([1.5709, 0.0711])\n",
      "Epoch 972, Loss 45.307045, Params tensor([1.5714, 0.0711])\n",
      "Epoch 973, Loss 45.288094, Params tensor([1.5718, 0.0712])\n",
      "Epoch 974, Loss 45.269173, Params tensor([1.5722, 0.0712])\n",
      "Epoch 975, Loss 45.250263, Params tensor([1.5727, 0.0712])\n",
      "Epoch 976, Loss 45.231373, Params tensor([1.5731, 0.0713])\n",
      "Epoch 977, Loss 45.212521, Params tensor([1.5735, 0.0713])\n",
      "Epoch 978, Loss 45.193680, Params tensor([1.5740, 0.0714])\n",
      "Epoch 979, Loss 45.174870, Params tensor([1.5744, 0.0714])\n",
      "Epoch 980, Loss 45.156071, Params tensor([1.5748, 0.0715])\n",
      "Epoch 981, Loss 45.137306, Params tensor([1.5753, 0.0715])\n",
      "Epoch 982, Loss 45.118549, Params tensor([1.5757, 0.0716])\n",
      "Epoch 983, Loss 45.099831, Params tensor([1.5761, 0.0716])\n",
      "Epoch 984, Loss 45.081127, Params tensor([1.5765, 0.0717])\n",
      "Epoch 985, Loss 45.062454, Params tensor([1.5770, 0.0717])\n",
      "Epoch 986, Loss 45.043797, Params tensor([1.5774, 0.0717])\n",
      "Epoch 987, Loss 45.025162, Params tensor([1.5778, 0.0718])\n",
      "Epoch 988, Loss 45.006554, Params tensor([1.5783, 0.0718])\n",
      "Epoch 989, Loss 44.987957, Params tensor([1.5787, 0.0719])\n",
      "Epoch 990, Loss 44.969395, Params tensor([1.5791, 0.0719])\n",
      "Epoch 991, Loss 44.950855, Params tensor([1.5795, 0.0720])\n",
      "Epoch 992, Loss 44.932331, Params tensor([1.5800, 0.0720])\n",
      "Epoch 993, Loss 44.913834, Params tensor([1.5804, 0.0721])\n",
      "Epoch 994, Loss 44.895359, Params tensor([1.5808, 0.0721])\n",
      "Epoch 995, Loss 44.876904, Params tensor([1.5813, 0.0722])\n",
      "Epoch 996, Loss 44.858463, Params tensor([1.5817, 0.0722])\n",
      "Epoch 997, Loss 44.840057, Params tensor([1.5821, 0.0722])\n",
      "Epoch 998, Loss 44.821671, Params tensor([1.5825, 0.0723])\n",
      "Epoch 999, Loss 44.803303, Params tensor([1.5830, 0.0723])\n",
      "Epoch 1000, Loss 44.784958, Params tensor([1.5834, 0.0724])\n",
      "Epoch 1001, Loss 44.766644, Params tensor([1.5838, 0.0724])\n",
      "Epoch 1002, Loss 44.748341, Params tensor([1.5842, 0.0725])\n",
      "Epoch 1003, Loss 44.730057, Params tensor([1.5847, 0.0725])\n",
      "Epoch 1004, Loss 44.711815, Params tensor([1.5851, 0.0726])\n",
      "Epoch 1005, Loss 44.693577, Params tensor([1.5855, 0.0726])\n",
      "Epoch 1006, Loss 44.675369, Params tensor([1.5859, 0.0726])\n",
      "Epoch 1007, Loss 44.657177, Params tensor([1.5864, 0.0727])\n",
      "Epoch 1008, Loss 44.639011, Params tensor([1.5868, 0.0727])\n",
      "Epoch 1009, Loss 44.620865, Params tensor([1.5872, 0.0728])\n",
      "Epoch 1010, Loss 44.602741, Params tensor([1.5876, 0.0728])\n",
      "Epoch 1011, Loss 44.584641, Params tensor([1.5881, 0.0729])\n",
      "Epoch 1012, Loss 44.566563, Params tensor([1.5885, 0.0729])\n",
      "Epoch 1013, Loss 44.548508, Params tensor([1.5889, 0.0730])\n",
      "Epoch 1014, Loss 44.530472, Params tensor([1.5893, 0.0730])\n",
      "Epoch 1015, Loss 44.512451, Params tensor([1.5897, 0.0730])\n",
      "Epoch 1016, Loss 44.494457, Params tensor([1.5902, 0.0731])\n",
      "Epoch 1017, Loss 44.476486, Params tensor([1.5906, 0.0731])\n",
      "Epoch 1018, Loss 44.458542, Params tensor([1.5910, 0.0732])\n",
      "Epoch 1019, Loss 44.440617, Params tensor([1.5914, 0.0732])\n",
      "Epoch 1020, Loss 44.422710, Params tensor([1.5918, 0.0733])\n",
      "Epoch 1021, Loss 44.404823, Params tensor([1.5923, 0.0733])\n",
      "Epoch 1022, Loss 44.386959, Params tensor([1.5927, 0.0733])\n",
      "Epoch 1023, Loss 44.369125, Params tensor([1.5931, 0.0734])\n",
      "Epoch 1024, Loss 44.351299, Params tensor([1.5935, 0.0734])\n",
      "Epoch 1025, Loss 44.333496, Params tensor([1.5939, 0.0735])\n",
      "Epoch 1026, Loss 44.315723, Params tensor([1.5944, 0.0735])\n",
      "Epoch 1027, Loss 44.297970, Params tensor([1.5948, 0.0736])\n",
      "Epoch 1028, Loss 44.280239, Params tensor([1.5952, 0.0736])\n",
      "Epoch 1029, Loss 44.262516, Params tensor([1.5956, 0.0736])\n",
      "Epoch 1030, Loss 44.244835, Params tensor([1.5960, 0.0737])\n",
      "Epoch 1031, Loss 44.227169, Params tensor([1.5965, 0.0737])\n",
      "Epoch 1032, Loss 44.209518, Params tensor([1.5969, 0.0738])\n",
      "Epoch 1033, Loss 44.191887, Params tensor([1.5973, 0.0738])\n",
      "Epoch 1034, Loss 44.174282, Params tensor([1.5977, 0.0739])\n",
      "Epoch 1035, Loss 44.156693, Params tensor([1.5981, 0.0739])\n",
      "Epoch 1036, Loss 44.139133, Params tensor([1.5985, 0.0739])\n",
      "Epoch 1037, Loss 44.121590, Params tensor([1.5990, 0.0740])\n",
      "Epoch 1038, Loss 44.104073, Params tensor([1.5994, 0.0740])\n",
      "Epoch 1039, Loss 44.086575, Params tensor([1.5998, 0.0741])\n",
      "Epoch 1040, Loss 44.069092, Params tensor([1.6002, 0.0741])\n",
      "Epoch 1041, Loss 44.051636, Params tensor([1.6006, 0.0742])\n",
      "Epoch 1042, Loss 44.034195, Params tensor([1.6010, 0.0742])\n",
      "Epoch 1043, Loss 44.016785, Params tensor([1.6015, 0.0742])\n",
      "Epoch 1044, Loss 43.999386, Params tensor([1.6019, 0.0743])\n",
      "Epoch 1045, Loss 43.982018, Params tensor([1.6023, 0.0743])\n",
      "Epoch 1046, Loss 43.964664, Params tensor([1.6027, 0.0744])\n",
      "Epoch 1047, Loss 43.947323, Params tensor([1.6031, 0.0744])\n",
      "Epoch 1048, Loss 43.930012, Params tensor([1.6035, 0.0745])\n",
      "Epoch 1049, Loss 43.912731, Params tensor([1.6039, 0.0745])\n",
      "Epoch 1050, Loss 43.895462, Params tensor([1.6044, 0.0745])\n",
      "Epoch 1051, Loss 43.878220, Params tensor([1.6048, 0.0746])\n",
      "Epoch 1052, Loss 43.860992, Params tensor([1.6052, 0.0746])\n",
      "Epoch 1053, Loss 43.843777, Params tensor([1.6056, 0.0747])\n",
      "Epoch 1054, Loss 43.826599, Params tensor([1.6060, 0.0747])\n",
      "Epoch 1055, Loss 43.809433, Params tensor([1.6064, 0.0748])\n",
      "Epoch 1056, Loss 43.792294, Params tensor([1.6068, 0.0748])\n",
      "Epoch 1057, Loss 43.775169, Params tensor([1.6072, 0.0748])\n",
      "Epoch 1058, Loss 43.758060, Params tensor([1.6077, 0.0749])\n",
      "Epoch 1059, Loss 43.740982, Params tensor([1.6081, 0.0749])\n",
      "Epoch 1060, Loss 43.723911, Params tensor([1.6085, 0.0750])\n",
      "Epoch 1061, Loss 43.706863, Params tensor([1.6089, 0.0750])\n",
      "Epoch 1062, Loss 43.689850, Params tensor([1.6093, 0.0751])\n",
      "Epoch 1063, Loss 43.672852, Params tensor([1.6097, 0.0751])\n",
      "Epoch 1064, Loss 43.655869, Params tensor([1.6101, 0.0751])\n",
      "Epoch 1065, Loss 43.638912, Params tensor([1.6105, 0.0752])\n",
      "Epoch 1066, Loss 43.621979, Params tensor([1.6109, 0.0752])\n",
      "Epoch 1067, Loss 43.605057, Params tensor([1.6113, 0.0753])\n",
      "Epoch 1068, Loss 43.588161, Params tensor([1.6117, 0.0753])\n",
      "Epoch 1069, Loss 43.571281, Params tensor([1.6122, 0.0753])\n",
      "Epoch 1070, Loss 43.554428, Params tensor([1.6126, 0.0754])\n",
      "Epoch 1071, Loss 43.537590, Params tensor([1.6130, 0.0754])\n",
      "Epoch 1072, Loss 43.520775, Params tensor([1.6134, 0.0755])\n",
      "Epoch 1073, Loss 43.503971, Params tensor([1.6138, 0.0755])\n",
      "Epoch 1074, Loss 43.487202, Params tensor([1.6142, 0.0755])\n",
      "Epoch 1075, Loss 43.470444, Params tensor([1.6146, 0.0756])\n",
      "Epoch 1076, Loss 43.453701, Params tensor([1.6150, 0.0756])\n",
      "Epoch 1077, Loss 43.436996, Params tensor([1.6154, 0.0757])\n",
      "Epoch 1078, Loss 43.420296, Params tensor([1.6158, 0.0757])\n",
      "Epoch 1079, Loss 43.403610, Params tensor([1.6162, 0.0758])\n",
      "Epoch 1080, Loss 43.386959, Params tensor([1.6166, 0.0758])\n",
      "Epoch 1081, Loss 43.370316, Params tensor([1.6170, 0.0758])\n",
      "Epoch 1082, Loss 43.353703, Params tensor([1.6174, 0.0759])\n",
      "Epoch 1083, Loss 43.337112, Params tensor([1.6179, 0.0759])\n",
      "Epoch 1084, Loss 43.320541, Params tensor([1.6183, 0.0760])\n",
      "Epoch 1085, Loss 43.303993, Params tensor([1.6187, 0.0760])\n",
      "Epoch 1086, Loss 43.287460, Params tensor([1.6191, 0.0760])\n",
      "Epoch 1087, Loss 43.270939, Params tensor([1.6195, 0.0761])\n",
      "Epoch 1088, Loss 43.254452, Params tensor([1.6199, 0.0761])\n",
      "Epoch 1089, Loss 43.237980, Params tensor([1.6203, 0.0762])\n",
      "Epoch 1090, Loss 43.221523, Params tensor([1.6207, 0.0762])\n",
      "Epoch 1091, Loss 43.205082, Params tensor([1.6211, 0.0762])\n",
      "Epoch 1092, Loss 43.188675, Params tensor([1.6215, 0.0763])\n",
      "Epoch 1093, Loss 43.172276, Params tensor([1.6219, 0.0763])\n",
      "Epoch 1094, Loss 43.155903, Params tensor([1.6223, 0.0764])\n",
      "Epoch 1095, Loss 43.139538, Params tensor([1.6227, 0.0764])\n",
      "Epoch 1096, Loss 43.123203, Params tensor([1.6231, 0.0764])\n",
      "Epoch 1097, Loss 43.106892, Params tensor([1.6235, 0.0765])\n",
      "Epoch 1098, Loss 43.090603, Params tensor([1.6239, 0.0765])\n",
      "Epoch 1099, Loss 43.074314, Params tensor([1.6243, 0.0766])\n",
      "Epoch 1100, Loss 43.058056, Params tensor([1.6247, 0.0766])\n",
      "Epoch 1101, Loss 43.041824, Params tensor([1.6251, 0.0766])\n",
      "Epoch 1102, Loss 43.025604, Params tensor([1.6255, 0.0767])\n",
      "Epoch 1103, Loss 43.009403, Params tensor([1.6259, 0.0767])\n",
      "Epoch 1104, Loss 42.993225, Params tensor([1.6263, 0.0768])\n",
      "Epoch 1105, Loss 42.977062, Params tensor([1.6267, 0.0768])\n",
      "Epoch 1106, Loss 42.960922, Params tensor([1.6271, 0.0768])\n",
      "Epoch 1107, Loss 42.944801, Params tensor([1.6275, 0.0769])\n",
      "Epoch 1108, Loss 42.928696, Params tensor([1.6279, 0.0769])\n",
      "Epoch 1109, Loss 42.912609, Params tensor([1.6283, 0.0770])\n",
      "Epoch 1110, Loss 42.896557, Params tensor([1.6287, 0.0770])\n",
      "Epoch 1111, Loss 42.880505, Params tensor([1.6291, 0.0770])\n",
      "Epoch 1112, Loss 42.864483, Params tensor([1.6295, 0.0771])\n",
      "Epoch 1113, Loss 42.848484, Params tensor([1.6299, 0.0771])\n",
      "Epoch 1114, Loss 42.832489, Params tensor([1.6303, 0.0772])\n",
      "Epoch 1115, Loss 42.816532, Params tensor([1.6307, 0.0772])\n",
      "Epoch 1116, Loss 42.800579, Params tensor([1.6311, 0.0772])\n",
      "Epoch 1117, Loss 42.784653, Params tensor([1.6315, 0.0773])\n",
      "Epoch 1118, Loss 42.768742, Params tensor([1.6319, 0.0773])\n",
      "Epoch 1119, Loss 42.752853, Params tensor([1.6323, 0.0774])\n",
      "Epoch 1120, Loss 42.736984, Params tensor([1.6327, 0.0774])\n",
      "Epoch 1121, Loss 42.721127, Params tensor([1.6331, 0.0774])\n",
      "Epoch 1122, Loss 42.705296, Params tensor([1.6335, 0.0775])\n",
      "Epoch 1123, Loss 42.689484, Params tensor([1.6339, 0.0775])\n",
      "Epoch 1124, Loss 42.673691, Params tensor([1.6343, 0.0776])\n",
      "Epoch 1125, Loss 42.657917, Params tensor([1.6346, 0.0776])\n",
      "Epoch 1126, Loss 42.642162, Params tensor([1.6350, 0.0776])\n",
      "Epoch 1127, Loss 42.626423, Params tensor([1.6354, 0.0777])\n",
      "Epoch 1128, Loss 42.610706, Params tensor([1.6358, 0.0777])\n",
      "Epoch 1129, Loss 42.595009, Params tensor([1.6362, 0.0778])\n",
      "Epoch 1130, Loss 42.579327, Params tensor([1.6366, 0.0778])\n",
      "Epoch 1131, Loss 42.563663, Params tensor([1.6370, 0.0778])\n",
      "Epoch 1132, Loss 42.548027, Params tensor([1.6374, 0.0779])\n",
      "Epoch 1133, Loss 42.532406, Params tensor([1.6378, 0.0779])\n",
      "Epoch 1134, Loss 42.516800, Params tensor([1.6382, 0.0780])\n",
      "Epoch 1135, Loss 42.501213, Params tensor([1.6386, 0.0780])\n",
      "Epoch 1136, Loss 42.485653, Params tensor([1.6390, 0.0780])\n",
      "Epoch 1137, Loss 42.470100, Params tensor([1.6394, 0.0781])\n",
      "Epoch 1138, Loss 42.454575, Params tensor([1.6398, 0.0781])\n",
      "Epoch 1139, Loss 42.439060, Params tensor([1.6402, 0.0781])\n",
      "Epoch 1140, Loss 42.423580, Params tensor([1.6405, 0.0782])\n",
      "Epoch 1141, Loss 42.408100, Params tensor([1.6409, 0.0782])\n",
      "Epoch 1142, Loss 42.392654, Params tensor([1.6413, 0.0783])\n",
      "Epoch 1143, Loss 42.377220, Params tensor([1.6417, 0.0783])\n",
      "Epoch 1144, Loss 42.361790, Params tensor([1.6421, 0.0783])\n",
      "Epoch 1145, Loss 42.346390, Params tensor([1.6425, 0.0784])\n",
      "Epoch 1146, Loss 42.331013, Params tensor([1.6429, 0.0784])\n",
      "Epoch 1147, Loss 42.315647, Params tensor([1.6433, 0.0785])\n",
      "Epoch 1148, Loss 42.300308, Params tensor([1.6437, 0.0785])\n",
      "Epoch 1149, Loss 42.284977, Params tensor([1.6441, 0.0785])\n",
      "Epoch 1150, Loss 42.269672, Params tensor([1.6444, 0.0786])\n",
      "Epoch 1151, Loss 42.254379, Params tensor([1.6448, 0.0786])\n",
      "Epoch 1152, Loss 42.239120, Params tensor([1.6452, 0.0786])\n",
      "Epoch 1153, Loss 42.223862, Params tensor([1.6456, 0.0787])\n",
      "Epoch 1154, Loss 42.208630, Params tensor([1.6460, 0.0787])\n",
      "Epoch 1155, Loss 42.193409, Params tensor([1.6464, 0.0788])\n",
      "Epoch 1156, Loss 42.178219, Params tensor([1.6468, 0.0788])\n",
      "Epoch 1157, Loss 42.163040, Params tensor([1.6472, 0.0788])\n",
      "Epoch 1158, Loss 42.147884, Params tensor([1.6476, 0.0789])\n",
      "Epoch 1159, Loss 42.132744, Params tensor([1.6479, 0.0789])\n",
      "Epoch 1160, Loss 42.117619, Params tensor([1.6483, 0.0789])\n",
      "Epoch 1161, Loss 42.102524, Params tensor([1.6487, 0.0790])\n",
      "Epoch 1162, Loss 42.087433, Params tensor([1.6491, 0.0790])\n",
      "Epoch 1163, Loss 42.072369, Params tensor([1.6495, 0.0791])\n",
      "Epoch 1164, Loss 42.057308, Params tensor([1.6499, 0.0791])\n",
      "Epoch 1165, Loss 42.042282, Params tensor([1.6503, 0.0791])\n",
      "Epoch 1166, Loss 42.027267, Params tensor([1.6506, 0.0792])\n",
      "Epoch 1167, Loss 42.012264, Params tensor([1.6510, 0.0792])\n",
      "Epoch 1168, Loss 41.997288, Params tensor([1.6514, 0.0792])\n",
      "Epoch 1169, Loss 41.982327, Params tensor([1.6518, 0.0793])\n",
      "Epoch 1170, Loss 41.967392, Params tensor([1.6522, 0.0793])\n",
      "Epoch 1171, Loss 41.952457, Params tensor([1.6526, 0.0794])\n",
      "Epoch 1172, Loss 41.937561, Params tensor([1.6530, 0.0794])\n",
      "Epoch 1173, Loss 41.922672, Params tensor([1.6533, 0.0794])\n",
      "Epoch 1174, Loss 41.907803, Params tensor([1.6537, 0.0795])\n",
      "Epoch 1175, Loss 41.892952, Params tensor([1.6541, 0.0795])\n",
      "Epoch 1176, Loss 41.878120, Params tensor([1.6545, 0.0795])\n",
      "Epoch 1177, Loss 41.863308, Params tensor([1.6549, 0.0796])\n",
      "Epoch 1178, Loss 41.848507, Params tensor([1.6553, 0.0796])\n",
      "Epoch 1179, Loss 41.833725, Params tensor([1.6556, 0.0797])\n",
      "Epoch 1180, Loss 41.818966, Params tensor([1.6560, 0.0797])\n",
      "Epoch 1181, Loss 41.804222, Params tensor([1.6564, 0.0797])\n",
      "Epoch 1182, Loss 41.789490, Params tensor([1.6568, 0.0798])\n",
      "Epoch 1183, Loss 41.774780, Params tensor([1.6572, 0.0798])\n",
      "Epoch 1184, Loss 41.760086, Params tensor([1.6575, 0.0798])\n",
      "Epoch 1185, Loss 41.745415, Params tensor([1.6579, 0.0799])\n",
      "Epoch 1186, Loss 41.730755, Params tensor([1.6583, 0.0799])\n",
      "Epoch 1187, Loss 41.716122, Params tensor([1.6587, 0.0799])\n",
      "Epoch 1188, Loss 41.701504, Params tensor([1.6591, 0.0800])\n",
      "Epoch 1189, Loss 41.686897, Params tensor([1.6594, 0.0800])\n",
      "Epoch 1190, Loss 41.672314, Params tensor([1.6598, 0.0801])\n",
      "Epoch 1191, Loss 41.657753, Params tensor([1.6602, 0.0801])\n",
      "Epoch 1192, Loss 41.643192, Params tensor([1.6606, 0.0801])\n",
      "Epoch 1193, Loss 41.628658, Params tensor([1.6610, 0.0802])\n",
      "Epoch 1194, Loss 41.614143, Params tensor([1.6613, 0.0802])\n",
      "Epoch 1195, Loss 41.599648, Params tensor([1.6617, 0.0802])\n",
      "Epoch 1196, Loss 41.585167, Params tensor([1.6621, 0.0803])\n",
      "Epoch 1197, Loss 41.570705, Params tensor([1.6625, 0.0803])\n",
      "Epoch 1198, Loss 41.556263, Params tensor([1.6629, 0.0803])\n",
      "Epoch 1199, Loss 41.541836, Params tensor([1.6632, 0.0804])\n",
      "Epoch 1200, Loss 41.527424, Params tensor([1.6636, 0.0804])\n",
      "Epoch 1201, Loss 41.513031, Params tensor([1.6640, 0.0805])\n",
      "Epoch 1202, Loss 41.498653, Params tensor([1.6644, 0.0805])\n",
      "Epoch 1203, Loss 41.484291, Params tensor([1.6647, 0.0805])\n",
      "Epoch 1204, Loss 41.469952, Params tensor([1.6651, 0.0806])\n",
      "Epoch 1205, Loss 41.455631, Params tensor([1.6655, 0.0806])\n",
      "Epoch 1206, Loss 41.441319, Params tensor([1.6659, 0.0806])\n",
      "Epoch 1207, Loss 41.427029, Params tensor([1.6663, 0.0807])\n",
      "Epoch 1208, Loss 41.412762, Params tensor([1.6666, 0.0807])\n",
      "Epoch 1209, Loss 41.398510, Params tensor([1.6670, 0.0807])\n",
      "Epoch 1210, Loss 41.384274, Params tensor([1.6674, 0.0808])\n",
      "Epoch 1211, Loss 41.370041, Params tensor([1.6678, 0.0808])\n",
      "Epoch 1212, Loss 41.355839, Params tensor([1.6681, 0.0808])\n",
      "Epoch 1213, Loss 41.341656, Params tensor([1.6685, 0.0809])\n",
      "Epoch 1214, Loss 41.327480, Params tensor([1.6689, 0.0809])\n",
      "Epoch 1215, Loss 41.313335, Params tensor([1.6693, 0.0810])\n",
      "Epoch 1216, Loss 41.299206, Params tensor([1.6696, 0.0810])\n",
      "Epoch 1217, Loss 41.285084, Params tensor([1.6700, 0.0810])\n",
      "Epoch 1218, Loss 41.270985, Params tensor([1.6704, 0.0811])\n",
      "Epoch 1219, Loss 41.256897, Params tensor([1.6707, 0.0811])\n",
      "Epoch 1220, Loss 41.242825, Params tensor([1.6711, 0.0811])\n",
      "Epoch 1221, Loss 41.228775, Params tensor([1.6715, 0.0812])\n",
      "Epoch 1222, Loss 41.214741, Params tensor([1.6719, 0.0812])\n",
      "Epoch 1223, Loss 41.200729, Params tensor([1.6722, 0.0812])\n",
      "Epoch 1224, Loss 41.186733, Params tensor([1.6726, 0.0813])\n",
      "Epoch 1225, Loss 41.172745, Params tensor([1.6730, 0.0813])\n",
      "Epoch 1226, Loss 41.158775, Params tensor([1.6734, 0.0813])\n",
      "Epoch 1227, Loss 41.144821, Params tensor([1.6737, 0.0814])\n",
      "Epoch 1228, Loss 41.130894, Params tensor([1.6741, 0.0814])\n",
      "Epoch 1229, Loss 41.116978, Params tensor([1.6745, 0.0814])\n",
      "Epoch 1230, Loss 41.103081, Params tensor([1.6748, 0.0815])\n",
      "Epoch 1231, Loss 41.089199, Params tensor([1.6752, 0.0815])\n",
      "Epoch 1232, Loss 41.075333, Params tensor([1.6756, 0.0816])\n",
      "Epoch 1233, Loss 41.061489, Params tensor([1.6760, 0.0816])\n",
      "Epoch 1234, Loss 41.047653, Params tensor([1.6763, 0.0816])\n",
      "Epoch 1235, Loss 41.033840, Params tensor([1.6767, 0.0817])\n",
      "Epoch 1236, Loss 41.020035, Params tensor([1.6771, 0.0817])\n",
      "Epoch 1237, Loss 41.006260, Params tensor([1.6774, 0.0817])\n",
      "Epoch 1238, Loss 40.992493, Params tensor([1.6778, 0.0818])\n",
      "Epoch 1239, Loss 40.978752, Params tensor([1.6782, 0.0818])\n",
      "Epoch 1240, Loss 40.965008, Params tensor([1.6785, 0.0818])\n",
      "Epoch 1241, Loss 40.951290, Params tensor([1.6789, 0.0819])\n",
      "Epoch 1242, Loss 40.937595, Params tensor([1.6793, 0.0819])\n",
      "Epoch 1243, Loss 40.923916, Params tensor([1.6796, 0.0819])\n",
      "Epoch 1244, Loss 40.910244, Params tensor([1.6800, 0.0820])\n",
      "Epoch 1245, Loss 40.896595, Params tensor([1.6804, 0.0820])\n",
      "Epoch 1246, Loss 40.882969, Params tensor([1.6807, 0.0820])\n",
      "Epoch 1247, Loss 40.869350, Params tensor([1.6811, 0.0821])\n",
      "Epoch 1248, Loss 40.855747, Params tensor([1.6815, 0.0821])\n",
      "Epoch 1249, Loss 40.842159, Params tensor([1.6818, 0.0821])\n",
      "Epoch 1250, Loss 40.828590, Params tensor([1.6822, 0.0822])\n",
      "Epoch 1251, Loss 40.815044, Params tensor([1.6826, 0.0822])\n",
      "Epoch 1252, Loss 40.801510, Params tensor([1.6829, 0.0822])\n",
      "Epoch 1253, Loss 40.787987, Params tensor([1.6833, 0.0823])\n",
      "Epoch 1254, Loss 40.774479, Params tensor([1.6837, 0.0823])\n",
      "Epoch 1255, Loss 40.760998, Params tensor([1.6840, 0.0823])\n",
      "Epoch 1256, Loss 40.747524, Params tensor([1.6844, 0.0824])\n",
      "Epoch 1257, Loss 40.734074, Params tensor([1.6848, 0.0824])\n",
      "Epoch 1258, Loss 40.720638, Params tensor([1.6851, 0.0824])\n",
      "Epoch 1259, Loss 40.707214, Params tensor([1.6855, 0.0825])\n",
      "Epoch 1260, Loss 40.693806, Params tensor([1.6859, 0.0825])\n",
      "Epoch 1261, Loss 40.680420, Params tensor([1.6862, 0.0825])\n",
      "Epoch 1262, Loss 40.667049, Params tensor([1.6866, 0.0826])\n",
      "Epoch 1263, Loss 40.653683, Params tensor([1.6870, 0.0826])\n",
      "Epoch 1264, Loss 40.640354, Params tensor([1.6873, 0.0826])\n",
      "Epoch 1265, Loss 40.627026, Params tensor([1.6877, 0.0827])\n",
      "Epoch 1266, Loss 40.613716, Params tensor([1.6881, 0.0827])\n",
      "Epoch 1267, Loss 40.600422, Params tensor([1.6884, 0.0827])\n",
      "Epoch 1268, Loss 40.587151, Params tensor([1.6888, 0.0828])\n",
      "Epoch 1269, Loss 40.573887, Params tensor([1.6891, 0.0828])\n",
      "Epoch 1270, Loss 40.560646, Params tensor([1.6895, 0.0828])\n",
      "Epoch 1271, Loss 40.547413, Params tensor([1.6899, 0.0829])\n",
      "Epoch 1272, Loss 40.534203, Params tensor([1.6902, 0.0829])\n",
      "Epoch 1273, Loss 40.521000, Params tensor([1.6906, 0.0829])\n",
      "Epoch 1274, Loss 40.507824, Params tensor([1.6909, 0.0830])\n",
      "Epoch 1275, Loss 40.494656, Params tensor([1.6913, 0.0830])\n",
      "Epoch 1276, Loss 40.481506, Params tensor([1.6917, 0.0830])\n",
      "Epoch 1277, Loss 40.468380, Params tensor([1.6920, 0.0831])\n",
      "Epoch 1278, Loss 40.455257, Params tensor([1.6924, 0.0831])\n",
      "Epoch 1279, Loss 40.442154, Params tensor([1.6928, 0.0831])\n",
      "Epoch 1280, Loss 40.429070, Params tensor([1.6931, 0.0832])\n",
      "Epoch 1281, Loss 40.415997, Params tensor([1.6935, 0.0832])\n",
      "Epoch 1282, Loss 40.402943, Params tensor([1.6938, 0.0832])\n",
      "Epoch 1283, Loss 40.389904, Params tensor([1.6942, 0.0833])\n",
      "Epoch 1284, Loss 40.376888, Params tensor([1.6946, 0.0833])\n",
      "Epoch 1285, Loss 40.363876, Params tensor([1.6949, 0.0833])\n",
      "Epoch 1286, Loss 40.350876, Params tensor([1.6953, 0.0834])\n",
      "Epoch 1287, Loss 40.337902, Params tensor([1.6956, 0.0834])\n",
      "Epoch 1288, Loss 40.324944, Params tensor([1.6960, 0.0834])\n",
      "Epoch 1289, Loss 40.312000, Params tensor([1.6963, 0.0835])\n",
      "Epoch 1290, Loss 40.299068, Params tensor([1.6967, 0.0835])\n",
      "Epoch 1291, Loss 40.286160, Params tensor([1.6971, 0.0835])\n",
      "Epoch 1292, Loss 40.273254, Params tensor([1.6974, 0.0836])\n",
      "Epoch 1293, Loss 40.260372, Params tensor([1.6978, 0.0836])\n",
      "Epoch 1294, Loss 40.247501, Params tensor([1.6981, 0.0836])\n",
      "Epoch 1295, Loss 40.234653, Params tensor([1.6985, 0.0837])\n",
      "Epoch 1296, Loss 40.221817, Params tensor([1.6988, 0.0837])\n",
      "Epoch 1297, Loss 40.208988, Params tensor([1.6992, 0.0837])\n",
      "Epoch 1298, Loss 40.196190, Params tensor([1.6996, 0.0838])\n",
      "Epoch 1299, Loss 40.183403, Params tensor([1.6999, 0.0838])\n",
      "Epoch 1300, Loss 40.170628, Params tensor([1.7003, 0.0838])\n",
      "Epoch 1301, Loss 40.157867, Params tensor([1.7006, 0.0839])\n",
      "Epoch 1302, Loss 40.145126, Params tensor([1.7010, 0.0839])\n",
      "Epoch 1303, Loss 40.132401, Params tensor([1.7013, 0.0839])\n",
      "Epoch 1304, Loss 40.119682, Params tensor([1.7017, 0.0840])\n",
      "Epoch 1305, Loss 40.106983, Params tensor([1.7020, 0.0840])\n",
      "Epoch 1306, Loss 40.094303, Params tensor([1.7024, 0.0840])\n",
      "Epoch 1307, Loss 40.081631, Params tensor([1.7028, 0.0841])\n",
      "Epoch 1308, Loss 40.068981, Params tensor([1.7031, 0.0841])\n",
      "Epoch 1309, Loss 40.056351, Params tensor([1.7035, 0.0841])\n",
      "Epoch 1310, Loss 40.043720, Params tensor([1.7038, 0.0841])\n",
      "Epoch 1311, Loss 40.031113, Params tensor([1.7042, 0.0842])\n",
      "Epoch 1312, Loss 40.018528, Params tensor([1.7045, 0.0842])\n",
      "Epoch 1313, Loss 40.005955, Params tensor([1.7049, 0.0842])\n",
      "Epoch 1314, Loss 39.993385, Params tensor([1.7052, 0.0843])\n",
      "Epoch 1315, Loss 39.980839, Params tensor([1.7056, 0.0843])\n",
      "Epoch 1316, Loss 39.968311, Params tensor([1.7059, 0.0843])\n",
      "Epoch 1317, Loss 39.955795, Params tensor([1.7063, 0.0844])\n",
      "Epoch 1318, Loss 39.943302, Params tensor([1.7066, 0.0844])\n",
      "Epoch 1319, Loss 39.930817, Params tensor([1.7070, 0.0844])\n",
      "Epoch 1320, Loss 39.918343, Params tensor([1.7073, 0.0845])\n",
      "Epoch 1321, Loss 39.905888, Params tensor([1.7077, 0.0845])\n",
      "Epoch 1322, Loss 39.893448, Params tensor([1.7080, 0.0845])\n",
      "Epoch 1323, Loss 39.881023, Params tensor([1.7084, 0.0846])\n",
      "Epoch 1324, Loss 39.868610, Params tensor([1.7087, 0.0846])\n",
      "Epoch 1325, Loss 39.856216, Params tensor([1.7091, 0.0846])\n",
      "Epoch 1326, Loss 39.843838, Params tensor([1.7094, 0.0847])\n",
      "Epoch 1327, Loss 39.831470, Params tensor([1.7098, 0.0847])\n",
      "Epoch 1328, Loss 39.819118, Params tensor([1.7101, 0.0847])\n",
      "Epoch 1329, Loss 39.806782, Params tensor([1.7105, 0.0847])\n",
      "Epoch 1330, Loss 39.794460, Params tensor([1.7108, 0.0848])\n",
      "Epoch 1331, Loss 39.782154, Params tensor([1.7112, 0.0848])\n",
      "Epoch 1332, Loss 39.769863, Params tensor([1.7115, 0.0848])\n",
      "Epoch 1333, Loss 39.757587, Params tensor([1.7119, 0.0849])\n",
      "Epoch 1334, Loss 39.745327, Params tensor([1.7122, 0.0849])\n",
      "Epoch 1335, Loss 39.733078, Params tensor([1.7126, 0.0849])\n",
      "Epoch 1336, Loss 39.720837, Params tensor([1.7129, 0.0850])\n",
      "Epoch 1337, Loss 39.708622, Params tensor([1.7133, 0.0850])\n",
      "Epoch 1338, Loss 39.696426, Params tensor([1.7136, 0.0850])\n",
      "Epoch 1339, Loss 39.684231, Params tensor([1.7140, 0.0851])\n",
      "Epoch 1340, Loss 39.672058, Params tensor([1.7143, 0.0851])\n",
      "Epoch 1341, Loss 39.659901, Params tensor([1.7147, 0.0851])\n",
      "Epoch 1342, Loss 39.647762, Params tensor([1.7150, 0.0851])\n",
      "Epoch 1343, Loss 39.635632, Params tensor([1.7154, 0.0852])\n",
      "Epoch 1344, Loss 39.623508, Params tensor([1.7157, 0.0852])\n",
      "Epoch 1345, Loss 39.611412, Params tensor([1.7161, 0.0852])\n",
      "Epoch 1346, Loss 39.599323, Params tensor([1.7164, 0.0853])\n",
      "Epoch 1347, Loss 39.587254, Params tensor([1.7168, 0.0853])\n",
      "Epoch 1348, Loss 39.575199, Params tensor([1.7171, 0.0853])\n",
      "Epoch 1349, Loss 39.563156, Params tensor([1.7174, 0.0854])\n",
      "Epoch 1350, Loss 39.551132, Params tensor([1.7178, 0.0854])\n",
      "Epoch 1351, Loss 39.539112, Params tensor([1.7181, 0.0854])\n",
      "Epoch 1352, Loss 39.527115, Params tensor([1.7185, 0.0855])\n",
      "Epoch 1353, Loss 39.515133, Params tensor([1.7188, 0.0855])\n",
      "Epoch 1354, Loss 39.503155, Params tensor([1.7192, 0.0855])\n",
      "Epoch 1355, Loss 39.491203, Params tensor([1.7195, 0.0855])\n",
      "Epoch 1356, Loss 39.479263, Params tensor([1.7199, 0.0856])\n",
      "Epoch 1357, Loss 39.467342, Params tensor([1.7202, 0.0856])\n",
      "Epoch 1358, Loss 39.455425, Params tensor([1.7205, 0.0856])\n",
      "Epoch 1359, Loss 39.443527, Params tensor([1.7209, 0.0857])\n",
      "Epoch 1360, Loss 39.431641, Params tensor([1.7212, 0.0857])\n",
      "Epoch 1361, Loss 39.419769, Params tensor([1.7216, 0.0857])\n",
      "Epoch 1362, Loss 39.407909, Params tensor([1.7219, 0.0858])\n",
      "Epoch 1363, Loss 39.396072, Params tensor([1.7223, 0.0858])\n",
      "Epoch 1364, Loss 39.384251, Params tensor([1.7226, 0.0858])\n",
      "Epoch 1365, Loss 39.372437, Params tensor([1.7229, 0.0858])\n",
      "Epoch 1366, Loss 39.360634, Params tensor([1.7233, 0.0859])\n",
      "Epoch 1367, Loss 39.348850, Params tensor([1.7236, 0.0859])\n",
      "Epoch 1368, Loss 39.337074, Params tensor([1.7240, 0.0859])\n",
      "Epoch 1369, Loss 39.325321, Params tensor([1.7243, 0.0860])\n",
      "Epoch 1370, Loss 39.313580, Params tensor([1.7247, 0.0860])\n",
      "Epoch 1371, Loss 39.301857, Params tensor([1.7250, 0.0860])\n",
      "Epoch 1372, Loss 39.290146, Params tensor([1.7253, 0.0861])\n",
      "Epoch 1373, Loss 39.278439, Params tensor([1.7257, 0.0861])\n",
      "Epoch 1374, Loss 39.266754, Params tensor([1.7260, 0.0861])\n",
      "Epoch 1375, Loss 39.255081, Params tensor([1.7264, 0.0861])\n",
      "Epoch 1376, Loss 39.243427, Params tensor([1.7267, 0.0862])\n",
      "Epoch 1377, Loss 39.231781, Params tensor([1.7270, 0.0862])\n",
      "Epoch 1378, Loss 39.220154, Params tensor([1.7274, 0.0862])\n",
      "Epoch 1379, Loss 39.208542, Params tensor([1.7277, 0.0863])\n",
      "Epoch 1380, Loss 39.196941, Params tensor([1.7281, 0.0863])\n",
      "Epoch 1381, Loss 39.185352, Params tensor([1.7284, 0.0863])\n",
      "Epoch 1382, Loss 39.173779, Params tensor([1.7287, 0.0863])\n",
      "Epoch 1383, Loss 39.162216, Params tensor([1.7291, 0.0864])\n",
      "Epoch 1384, Loss 39.150677, Params tensor([1.7294, 0.0864])\n",
      "Epoch 1385, Loss 39.139141, Params tensor([1.7297, 0.0864])\n",
      "Epoch 1386, Loss 39.127621, Params tensor([1.7301, 0.0865])\n",
      "Epoch 1387, Loss 39.116123, Params tensor([1.7304, 0.0865])\n",
      "Epoch 1388, Loss 39.104633, Params tensor([1.7308, 0.0865])\n",
      "Epoch 1389, Loss 39.093151, Params tensor([1.7311, 0.0865])\n",
      "Epoch 1390, Loss 39.081692, Params tensor([1.7314, 0.0866])\n",
      "Epoch 1391, Loss 39.070248, Params tensor([1.7318, 0.0866])\n",
      "Epoch 1392, Loss 39.058811, Params tensor([1.7321, 0.0866])\n",
      "Epoch 1393, Loss 39.047394, Params tensor([1.7324, 0.0867])\n",
      "Epoch 1394, Loss 39.035984, Params tensor([1.7328, 0.0867])\n",
      "Epoch 1395, Loss 39.024586, Params tensor([1.7331, 0.0867])\n",
      "Epoch 1396, Loss 39.013206, Params tensor([1.7335, 0.0868])\n",
      "Epoch 1397, Loss 39.001839, Params tensor([1.7338, 0.0868])\n",
      "Epoch 1398, Loss 38.990482, Params tensor([1.7341, 0.0868])\n",
      "Epoch 1399, Loss 38.979149, Params tensor([1.7345, 0.0868])\n",
      "Epoch 1400, Loss 38.967823, Params tensor([1.7348, 0.0869])\n",
      "Epoch 1401, Loss 38.956509, Params tensor([1.7351, 0.0869])\n",
      "Epoch 1402, Loss 38.945210, Params tensor([1.7355, 0.0869])\n",
      "Epoch 1403, Loss 38.933926, Params tensor([1.7358, 0.0870])\n",
      "Epoch 1404, Loss 38.922653, Params tensor([1.7361, 0.0870])\n",
      "Epoch 1405, Loss 38.911392, Params tensor([1.7365, 0.0870])\n",
      "Epoch 1406, Loss 38.900150, Params tensor([1.7368, 0.0870])\n",
      "Epoch 1407, Loss 38.888927, Params tensor([1.7371, 0.0871])\n",
      "Epoch 1408, Loss 38.877708, Params tensor([1.7375, 0.0871])\n",
      "Epoch 1409, Loss 38.866512, Params tensor([1.7378, 0.0871])\n",
      "Epoch 1410, Loss 38.855316, Params tensor([1.7381, 0.0871])\n",
      "Epoch 1411, Loss 38.844139, Params tensor([1.7385, 0.0872])\n",
      "Epoch 1412, Loss 38.832981, Params tensor([1.7388, 0.0872])\n",
      "Epoch 1413, Loss 38.821823, Params tensor([1.7391, 0.0872])\n",
      "Epoch 1414, Loss 38.810696, Params tensor([1.7395, 0.0873])\n",
      "Epoch 1415, Loss 38.799568, Params tensor([1.7398, 0.0873])\n",
      "Epoch 1416, Loss 38.788464, Params tensor([1.7401, 0.0873])\n",
      "Epoch 1417, Loss 38.777370, Params tensor([1.7405, 0.0873])\n",
      "Epoch 1418, Loss 38.766281, Params tensor([1.7408, 0.0874])\n",
      "Epoch 1419, Loss 38.755215, Params tensor([1.7411, 0.0874])\n",
      "Epoch 1420, Loss 38.744164, Params tensor([1.7415, 0.0874])\n",
      "Epoch 1421, Loss 38.733116, Params tensor([1.7418, 0.0875])\n",
      "Epoch 1422, Loss 38.722080, Params tensor([1.7421, 0.0875])\n",
      "Epoch 1423, Loss 38.711067, Params tensor([1.7425, 0.0875])\n",
      "Epoch 1424, Loss 38.700069, Params tensor([1.7428, 0.0875])\n",
      "Epoch 1425, Loss 38.689079, Params tensor([1.7431, 0.0876])\n",
      "Epoch 1426, Loss 38.678097, Params tensor([1.7434, 0.0876])\n",
      "Epoch 1427, Loss 38.667137, Params tensor([1.7438, 0.0876])\n",
      "Epoch 1428, Loss 38.656185, Params tensor([1.7441, 0.0877])\n",
      "Epoch 1429, Loss 38.645248, Params tensor([1.7444, 0.0877])\n",
      "Epoch 1430, Loss 38.634323, Params tensor([1.7448, 0.0877])\n",
      "Epoch 1431, Loss 38.623417, Params tensor([1.7451, 0.0877])\n",
      "Epoch 1432, Loss 38.612514, Params tensor([1.7454, 0.0878])\n",
      "Epoch 1433, Loss 38.601635, Params tensor([1.7457, 0.0878])\n",
      "Epoch 1434, Loss 38.590763, Params tensor([1.7461, 0.0878])\n",
      "Epoch 1435, Loss 38.579899, Params tensor([1.7464, 0.0878])\n",
      "Epoch 1436, Loss 38.569057, Params tensor([1.7467, 0.0879])\n",
      "Epoch 1437, Loss 38.558228, Params tensor([1.7471, 0.0879])\n",
      "Epoch 1438, Loss 38.547409, Params tensor([1.7474, 0.0879])\n",
      "Epoch 1439, Loss 38.536606, Params tensor([1.7477, 0.0880])\n",
      "Epoch 1440, Loss 38.525806, Params tensor([1.7480, 0.0880])\n",
      "Epoch 1441, Loss 38.515030, Params tensor([1.7484, 0.0880])\n",
      "Epoch 1442, Loss 38.504261, Params tensor([1.7487, 0.0880])\n",
      "Epoch 1443, Loss 38.493507, Params tensor([1.7490, 0.0881])\n",
      "Epoch 1444, Loss 38.482765, Params tensor([1.7493, 0.0881])\n",
      "Epoch 1445, Loss 38.472042, Params tensor([1.7497, 0.0881])\n",
      "Epoch 1446, Loss 38.461323, Params tensor([1.7500, 0.0881])\n",
      "Epoch 1447, Loss 38.450619, Params tensor([1.7503, 0.0882])\n",
      "Epoch 1448, Loss 38.439930, Params tensor([1.7507, 0.0882])\n",
      "Epoch 1449, Loss 38.429256, Params tensor([1.7510, 0.0882])\n",
      "Epoch 1450, Loss 38.418594, Params tensor([1.7513, 0.0882])\n",
      "Epoch 1451, Loss 38.407944, Params tensor([1.7516, 0.0883])\n",
      "Epoch 1452, Loss 38.397301, Params tensor([1.7520, 0.0883])\n",
      "Epoch 1453, Loss 38.386669, Params tensor([1.7523, 0.0883])\n",
      "Epoch 1454, Loss 38.376060, Params tensor([1.7526, 0.0884])\n",
      "Epoch 1455, Loss 38.365459, Params tensor([1.7529, 0.0884])\n",
      "Epoch 1456, Loss 38.354874, Params tensor([1.7532, 0.0884])\n",
      "Epoch 1457, Loss 38.344303, Params tensor([1.7536, 0.0884])\n",
      "Epoch 1458, Loss 38.333744, Params tensor([1.7539, 0.0885])\n",
      "Epoch 1459, Loss 38.323193, Params tensor([1.7542, 0.0885])\n",
      "Epoch 1460, Loss 38.312656, Params tensor([1.7545, 0.0885])\n",
      "Epoch 1461, Loss 38.302128, Params tensor([1.7549, 0.0885])\n",
      "Epoch 1462, Loss 38.291618, Params tensor([1.7552, 0.0886])\n",
      "Epoch 1463, Loss 38.281124, Params tensor([1.7555, 0.0886])\n",
      "Epoch 1464, Loss 38.270638, Params tensor([1.7558, 0.0886])\n",
      "Epoch 1465, Loss 38.260159, Params tensor([1.7562, 0.0886])\n",
      "Epoch 1466, Loss 38.249702, Params tensor([1.7565, 0.0887])\n",
      "Epoch 1467, Loss 38.239246, Params tensor([1.7568, 0.0887])\n",
      "Epoch 1468, Loss 38.228817, Params tensor([1.7571, 0.0887])\n",
      "Epoch 1469, Loss 38.218388, Params tensor([1.7574, 0.0888])\n",
      "Epoch 1470, Loss 38.207985, Params tensor([1.7578, 0.0888])\n",
      "Epoch 1471, Loss 38.197586, Params tensor([1.7581, 0.0888])\n",
      "Epoch 1472, Loss 38.187202, Params tensor([1.7584, 0.0888])\n",
      "Epoch 1473, Loss 38.176830, Params tensor([1.7587, 0.0889])\n",
      "Epoch 1474, Loss 38.166466, Params tensor([1.7591, 0.0889])\n",
      "Epoch 1475, Loss 38.156120, Params tensor([1.7594, 0.0889])\n",
      "Epoch 1476, Loss 38.145786, Params tensor([1.7597, 0.0889])\n",
      "Epoch 1477, Loss 38.135464, Params tensor([1.7600, 0.0890])\n",
      "Epoch 1478, Loss 38.125149, Params tensor([1.7603, 0.0890])\n",
      "Epoch 1479, Loss 38.114845, Params tensor([1.7607, 0.0890])\n",
      "Epoch 1480, Loss 38.104565, Params tensor([1.7610, 0.0890])\n",
      "Epoch 1481, Loss 38.094296, Params tensor([1.7613, 0.0891])\n",
      "Epoch 1482, Loss 38.084030, Params tensor([1.7616, 0.0891])\n",
      "Epoch 1483, Loss 38.073784, Params tensor([1.7619, 0.0891])\n",
      "Epoch 1484, Loss 38.063545, Params tensor([1.7622, 0.0891])\n",
      "Epoch 1485, Loss 38.053318, Params tensor([1.7626, 0.0892])\n",
      "Epoch 1486, Loss 38.043106, Params tensor([1.7629, 0.0892])\n",
      "Epoch 1487, Loss 38.032909, Params tensor([1.7632, 0.0892])\n",
      "Epoch 1488, Loss 38.022724, Params tensor([1.7635, 0.0892])\n",
      "Epoch 1489, Loss 38.012550, Params tensor([1.7638, 0.0893])\n",
      "Epoch 1490, Loss 38.002384, Params tensor([1.7642, 0.0893])\n",
      "Epoch 1491, Loss 37.992233, Params tensor([1.7645, 0.0893])\n",
      "Epoch 1492, Loss 37.982094, Params tensor([1.7648, 0.0893])\n",
      "Epoch 1493, Loss 37.971973, Params tensor([1.7651, 0.0894])\n",
      "Epoch 1494, Loss 37.961853, Params tensor([1.7654, 0.0894])\n",
      "Epoch 1495, Loss 37.951756, Params tensor([1.7657, 0.0894])\n",
      "Epoch 1496, Loss 37.941658, Params tensor([1.7661, 0.0894])\n",
      "Epoch 1497, Loss 37.931583, Params tensor([1.7664, 0.0895])\n",
      "Epoch 1498, Loss 37.921520, Params tensor([1.7667, 0.0895])\n",
      "Epoch 1499, Loss 37.911465, Params tensor([1.7670, 0.0895])\n",
      "Epoch 1500, Loss 37.901424, Params tensor([1.7673, 0.0895])\n",
      "Epoch 1501, Loss 37.891392, Params tensor([1.7676, 0.0896])\n",
      "Epoch 1502, Loss 37.881378, Params tensor([1.7680, 0.0896])\n",
      "Epoch 1503, Loss 37.871376, Params tensor([1.7683, 0.0896])\n",
      "Epoch 1504, Loss 37.861374, Params tensor([1.7686, 0.0896])\n",
      "Epoch 1505, Loss 37.851402, Params tensor([1.7689, 0.0897])\n",
      "Epoch 1506, Loss 37.841427, Params tensor([1.7692, 0.0897])\n",
      "Epoch 1507, Loss 37.831470, Params tensor([1.7695, 0.0897])\n",
      "Epoch 1508, Loss 37.821522, Params tensor([1.7698, 0.0897])\n",
      "Epoch 1509, Loss 37.811588, Params tensor([1.7702, 0.0898])\n",
      "Epoch 1510, Loss 37.801670, Params tensor([1.7705, 0.0898])\n",
      "Epoch 1511, Loss 37.791759, Params tensor([1.7708, 0.0898])\n",
      "Epoch 1512, Loss 37.781857, Params tensor([1.7711, 0.0898])\n",
      "Epoch 1513, Loss 37.771973, Params tensor([1.7714, 0.0899])\n",
      "Epoch 1514, Loss 37.762100, Params tensor([1.7717, 0.0899])\n",
      "Epoch 1515, Loss 37.752235, Params tensor([1.7720, 0.0899])\n",
      "Epoch 1516, Loss 37.742390, Params tensor([1.7723, 0.0899])\n",
      "Epoch 1517, Loss 37.732548, Params tensor([1.7727, 0.0900])\n",
      "Epoch 1518, Loss 37.722721, Params tensor([1.7730, 0.0900])\n",
      "Epoch 1519, Loss 37.712910, Params tensor([1.7733, 0.0900])\n",
      "Epoch 1520, Loss 37.703110, Params tensor([1.7736, 0.0900])\n",
      "Epoch 1521, Loss 37.693314, Params tensor([1.7739, 0.0901])\n",
      "Epoch 1522, Loss 37.683529, Params tensor([1.7742, 0.0901])\n",
      "Epoch 1523, Loss 37.673767, Params tensor([1.7745, 0.0901])\n",
      "Epoch 1524, Loss 37.664009, Params tensor([1.7748, 0.0901])\n",
      "Epoch 1525, Loss 37.654270, Params tensor([1.7752, 0.0902])\n",
      "Epoch 1526, Loss 37.644535, Params tensor([1.7755, 0.0902])\n",
      "Epoch 1527, Loss 37.634815, Params tensor([1.7758, 0.0902])\n",
      "Epoch 1528, Loss 37.625107, Params tensor([1.7761, 0.0902])\n",
      "Epoch 1529, Loss 37.615410, Params tensor([1.7764, 0.0903])\n",
      "Epoch 1530, Loss 37.605721, Params tensor([1.7767, 0.0903])\n",
      "Epoch 1531, Loss 37.596046, Params tensor([1.7770, 0.0903])\n",
      "Epoch 1532, Loss 37.586388, Params tensor([1.7773, 0.0903])\n",
      "Epoch 1533, Loss 37.576729, Params tensor([1.7776, 0.0904])\n",
      "Epoch 1534, Loss 37.567089, Params tensor([1.7779, 0.0904])\n",
      "Epoch 1535, Loss 37.557465, Params tensor([1.7783, 0.0904])\n",
      "Epoch 1536, Loss 37.547848, Params tensor([1.7786, 0.0904])\n",
      "Epoch 1537, Loss 37.538250, Params tensor([1.7789, 0.0905])\n",
      "Epoch 1538, Loss 37.528652, Params tensor([1.7792, 0.0905])\n",
      "Epoch 1539, Loss 37.519073, Params tensor([1.7795, 0.0905])\n",
      "Epoch 1540, Loss 37.509499, Params tensor([1.7798, 0.0905])\n",
      "Epoch 1541, Loss 37.499947, Params tensor([1.7801, 0.0905])\n",
      "Epoch 1542, Loss 37.490395, Params tensor([1.7804, 0.0906])\n",
      "Epoch 1543, Loss 37.480862, Params tensor([1.7807, 0.0906])\n",
      "Epoch 1544, Loss 37.471336, Params tensor([1.7810, 0.0906])\n",
      "Epoch 1545, Loss 37.461819, Params tensor([1.7813, 0.0906])\n",
      "Epoch 1546, Loss 37.452312, Params tensor([1.7816, 0.0907])\n",
      "Epoch 1547, Loss 37.442825, Params tensor([1.7820, 0.0907])\n",
      "Epoch 1548, Loss 37.433353, Params tensor([1.7823, 0.0907])\n",
      "Epoch 1549, Loss 37.423882, Params tensor([1.7826, 0.0907])\n",
      "Epoch 1550, Loss 37.414429, Params tensor([1.7829, 0.0908])\n",
      "Epoch 1551, Loss 37.404984, Params tensor([1.7832, 0.0908])\n",
      "Epoch 1552, Loss 37.395554, Params tensor([1.7835, 0.0908])\n",
      "Epoch 1553, Loss 37.386124, Params tensor([1.7838, 0.0908])\n",
      "Epoch 1554, Loss 37.376720, Params tensor([1.7841, 0.0909])\n",
      "Epoch 1555, Loss 37.367317, Params tensor([1.7844, 0.0909])\n",
      "Epoch 1556, Loss 37.357925, Params tensor([1.7847, 0.0909])\n",
      "Epoch 1557, Loss 37.348545, Params tensor([1.7850, 0.0909])\n",
      "Epoch 1558, Loss 37.339188, Params tensor([1.7853, 0.0909])\n",
      "Epoch 1559, Loss 37.329834, Params tensor([1.7856, 0.0910])\n",
      "Epoch 1560, Loss 37.320488, Params tensor([1.7859, 0.0910])\n",
      "Epoch 1561, Loss 37.311157, Params tensor([1.7862, 0.0910])\n",
      "Epoch 1562, Loss 37.301838, Params tensor([1.7865, 0.0910])\n",
      "Epoch 1563, Loss 37.292526, Params tensor([1.7868, 0.0911])\n",
      "Epoch 1564, Loss 37.283226, Params tensor([1.7871, 0.0911])\n",
      "Epoch 1565, Loss 37.273945, Params tensor([1.7874, 0.0911])\n",
      "Epoch 1566, Loss 37.264668, Params tensor([1.7878, 0.0911])\n",
      "Epoch 1567, Loss 37.255405, Params tensor([1.7881, 0.0912])\n",
      "Epoch 1568, Loss 37.246147, Params tensor([1.7884, 0.0912])\n",
      "Epoch 1569, Loss 37.236912, Params tensor([1.7887, 0.0912])\n",
      "Epoch 1570, Loss 37.227676, Params tensor([1.7890, 0.0912])\n",
      "Epoch 1571, Loss 37.218460, Params tensor([1.7893, 0.0912])\n",
      "Epoch 1572, Loss 37.209251, Params tensor([1.7896, 0.0913])\n",
      "Epoch 1573, Loss 37.200050, Params tensor([1.7899, 0.0913])\n",
      "Epoch 1574, Loss 37.190861, Params tensor([1.7902, 0.0913])\n",
      "Epoch 1575, Loss 37.181686, Params tensor([1.7905, 0.0913])\n",
      "Epoch 1576, Loss 37.172520, Params tensor([1.7908, 0.0914])\n",
      "Epoch 1577, Loss 37.163364, Params tensor([1.7911, 0.0914])\n",
      "Epoch 1578, Loss 37.154224, Params tensor([1.7914, 0.0914])\n",
      "Epoch 1579, Loss 37.145096, Params tensor([1.7917, 0.0914])\n",
      "Epoch 1580, Loss 37.135971, Params tensor([1.7920, 0.0915])\n",
      "Epoch 1581, Loss 37.126865, Params tensor([1.7923, 0.0915])\n",
      "Epoch 1582, Loss 37.117764, Params tensor([1.7926, 0.0915])\n",
      "Epoch 1583, Loss 37.108669, Params tensor([1.7929, 0.0915])\n",
      "Epoch 1584, Loss 37.099594, Params tensor([1.7932, 0.0915])\n",
      "Epoch 1585, Loss 37.090527, Params tensor([1.7935, 0.0916])\n",
      "Epoch 1586, Loss 37.081478, Params tensor([1.7938, 0.0916])\n",
      "Epoch 1587, Loss 37.072430, Params tensor([1.7941, 0.0916])\n",
      "Epoch 1588, Loss 37.063396, Params tensor([1.7944, 0.0916])\n",
      "Epoch 1589, Loss 37.054379, Params tensor([1.7947, 0.0917])\n",
      "Epoch 1590, Loss 37.045353, Params tensor([1.7950, 0.0917])\n",
      "Epoch 1591, Loss 37.036362, Params tensor([1.7953, 0.0917])\n",
      "Epoch 1592, Loss 37.027367, Params tensor([1.7956, 0.0917])\n",
      "Epoch 1593, Loss 37.018387, Params tensor([1.7959, 0.0917])\n",
      "Epoch 1594, Loss 37.009415, Params tensor([1.7962, 0.0918])\n",
      "Epoch 1595, Loss 37.000462, Params tensor([1.7965, 0.0918])\n",
      "Epoch 1596, Loss 36.991512, Params tensor([1.7968, 0.0918])\n",
      "Epoch 1597, Loss 36.982578, Params tensor([1.7971, 0.0918])\n",
      "Epoch 1598, Loss 36.973652, Params tensor([1.7974, 0.0919])\n",
      "Epoch 1599, Loss 36.964737, Params tensor([1.7977, 0.0919])\n",
      "Epoch 1600, Loss 36.955822, Params tensor([1.7980, 0.0919])\n",
      "Epoch 1601, Loss 36.946934, Params tensor([1.7983, 0.0919])\n",
      "Epoch 1602, Loss 36.938053, Params tensor([1.7986, 0.0919])\n",
      "Epoch 1603, Loss 36.929184, Params tensor([1.7989, 0.0920])\n",
      "Epoch 1604, Loss 36.920322, Params tensor([1.7992, 0.0920])\n",
      "Epoch 1605, Loss 36.911465, Params tensor([1.7994, 0.0920])\n",
      "Epoch 1606, Loss 36.902622, Params tensor([1.7997, 0.0920])\n",
      "Epoch 1607, Loss 36.893795, Params tensor([1.8000, 0.0921])\n",
      "Epoch 1608, Loss 36.884983, Params tensor([1.8003, 0.0921])\n",
      "Epoch 1609, Loss 36.876167, Params tensor([1.8006, 0.0921])\n",
      "Epoch 1610, Loss 36.867374, Params tensor([1.8009, 0.0921])\n",
      "Epoch 1611, Loss 36.858578, Params tensor([1.8012, 0.0921])\n",
      "Epoch 1612, Loss 36.849804, Params tensor([1.8015, 0.0922])\n",
      "Epoch 1613, Loss 36.841038, Params tensor([1.8018, 0.0922])\n",
      "Epoch 1614, Loss 36.832279, Params tensor([1.8021, 0.0922])\n",
      "Epoch 1615, Loss 36.823536, Params tensor([1.8024, 0.0922])\n",
      "Epoch 1616, Loss 36.814796, Params tensor([1.8027, 0.0922])\n",
      "Epoch 1617, Loss 36.806072, Params tensor([1.8030, 0.0923])\n",
      "Epoch 1618, Loss 36.797363, Params tensor([1.8033, 0.0923])\n",
      "Epoch 1619, Loss 36.788651, Params tensor([1.8036, 0.0923])\n",
      "Epoch 1620, Loss 36.779964, Params tensor([1.8039, 0.0923])\n",
      "Epoch 1621, Loss 36.771278, Params tensor([1.8042, 0.0924])\n",
      "Epoch 1622, Loss 36.762604, Params tensor([1.8045, 0.0924])\n",
      "Epoch 1623, Loss 36.753941, Params tensor([1.8048, 0.0924])\n",
      "Epoch 1624, Loss 36.745293, Params tensor([1.8051, 0.0924])\n",
      "Epoch 1625, Loss 36.736656, Params tensor([1.8053, 0.0924])\n",
      "Epoch 1626, Loss 36.728020, Params tensor([1.8056, 0.0925])\n",
      "Epoch 1627, Loss 36.719402, Params tensor([1.8059, 0.0925])\n",
      "Epoch 1628, Loss 36.710789, Params tensor([1.8062, 0.0925])\n",
      "Epoch 1629, Loss 36.702187, Params tensor([1.8065, 0.0925])\n",
      "Epoch 1630, Loss 36.693596, Params tensor([1.8068, 0.0925])\n",
      "Epoch 1631, Loss 36.685013, Params tensor([1.8071, 0.0926])\n",
      "Epoch 1632, Loss 36.676449, Params tensor([1.8074, 0.0926])\n",
      "Epoch 1633, Loss 36.667892, Params tensor([1.8077, 0.0926])\n",
      "Epoch 1634, Loss 36.659340, Params tensor([1.8080, 0.0926])\n",
      "Epoch 1635, Loss 36.650806, Params tensor([1.8083, 0.0926])\n",
      "Epoch 1636, Loss 36.642273, Params tensor([1.8086, 0.0927])\n",
      "Epoch 1637, Loss 36.633762, Params tensor([1.8088, 0.0927])\n",
      "Epoch 1638, Loss 36.625248, Params tensor([1.8091, 0.0927])\n",
      "Epoch 1639, Loss 36.616753, Params tensor([1.8094, 0.0927])\n",
      "Epoch 1640, Loss 36.608265, Params tensor([1.8097, 0.0927])\n",
      "Epoch 1641, Loss 36.599789, Params tensor([1.8100, 0.0928])\n",
      "Epoch 1642, Loss 36.591324, Params tensor([1.8103, 0.0928])\n",
      "Epoch 1643, Loss 36.582859, Params tensor([1.8106, 0.0928])\n",
      "Epoch 1644, Loss 36.574417, Params tensor([1.8109, 0.0928])\n",
      "Epoch 1645, Loss 36.565979, Params tensor([1.8112, 0.0929])\n",
      "Epoch 1646, Loss 36.557560, Params tensor([1.8115, 0.0929])\n",
      "Epoch 1647, Loss 36.549137, Params tensor([1.8117, 0.0929])\n",
      "Epoch 1648, Loss 36.540737, Params tensor([1.8120, 0.0929])\n",
      "Epoch 1649, Loss 36.532333, Params tensor([1.8123, 0.0929])\n",
      "Epoch 1650, Loss 36.523952, Params tensor([1.8126, 0.0930])\n",
      "Epoch 1651, Loss 36.515575, Params tensor([1.8129, 0.0930])\n",
      "Epoch 1652, Loss 36.507206, Params tensor([1.8132, 0.0930])\n",
      "Epoch 1653, Loss 36.498852, Params tensor([1.8135, 0.0930])\n",
      "Epoch 1654, Loss 36.490505, Params tensor([1.8138, 0.0930])\n",
      "Epoch 1655, Loss 36.482174, Params tensor([1.8141, 0.0931])\n",
      "Epoch 1656, Loss 36.473843, Params tensor([1.8143, 0.0931])\n",
      "Epoch 1657, Loss 36.465538, Params tensor([1.8146, 0.0931])\n",
      "Epoch 1658, Loss 36.457226, Params tensor([1.8149, 0.0931])\n",
      "Epoch 1659, Loss 36.448929, Params tensor([1.8152, 0.0931])\n",
      "Epoch 1660, Loss 36.440639, Params tensor([1.8155, 0.0932])\n",
      "Epoch 1661, Loss 36.432362, Params tensor([1.8158, 0.0932])\n",
      "Epoch 1662, Loss 36.424095, Params tensor([1.8161, 0.0932])\n",
      "Epoch 1663, Loss 36.415844, Params tensor([1.8164, 0.0932])\n",
      "Epoch 1664, Loss 36.407593, Params tensor([1.8166, 0.0932])\n",
      "Epoch 1665, Loss 36.399368, Params tensor([1.8169, 0.0933])\n",
      "Epoch 1666, Loss 36.391136, Params tensor([1.8172, 0.0933])\n",
      "Epoch 1667, Loss 36.382923, Params tensor([1.8175, 0.0933])\n",
      "Epoch 1668, Loss 36.374710, Params tensor([1.8178, 0.0933])\n",
      "Epoch 1669, Loss 36.366516, Params tensor([1.8181, 0.0933])\n",
      "Epoch 1670, Loss 36.358326, Params tensor([1.8184, 0.0934])\n",
      "Epoch 1671, Loss 36.350155, Params tensor([1.8186, 0.0934])\n",
      "Epoch 1672, Loss 36.341988, Params tensor([1.8189, 0.0934])\n",
      "Epoch 1673, Loss 36.333828, Params tensor([1.8192, 0.0934])\n",
      "Epoch 1674, Loss 36.325680, Params tensor([1.8195, 0.0934])\n",
      "Epoch 1675, Loss 36.317539, Params tensor([1.8198, 0.0935])\n",
      "Epoch 1676, Loss 36.309406, Params tensor([1.8201, 0.0935])\n",
      "Epoch 1677, Loss 36.301296, Params tensor([1.8203, 0.0935])\n",
      "Epoch 1678, Loss 36.293186, Params tensor([1.8206, 0.0935])\n",
      "Epoch 1679, Loss 36.285084, Params tensor([1.8209, 0.0935])\n",
      "Epoch 1680, Loss 36.276993, Params tensor([1.8212, 0.0936])\n",
      "Epoch 1681, Loss 36.268913, Params tensor([1.8215, 0.0936])\n",
      "Epoch 1682, Loss 36.260841, Params tensor([1.8218, 0.0936])\n",
      "Epoch 1683, Loss 36.252785, Params tensor([1.8220, 0.0936])\n",
      "Epoch 1684, Loss 36.244736, Params tensor([1.8223, 0.0936])\n",
      "Epoch 1685, Loss 36.236691, Params tensor([1.8226, 0.0936])\n",
      "Epoch 1686, Loss 36.228664, Params tensor([1.8229, 0.0937])\n",
      "Epoch 1687, Loss 36.220638, Params tensor([1.8232, 0.0937])\n",
      "Epoch 1688, Loss 36.212631, Params tensor([1.8235, 0.0937])\n",
      "Epoch 1689, Loss 36.204628, Params tensor([1.8237, 0.0937])\n",
      "Epoch 1690, Loss 36.196632, Params tensor([1.8240, 0.0937])\n",
      "Epoch 1691, Loss 36.188648, Params tensor([1.8243, 0.0938])\n",
      "Epoch 1692, Loss 36.180679, Params tensor([1.8246, 0.0938])\n",
      "Epoch 1693, Loss 36.172718, Params tensor([1.8249, 0.0938])\n",
      "Epoch 1694, Loss 36.164761, Params tensor([1.8251, 0.0938])\n",
      "Epoch 1695, Loss 36.156815, Params tensor([1.8254, 0.0938])\n",
      "Epoch 1696, Loss 36.148880, Params tensor([1.8257, 0.0939])\n",
      "Epoch 1697, Loss 36.140953, Params tensor([1.8260, 0.0939])\n",
      "Epoch 1698, Loss 36.133034, Params tensor([1.8263, 0.0939])\n",
      "Epoch 1699, Loss 36.125130, Params tensor([1.8266, 0.0939])\n",
      "Epoch 1700, Loss 36.117233, Params tensor([1.8268, 0.0939])\n",
      "Epoch 1701, Loss 36.109341, Params tensor([1.8271, 0.0940])\n",
      "Epoch 1702, Loss 36.101463, Params tensor([1.8274, 0.0940])\n",
      "Epoch 1703, Loss 36.093594, Params tensor([1.8277, 0.0940])\n",
      "Epoch 1704, Loss 36.085739, Params tensor([1.8280, 0.0940])\n",
      "Epoch 1705, Loss 36.077885, Params tensor([1.8282, 0.0940])\n",
      "Epoch 1706, Loss 36.070042, Params tensor([1.8285, 0.0940])\n",
      "Epoch 1707, Loss 36.062214, Params tensor([1.8288, 0.0941])\n",
      "Epoch 1708, Loss 36.054390, Params tensor([1.8291, 0.0941])\n",
      "Epoch 1709, Loss 36.046574, Params tensor([1.8293, 0.0941])\n",
      "Epoch 1710, Loss 36.038776, Params tensor([1.8296, 0.0941])\n",
      "Epoch 1711, Loss 36.030979, Params tensor([1.8299, 0.0941])\n",
      "Epoch 1712, Loss 36.023193, Params tensor([1.8302, 0.0942])\n",
      "Epoch 1713, Loss 36.015427, Params tensor([1.8305, 0.0942])\n",
      "Epoch 1714, Loss 36.007656, Params tensor([1.8307, 0.0942])\n",
      "Epoch 1715, Loss 35.999897, Params tensor([1.8310, 0.0942])\n",
      "Epoch 1716, Loss 35.992149, Params tensor([1.8313, 0.0942])\n",
      "Epoch 1717, Loss 35.984409, Params tensor([1.8316, 0.0943])\n",
      "Epoch 1718, Loss 35.976685, Params tensor([1.8318, 0.0943])\n",
      "Epoch 1719, Loss 35.968960, Params tensor([1.8321, 0.0943])\n",
      "Epoch 1720, Loss 35.961246, Params tensor([1.8324, 0.0943])\n",
      "Epoch 1721, Loss 35.953548, Params tensor([1.8327, 0.0943])\n",
      "Epoch 1722, Loss 35.945858, Params tensor([1.8330, 0.0943])\n",
      "Epoch 1723, Loss 35.938175, Params tensor([1.8332, 0.0944])\n",
      "Epoch 1724, Loss 35.930508, Params tensor([1.8335, 0.0944])\n",
      "Epoch 1725, Loss 35.922840, Params tensor([1.8338, 0.0944])\n",
      "Epoch 1726, Loss 35.915188, Params tensor([1.8341, 0.0944])\n",
      "Epoch 1727, Loss 35.907536, Params tensor([1.8343, 0.0944])\n",
      "Epoch 1728, Loss 35.899902, Params tensor([1.8346, 0.0945])\n",
      "Epoch 1729, Loss 35.892273, Params tensor([1.8349, 0.0945])\n",
      "Epoch 1730, Loss 35.884651, Params tensor([1.8352, 0.0945])\n",
      "Epoch 1731, Loss 35.877048, Params tensor([1.8354, 0.0945])\n",
      "Epoch 1732, Loss 35.869442, Params tensor([1.8357, 0.0945])\n",
      "Epoch 1733, Loss 35.861851, Params tensor([1.8360, 0.0945])\n",
      "Epoch 1734, Loss 35.854267, Params tensor([1.8363, 0.0946])\n",
      "Epoch 1735, Loss 35.846695, Params tensor([1.8365, 0.0946])\n",
      "Epoch 1736, Loss 35.839130, Params tensor([1.8368, 0.0946])\n",
      "Epoch 1737, Loss 35.831577, Params tensor([1.8371, 0.0946])\n",
      "Epoch 1738, Loss 35.824032, Params tensor([1.8374, 0.0946])\n",
      "Epoch 1739, Loss 35.816498, Params tensor([1.8376, 0.0946])\n",
      "Epoch 1740, Loss 35.808968, Params tensor([1.8379, 0.0947])\n",
      "Epoch 1741, Loss 35.801453, Params tensor([1.8382, 0.0947])\n",
      "Epoch 1742, Loss 35.793941, Params tensor([1.8385, 0.0947])\n",
      "Epoch 1743, Loss 35.786438, Params tensor([1.8387, 0.0947])\n",
      "Epoch 1744, Loss 35.778946, Params tensor([1.8390, 0.0947])\n",
      "Epoch 1745, Loss 35.771461, Params tensor([1.8393, 0.0948])\n",
      "Epoch 1746, Loss 35.763985, Params tensor([1.8395, 0.0948])\n",
      "Epoch 1747, Loss 35.756527, Params tensor([1.8398, 0.0948])\n",
      "Epoch 1748, Loss 35.749062, Params tensor([1.8401, 0.0948])\n",
      "Epoch 1749, Loss 35.741627, Params tensor([1.8404, 0.0948])\n",
      "Epoch 1750, Loss 35.734188, Params tensor([1.8406, 0.0948])\n",
      "Epoch 1751, Loss 35.726749, Params tensor([1.8409, 0.0949])\n",
      "Epoch 1752, Loss 35.719334, Params tensor([1.8412, 0.0949])\n",
      "Epoch 1753, Loss 35.711929, Params tensor([1.8415, 0.0949])\n",
      "Epoch 1754, Loss 35.704525, Params tensor([1.8417, 0.0949])\n",
      "Epoch 1755, Loss 35.697128, Params tensor([1.8420, 0.0949])\n",
      "Epoch 1756, Loss 35.689743, Params tensor([1.8423, 0.0949])\n",
      "Epoch 1757, Loss 35.682369, Params tensor([1.8425, 0.0950])\n",
      "Epoch 1758, Loss 35.675003, Params tensor([1.8428, 0.0950])\n",
      "Epoch 1759, Loss 35.667637, Params tensor([1.8431, 0.0950])\n",
      "Epoch 1760, Loss 35.660290, Params tensor([1.8433, 0.0950])\n",
      "Epoch 1761, Loss 35.652950, Params tensor([1.8436, 0.0950])\n",
      "Epoch 1762, Loss 35.645615, Params tensor([1.8439, 0.0950])\n",
      "Epoch 1763, Loss 35.638290, Params tensor([1.8442, 0.0951])\n",
      "Epoch 1764, Loss 35.630974, Params tensor([1.8444, 0.0951])\n",
      "Epoch 1765, Loss 35.623672, Params tensor([1.8447, 0.0951])\n",
      "Epoch 1766, Loss 35.616379, Params tensor([1.8450, 0.0951])\n",
      "Epoch 1767, Loss 35.609089, Params tensor([1.8452, 0.0951])\n",
      "Epoch 1768, Loss 35.601810, Params tensor([1.8455, 0.0952])\n",
      "Epoch 1769, Loss 35.594540, Params tensor([1.8458, 0.0952])\n",
      "Epoch 1770, Loss 35.587280, Params tensor([1.8460, 0.0952])\n",
      "Epoch 1771, Loss 35.580021, Params tensor([1.8463, 0.0952])\n",
      "Epoch 1772, Loss 35.572781, Params tensor([1.8466, 0.0952])\n",
      "Epoch 1773, Loss 35.565548, Params tensor([1.8468, 0.0952])\n",
      "Epoch 1774, Loss 35.558315, Params tensor([1.8471, 0.0953])\n",
      "Epoch 1775, Loss 35.551098, Params tensor([1.8474, 0.0953])\n",
      "Epoch 1776, Loss 35.543892, Params tensor([1.8477, 0.0953])\n",
      "Epoch 1777, Loss 35.536686, Params tensor([1.8479, 0.0953])\n",
      "Epoch 1778, Loss 35.529495, Params tensor([1.8482, 0.0953])\n",
      "Epoch 1779, Loss 35.522312, Params tensor([1.8485, 0.0953])\n",
      "Epoch 1780, Loss 35.515137, Params tensor([1.8487, 0.0954])\n",
      "Epoch 1781, Loss 35.507969, Params tensor([1.8490, 0.0954])\n",
      "Epoch 1782, Loss 35.500809, Params tensor([1.8493, 0.0954])\n",
      "Epoch 1783, Loss 35.493664, Params tensor([1.8495, 0.0954])\n",
      "Epoch 1784, Loss 35.486515, Params tensor([1.8498, 0.0954])\n",
      "Epoch 1785, Loss 35.479385, Params tensor([1.8501, 0.0954])\n",
      "Epoch 1786, Loss 35.472263, Params tensor([1.8503, 0.0955])\n",
      "Epoch 1787, Loss 35.465149, Params tensor([1.8506, 0.0955])\n",
      "Epoch 1788, Loss 35.458050, Params tensor([1.8509, 0.0955])\n",
      "Epoch 1789, Loss 35.450947, Params tensor([1.8511, 0.0955])\n",
      "Epoch 1790, Loss 35.443851, Params tensor([1.8514, 0.0955])\n",
      "Epoch 1791, Loss 35.436775, Params tensor([1.8517, 0.0955])\n",
      "Epoch 1792, Loss 35.429703, Params tensor([1.8519, 0.0955])\n",
      "Epoch 1793, Loss 35.422638, Params tensor([1.8522, 0.0956])\n",
      "Epoch 1794, Loss 35.415585, Params tensor([1.8524, 0.0956])\n",
      "Epoch 1795, Loss 35.408535, Params tensor([1.8527, 0.0956])\n",
      "Epoch 1796, Loss 35.401497, Params tensor([1.8530, 0.0956])\n",
      "Epoch 1797, Loss 35.394466, Params tensor([1.8532, 0.0956])\n",
      "Epoch 1798, Loss 35.387440, Params tensor([1.8535, 0.0956])\n",
      "Epoch 1799, Loss 35.380424, Params tensor([1.8538, 0.0957])\n",
      "Epoch 1800, Loss 35.373417, Params tensor([1.8540, 0.0957])\n",
      "Epoch 1801, Loss 35.366421, Params tensor([1.8543, 0.0957])\n",
      "Epoch 1802, Loss 35.359432, Params tensor([1.8546, 0.0957])\n",
      "Epoch 1803, Loss 35.352451, Params tensor([1.8548, 0.0957])\n",
      "Epoch 1804, Loss 35.345478, Params tensor([1.8551, 0.0957])\n",
      "Epoch 1805, Loss 35.338520, Params tensor([1.8554, 0.0958])\n",
      "Epoch 1806, Loss 35.331558, Params tensor([1.8556, 0.0958])\n",
      "Epoch 1807, Loss 35.324612, Params tensor([1.8559, 0.0958])\n",
      "Epoch 1808, Loss 35.317673, Params tensor([1.8561, 0.0958])\n",
      "Epoch 1809, Loss 35.310741, Params tensor([1.8564, 0.0958])\n",
      "Epoch 1810, Loss 35.303829, Params tensor([1.8567, 0.0958])\n",
      "Epoch 1811, Loss 35.296909, Params tensor([1.8569, 0.0959])\n",
      "Epoch 1812, Loss 35.290005, Params tensor([1.8572, 0.0959])\n",
      "Epoch 1813, Loss 35.283108, Params tensor([1.8575, 0.0959])\n",
      "Epoch 1814, Loss 35.276222, Params tensor([1.8577, 0.0959])\n",
      "Epoch 1815, Loss 35.269341, Params tensor([1.8580, 0.0959])\n",
      "Epoch 1816, Loss 35.262463, Params tensor([1.8582, 0.0959])\n",
      "Epoch 1817, Loss 35.255600, Params tensor([1.8585, 0.0959])\n",
      "Epoch 1818, Loss 35.248741, Params tensor([1.8588, 0.0960])\n",
      "Epoch 1819, Loss 35.241890, Params tensor([1.8590, 0.0960])\n",
      "Epoch 1820, Loss 35.235058, Params tensor([1.8593, 0.0960])\n",
      "Epoch 1821, Loss 35.228222, Params tensor([1.8595, 0.0960])\n",
      "Epoch 1822, Loss 35.221401, Params tensor([1.8598, 0.0960])\n",
      "Epoch 1823, Loss 35.214584, Params tensor([1.8601, 0.0960])\n",
      "Epoch 1824, Loss 35.207779, Params tensor([1.8603, 0.0961])\n",
      "Epoch 1825, Loss 35.200981, Params tensor([1.8606, 0.0961])\n",
      "Epoch 1826, Loss 35.194187, Params tensor([1.8608, 0.0961])\n",
      "Epoch 1827, Loss 35.187408, Params tensor([1.8611, 0.0961])\n",
      "Epoch 1828, Loss 35.180634, Params tensor([1.8614, 0.0961])\n",
      "Epoch 1829, Loss 35.173862, Params tensor([1.8616, 0.0961])\n",
      "Epoch 1830, Loss 35.167110, Params tensor([1.8619, 0.0961])\n",
      "Epoch 1831, Loss 35.160355, Params tensor([1.8621, 0.0962])\n",
      "Epoch 1832, Loss 35.153618, Params tensor([1.8624, 0.0962])\n",
      "Epoch 1833, Loss 35.146881, Params tensor([1.8627, 0.0962])\n",
      "Epoch 1834, Loss 35.140152, Params tensor([1.8629, 0.0962])\n",
      "Epoch 1835, Loss 35.133434, Params tensor([1.8632, 0.0962])\n",
      "Epoch 1836, Loss 35.126720, Params tensor([1.8634, 0.0962])\n",
      "Epoch 1837, Loss 35.120022, Params tensor([1.8637, 0.0963])\n",
      "Epoch 1838, Loss 35.113331, Params tensor([1.8640, 0.0963])\n",
      "Epoch 1839, Loss 35.106640, Params tensor([1.8642, 0.0963])\n",
      "Epoch 1840, Loss 35.099960, Params tensor([1.8645, 0.0963])\n",
      "Epoch 1841, Loss 35.093296, Params tensor([1.8647, 0.0963])\n",
      "Epoch 1842, Loss 35.086632, Params tensor([1.8650, 0.0963])\n",
      "Epoch 1843, Loss 35.079971, Params tensor([1.8652, 0.0963])\n",
      "Epoch 1844, Loss 35.073334, Params tensor([1.8655, 0.0964])\n",
      "Epoch 1845, Loss 35.066696, Params tensor([1.8658, 0.0964])\n",
      "Epoch 1846, Loss 35.060062, Params tensor([1.8660, 0.0964])\n",
      "Epoch 1847, Loss 35.053440, Params tensor([1.8663, 0.0964])\n",
      "Epoch 1848, Loss 35.046829, Params tensor([1.8665, 0.0964])\n",
      "Epoch 1849, Loss 35.040218, Params tensor([1.8668, 0.0964])\n",
      "Epoch 1850, Loss 35.033623, Params tensor([1.8670, 0.0964])\n",
      "Epoch 1851, Loss 35.027035, Params tensor([1.8673, 0.0965])\n",
      "Epoch 1852, Loss 35.020451, Params tensor([1.8676, 0.0965])\n",
      "Epoch 1853, Loss 35.013878, Params tensor([1.8678, 0.0965])\n",
      "Epoch 1854, Loss 35.007309, Params tensor([1.8681, 0.0965])\n",
      "Epoch 1855, Loss 35.000744, Params tensor([1.8683, 0.0965])\n",
      "Epoch 1856, Loss 34.994194, Params tensor([1.8686, 0.0965])\n",
      "Epoch 1857, Loss 34.987652, Params tensor([1.8688, 0.0965])\n",
      "Epoch 1858, Loss 34.981121, Params tensor([1.8691, 0.0966])\n",
      "Epoch 1859, Loss 34.974586, Params tensor([1.8693, 0.0966])\n",
      "Epoch 1860, Loss 34.968067, Params tensor([1.8696, 0.0966])\n",
      "Epoch 1861, Loss 34.961552, Params tensor([1.8698, 0.0966])\n",
      "Epoch 1862, Loss 34.955051, Params tensor([1.8701, 0.0966])\n",
      "Epoch 1863, Loss 34.948555, Params tensor([1.8704, 0.0966])\n",
      "Epoch 1864, Loss 34.942066, Params tensor([1.8706, 0.0966])\n",
      "Epoch 1865, Loss 34.935585, Params tensor([1.8709, 0.0967])\n",
      "Epoch 1866, Loss 34.929111, Params tensor([1.8711, 0.0967])\n",
      "Epoch 1867, Loss 34.922642, Params tensor([1.8714, 0.0967])\n",
      "Epoch 1868, Loss 34.916183, Params tensor([1.8716, 0.0967])\n",
      "Epoch 1869, Loss 34.909737, Params tensor([1.8719, 0.0967])\n",
      "Epoch 1870, Loss 34.903297, Params tensor([1.8721, 0.0967])\n",
      "Epoch 1871, Loss 34.896862, Params tensor([1.8724, 0.0967])\n",
      "Epoch 1872, Loss 34.890430, Params tensor([1.8726, 0.0968])\n",
      "Epoch 1873, Loss 34.884007, Params tensor([1.8729, 0.0968])\n",
      "Epoch 1874, Loss 34.877598, Params tensor([1.8731, 0.0968])\n",
      "Epoch 1875, Loss 34.871201, Params tensor([1.8734, 0.0968])\n",
      "Epoch 1876, Loss 34.864803, Params tensor([1.8737, 0.0968])\n",
      "Epoch 1877, Loss 34.858414, Params tensor([1.8739, 0.0968])\n",
      "Epoch 1878, Loss 34.852032, Params tensor([1.8742, 0.0968])\n",
      "Epoch 1879, Loss 34.845657, Params tensor([1.8744, 0.0969])\n",
      "Epoch 1880, Loss 34.839294, Params tensor([1.8747, 0.0969])\n",
      "Epoch 1881, Loss 34.832939, Params tensor([1.8749, 0.0969])\n",
      "Epoch 1882, Loss 34.826584, Params tensor([1.8752, 0.0969])\n",
      "Epoch 1883, Loss 34.820236, Params tensor([1.8754, 0.0969])\n",
      "Epoch 1884, Loss 34.813904, Params tensor([1.8757, 0.0969])\n",
      "Epoch 1885, Loss 34.807579, Params tensor([1.8759, 0.0969])\n",
      "Epoch 1886, Loss 34.801258, Params tensor([1.8762, 0.0970])\n",
      "Epoch 1887, Loss 34.794941, Params tensor([1.8764, 0.0970])\n",
      "Epoch 1888, Loss 34.788635, Params tensor([1.8767, 0.0970])\n",
      "Epoch 1889, Loss 34.782345, Params tensor([1.8769, 0.0970])\n",
      "Epoch 1890, Loss 34.776043, Params tensor([1.8772, 0.0970])\n",
      "Epoch 1891, Loss 34.769772, Params tensor([1.8774, 0.0970])\n",
      "Epoch 1892, Loss 34.763489, Params tensor([1.8777, 0.0970])\n",
      "Epoch 1893, Loss 34.757225, Params tensor([1.8779, 0.0971])\n",
      "Epoch 1894, Loss 34.750961, Params tensor([1.8782, 0.0971])\n",
      "Epoch 1895, Loss 34.744705, Params tensor([1.8784, 0.0971])\n",
      "Epoch 1896, Loss 34.738461, Params tensor([1.8787, 0.0971])\n",
      "Epoch 1897, Loss 34.732227, Params tensor([1.8789, 0.0971])\n",
      "Epoch 1898, Loss 34.725990, Params tensor([1.8792, 0.0971])\n",
      "Epoch 1899, Loss 34.719772, Params tensor([1.8794, 0.0971])\n",
      "Epoch 1900, Loss 34.713551, Params tensor([1.8797, 0.0971])\n",
      "Epoch 1901, Loss 34.707352, Params tensor([1.8799, 0.0972])\n",
      "Epoch 1902, Loss 34.701145, Params tensor([1.8802, 0.0972])\n",
      "Epoch 1903, Loss 34.694950, Params tensor([1.8804, 0.0972])\n",
      "Epoch 1904, Loss 34.688766, Params tensor([1.8807, 0.0972])\n",
      "Epoch 1905, Loss 34.682590, Params tensor([1.8809, 0.0972])\n",
      "Epoch 1906, Loss 34.676418, Params tensor([1.8812, 0.0972])\n",
      "Epoch 1907, Loss 34.670254, Params tensor([1.8814, 0.0972])\n",
      "Epoch 1908, Loss 34.664104, Params tensor([1.8816, 0.0973])\n",
      "Epoch 1909, Loss 34.657955, Params tensor([1.8819, 0.0973])\n",
      "Epoch 1910, Loss 34.651814, Params tensor([1.8821, 0.0973])\n",
      "Epoch 1911, Loss 34.645668, Params tensor([1.8824, 0.0973])\n",
      "Epoch 1912, Loss 34.639549, Params tensor([1.8826, 0.0973])\n",
      "Epoch 1913, Loss 34.633427, Params tensor([1.8829, 0.0973])\n",
      "Epoch 1914, Loss 34.627316, Params tensor([1.8831, 0.0973])\n",
      "Epoch 1915, Loss 34.621216, Params tensor([1.8834, 0.0973])\n",
      "Epoch 1916, Loss 34.615112, Params tensor([1.8836, 0.0974])\n",
      "Epoch 1917, Loss 34.609024, Params tensor([1.8839, 0.0974])\n",
      "Epoch 1918, Loss 34.602940, Params tensor([1.8841, 0.0974])\n",
      "Epoch 1919, Loss 34.596867, Params tensor([1.8844, 0.0974])\n",
      "Epoch 1920, Loss 34.590790, Params tensor([1.8846, 0.0974])\n",
      "Epoch 1921, Loss 34.584732, Params tensor([1.8849, 0.0974])\n",
      "Epoch 1922, Loss 34.578678, Params tensor([1.8851, 0.0974])\n",
      "Epoch 1923, Loss 34.572632, Params tensor([1.8853, 0.0974])\n",
      "Epoch 1924, Loss 34.566589, Params tensor([1.8856, 0.0975])\n",
      "Epoch 1925, Loss 34.560562, Params tensor([1.8858, 0.0975])\n",
      "Epoch 1926, Loss 34.554535, Params tensor([1.8861, 0.0975])\n",
      "Epoch 1927, Loss 34.548512, Params tensor([1.8863, 0.0975])\n",
      "Epoch 1928, Loss 34.542507, Params tensor([1.8866, 0.0975])\n",
      "Epoch 1929, Loss 34.536499, Params tensor([1.8868, 0.0975])\n",
      "Epoch 1930, Loss 34.530506, Params tensor([1.8871, 0.0975])\n",
      "Epoch 1931, Loss 34.524513, Params tensor([1.8873, 0.0975])\n",
      "Epoch 1932, Loss 34.518532, Params tensor([1.8875, 0.0976])\n",
      "Epoch 1933, Loss 34.512558, Params tensor([1.8878, 0.0976])\n",
      "Epoch 1934, Loss 34.506588, Params tensor([1.8880, 0.0976])\n",
      "Epoch 1935, Loss 34.500626, Params tensor([1.8883, 0.0976])\n",
      "Epoch 1936, Loss 34.494675, Params tensor([1.8885, 0.0976])\n",
      "Epoch 1937, Loss 34.488731, Params tensor([1.8888, 0.0976])\n",
      "Epoch 1938, Loss 34.482788, Params tensor([1.8890, 0.0976])\n",
      "Epoch 1939, Loss 34.476856, Params tensor([1.8893, 0.0976])\n",
      "Epoch 1940, Loss 34.470932, Params tensor([1.8895, 0.0977])\n",
      "Epoch 1941, Loss 34.465012, Params tensor([1.8897, 0.0977])\n",
      "Epoch 1942, Loss 34.459103, Params tensor([1.8900, 0.0977])\n",
      "Epoch 1943, Loss 34.453197, Params tensor([1.8902, 0.0977])\n",
      "Epoch 1944, Loss 34.447300, Params tensor([1.8905, 0.0977])\n",
      "Epoch 1945, Loss 34.441406, Params tensor([1.8907, 0.0977])\n",
      "Epoch 1946, Loss 34.435528, Params tensor([1.8910, 0.0977])\n",
      "Epoch 1947, Loss 34.429649, Params tensor([1.8912, 0.0977])\n",
      "Epoch 1948, Loss 34.423782, Params tensor([1.8914, 0.0978])\n",
      "Epoch 1949, Loss 34.417923, Params tensor([1.8917, 0.0978])\n",
      "Epoch 1950, Loss 34.412064, Params tensor([1.8919, 0.0978])\n",
      "Epoch 1951, Loss 34.406216, Params tensor([1.8922, 0.0978])\n",
      "Epoch 1952, Loss 34.400375, Params tensor([1.8924, 0.0978])\n",
      "Epoch 1953, Loss 34.394543, Params tensor([1.8926, 0.0978])\n",
      "Epoch 1954, Loss 34.388718, Params tensor([1.8929, 0.0978])\n",
      "Epoch 1955, Loss 34.382893, Params tensor([1.8931, 0.0978])\n",
      "Epoch 1956, Loss 34.377087, Params tensor([1.8934, 0.0979])\n",
      "Epoch 1957, Loss 34.371273, Params tensor([1.8936, 0.0979])\n",
      "Epoch 1958, Loss 34.365479, Params tensor([1.8938, 0.0979])\n",
      "Epoch 1959, Loss 34.359680, Params tensor([1.8941, 0.0979])\n",
      "Epoch 1960, Loss 34.353893, Params tensor([1.8943, 0.0979])\n",
      "Epoch 1961, Loss 34.348114, Params tensor([1.8946, 0.0979])\n",
      "Epoch 1962, Loss 34.342346, Params tensor([1.8948, 0.0979])\n",
      "Epoch 1963, Loss 34.336582, Params tensor([1.8950, 0.0979])\n",
      "Epoch 1964, Loss 34.330822, Params tensor([1.8953, 0.0979])\n",
      "Epoch 1965, Loss 34.325069, Params tensor([1.8955, 0.0980])\n",
      "Epoch 1966, Loss 34.319324, Params tensor([1.8958, 0.0980])\n",
      "Epoch 1967, Loss 34.313595, Params tensor([1.8960, 0.0980])\n",
      "Epoch 1968, Loss 34.307858, Params tensor([1.8962, 0.0980])\n",
      "Epoch 1969, Loss 34.302139, Params tensor([1.8965, 0.0980])\n",
      "Epoch 1970, Loss 34.296417, Params tensor([1.8967, 0.0980])\n",
      "Epoch 1971, Loss 34.290710, Params tensor([1.8970, 0.0980])\n",
      "Epoch 1972, Loss 34.285007, Params tensor([1.8972, 0.0980])\n",
      "Epoch 1973, Loss 34.279312, Params tensor([1.8974, 0.0981])\n",
      "Epoch 1974, Loss 34.273624, Params tensor([1.8977, 0.0981])\n",
      "Epoch 1975, Loss 34.267941, Params tensor([1.8979, 0.0981])\n",
      "Epoch 1976, Loss 34.262264, Params tensor([1.8982, 0.0981])\n",
      "Epoch 1977, Loss 34.256596, Params tensor([1.8984, 0.0981])\n",
      "Epoch 1978, Loss 34.250931, Params tensor([1.8986, 0.0981])\n",
      "Epoch 1979, Loss 34.245274, Params tensor([1.8989, 0.0981])\n",
      "Epoch 1980, Loss 34.239628, Params tensor([1.8991, 0.0981])\n",
      "Epoch 1981, Loss 34.233982, Params tensor([1.8993, 0.0981])\n",
      "Epoch 1982, Loss 34.228348, Params tensor([1.8996, 0.0982])\n",
      "Epoch 1983, Loss 34.222717, Params tensor([1.8998, 0.0982])\n",
      "Epoch 1984, Loss 34.217102, Params tensor([1.9000, 0.0982])\n",
      "Epoch 1985, Loss 34.211483, Params tensor([1.9003, 0.0982])\n",
      "Epoch 1986, Loss 34.205872, Params tensor([1.9005, 0.0982])\n",
      "Epoch 1987, Loss 34.200268, Params tensor([1.9008, 0.0982])\n",
      "Epoch 1988, Loss 34.194679, Params tensor([1.9010, 0.0982])\n",
      "Epoch 1989, Loss 34.189087, Params tensor([1.9012, 0.0982])\n",
      "Epoch 1990, Loss 34.183506, Params tensor([1.9015, 0.0982])\n",
      "Epoch 1991, Loss 34.177933, Params tensor([1.9017, 0.0983])\n",
      "Epoch 1992, Loss 34.172359, Params tensor([1.9019, 0.0983])\n",
      "Epoch 1993, Loss 34.166801, Params tensor([1.9022, 0.0983])\n",
      "Epoch 1994, Loss 34.161240, Params tensor([1.9024, 0.0983])\n",
      "Epoch 1995, Loss 34.155697, Params tensor([1.9026, 0.0983])\n",
      "Epoch 1996, Loss 34.150150, Params tensor([1.9029, 0.0983])\n",
      "Epoch 1997, Loss 34.144619, Params tensor([1.9031, 0.0983])\n",
      "Epoch 1998, Loss 34.139091, Params tensor([1.9033, 0.0983])\n",
      "Epoch 1999, Loss 34.133564, Params tensor([1.9036, 0.0983])\n",
      "Epoch 2000, Loss 34.128056, Params tensor([1.9038, 0.0984])\n",
      "Epoch 2001, Loss 34.122547, Params tensor([1.9041, 0.0984])\n",
      "Epoch 2002, Loss 34.117043, Params tensor([1.9043, 0.0984])\n",
      "Epoch 2003, Loss 34.111546, Params tensor([1.9045, 0.0984])\n",
      "Epoch 2004, Loss 34.106052, Params tensor([1.9048, 0.0984])\n",
      "Epoch 2005, Loss 34.100571, Params tensor([1.9050, 0.0984])\n",
      "Epoch 2006, Loss 34.095093, Params tensor([1.9052, 0.0984])\n",
      "Epoch 2007, Loss 34.089634, Params tensor([1.9055, 0.0984])\n",
      "Epoch 2008, Loss 34.084164, Params tensor([1.9057, 0.0984])\n",
      "Epoch 2009, Loss 34.078705, Params tensor([1.9059, 0.0984])\n",
      "Epoch 2010, Loss 34.073254, Params tensor([1.9062, 0.0985])\n",
      "Epoch 2011, Loss 34.067810, Params tensor([1.9064, 0.0985])\n",
      "Epoch 2012, Loss 34.062378, Params tensor([1.9066, 0.0985])\n",
      "Epoch 2013, Loss 34.056946, Params tensor([1.9069, 0.0985])\n",
      "Epoch 2014, Loss 34.051517, Params tensor([1.9071, 0.0985])\n",
      "Epoch 2015, Loss 34.046097, Params tensor([1.9073, 0.0985])\n",
      "Epoch 2016, Loss 34.040691, Params tensor([1.9075, 0.0985])\n",
      "Epoch 2017, Loss 34.035282, Params tensor([1.9078, 0.0985])\n",
      "Epoch 2018, Loss 34.029884, Params tensor([1.9080, 0.0985])\n",
      "Epoch 2019, Loss 34.024490, Params tensor([1.9082, 0.0986])\n",
      "Epoch 2020, Loss 34.019108, Params tensor([1.9085, 0.0986])\n",
      "Epoch 2021, Loss 34.013733, Params tensor([1.9087, 0.0986])\n",
      "Epoch 2022, Loss 34.008358, Params tensor([1.9089, 0.0986])\n",
      "Epoch 2023, Loss 34.002991, Params tensor([1.9092, 0.0986])\n",
      "Epoch 2024, Loss 33.997631, Params tensor([1.9094, 0.0986])\n",
      "Epoch 2025, Loss 33.992283, Params tensor([1.9096, 0.0986])\n",
      "Epoch 2026, Loss 33.986935, Params tensor([1.9099, 0.0986])\n",
      "Epoch 2027, Loss 33.981590, Params tensor([1.9101, 0.0986])\n",
      "Epoch 2028, Loss 33.976254, Params tensor([1.9103, 0.0986])\n",
      "Epoch 2029, Loss 33.970928, Params tensor([1.9106, 0.0987])\n",
      "Epoch 2030, Loss 33.965603, Params tensor([1.9108, 0.0987])\n",
      "Epoch 2031, Loss 33.960293, Params tensor([1.9110, 0.0987])\n",
      "Epoch 2032, Loss 33.954975, Params tensor([1.9112, 0.0987])\n",
      "Epoch 2033, Loss 33.949680, Params tensor([1.9115, 0.0987])\n",
      "Epoch 2034, Loss 33.944382, Params tensor([1.9117, 0.0987])\n",
      "Epoch 2035, Loss 33.939098, Params tensor([1.9119, 0.0987])\n",
      "Epoch 2036, Loss 33.933807, Params tensor([1.9122, 0.0987])\n",
      "Epoch 2037, Loss 33.928528, Params tensor([1.9124, 0.0987])\n",
      "Epoch 2038, Loss 33.923252, Params tensor([1.9126, 0.0987])\n",
      "Epoch 2039, Loss 33.917995, Params tensor([1.9129, 0.0988])\n",
      "Epoch 2040, Loss 33.912739, Params tensor([1.9131, 0.0988])\n",
      "Epoch 2041, Loss 33.907482, Params tensor([1.9133, 0.0988])\n",
      "Epoch 2042, Loss 33.902237, Params tensor([1.9135, 0.0988])\n",
      "Epoch 2043, Loss 33.896999, Params tensor([1.9138, 0.0988])\n",
      "Epoch 2044, Loss 33.891758, Params tensor([1.9140, 0.0988])\n",
      "Epoch 2045, Loss 33.886532, Params tensor([1.9142, 0.0988])\n",
      "Epoch 2046, Loss 33.881317, Params tensor([1.9145, 0.0988])\n",
      "Epoch 2047, Loss 33.876102, Params tensor([1.9147, 0.0988])\n",
      "Epoch 2048, Loss 33.870892, Params tensor([1.9149, 0.0988])\n",
      "Epoch 2049, Loss 33.865688, Params tensor([1.9151, 0.0989])\n",
      "Epoch 2050, Loss 33.860489, Params tensor([1.9154, 0.0989])\n",
      "Epoch 2051, Loss 33.855301, Params tensor([1.9156, 0.0989])\n",
      "Epoch 2052, Loss 33.850117, Params tensor([1.9158, 0.0989])\n",
      "Epoch 2053, Loss 33.844936, Params tensor([1.9160, 0.0989])\n",
      "Epoch 2054, Loss 33.839767, Params tensor([1.9163, 0.0989])\n",
      "Epoch 2055, Loss 33.834606, Params tensor([1.9165, 0.0989])\n",
      "Epoch 2056, Loss 33.829441, Params tensor([1.9167, 0.0989])\n",
      "Epoch 2057, Loss 33.824291, Params tensor([1.9170, 0.0989])\n",
      "Epoch 2058, Loss 33.819141, Params tensor([1.9172, 0.0989])\n",
      "Epoch 2059, Loss 33.813995, Params tensor([1.9174, 0.0989])\n",
      "Epoch 2060, Loss 33.808865, Params tensor([1.9176, 0.0990])\n",
      "Epoch 2061, Loss 33.803738, Params tensor([1.9179, 0.0990])\n",
      "Epoch 2062, Loss 33.798615, Params tensor([1.9181, 0.0990])\n",
      "Epoch 2063, Loss 33.793495, Params tensor([1.9183, 0.0990])\n",
      "Epoch 2064, Loss 33.788387, Params tensor([1.9185, 0.0990])\n",
      "Epoch 2065, Loss 33.783287, Params tensor([1.9188, 0.0990])\n",
      "Epoch 2066, Loss 33.778187, Params tensor([1.9190, 0.0990])\n",
      "Epoch 2067, Loss 33.773087, Params tensor([1.9192, 0.0990])\n",
      "Epoch 2068, Loss 33.768005, Params tensor([1.9194, 0.0990])\n",
      "Epoch 2069, Loss 33.762924, Params tensor([1.9197, 0.0990])\n",
      "Epoch 2070, Loss 33.757847, Params tensor([1.9199, 0.0990])\n",
      "Epoch 2071, Loss 33.752781, Params tensor([1.9201, 0.0991])\n",
      "Epoch 2072, Loss 33.747723, Params tensor([1.9203, 0.0991])\n",
      "Epoch 2073, Loss 33.742672, Params tensor([1.9206, 0.0991])\n",
      "Epoch 2074, Loss 33.737614, Params tensor([1.9208, 0.0991])\n",
      "Epoch 2075, Loss 33.732571, Params tensor([1.9210, 0.0991])\n",
      "Epoch 2076, Loss 33.727531, Params tensor([1.9212, 0.0991])\n",
      "Epoch 2077, Loss 33.722500, Params tensor([1.9215, 0.0991])\n",
      "Epoch 2078, Loss 33.717472, Params tensor([1.9217, 0.0991])\n",
      "Epoch 2079, Loss 33.712463, Params tensor([1.9219, 0.0991])\n",
      "Epoch 2080, Loss 33.707443, Params tensor([1.9221, 0.0991])\n",
      "Epoch 2081, Loss 33.702435, Params tensor([1.9224, 0.0991])\n",
      "Epoch 2082, Loss 33.697433, Params tensor([1.9226, 0.0992])\n",
      "Epoch 2083, Loss 33.692432, Params tensor([1.9228, 0.0992])\n",
      "Epoch 2084, Loss 33.687443, Params tensor([1.9230, 0.0992])\n",
      "Epoch 2085, Loss 33.682461, Params tensor([1.9232, 0.0992])\n",
      "Epoch 2086, Loss 33.677486, Params tensor([1.9235, 0.0992])\n",
      "Epoch 2087, Loss 33.672516, Params tensor([1.9237, 0.0992])\n",
      "Epoch 2088, Loss 33.667549, Params tensor([1.9239, 0.0992])\n",
      "Epoch 2089, Loss 33.662586, Params tensor([1.9241, 0.0992])\n",
      "Epoch 2090, Loss 33.657635, Params tensor([1.9244, 0.0992])\n",
      "Epoch 2091, Loss 33.652679, Params tensor([1.9246, 0.0992])\n",
      "Epoch 2092, Loss 33.647739, Params tensor([1.9248, 0.0992])\n",
      "Epoch 2093, Loss 33.642807, Params tensor([1.9250, 0.0993])\n",
      "Epoch 2094, Loss 33.637875, Params tensor([1.9253, 0.0993])\n",
      "Epoch 2095, Loss 33.632938, Params tensor([1.9255, 0.0993])\n",
      "Epoch 2096, Loss 33.628025, Params tensor([1.9257, 0.0993])\n",
      "Epoch 2097, Loss 33.623112, Params tensor([1.9259, 0.0993])\n",
      "Epoch 2098, Loss 33.618210, Params tensor([1.9261, 0.0993])\n",
      "Epoch 2099, Loss 33.613308, Params tensor([1.9264, 0.0993])\n",
      "Epoch 2100, Loss 33.608414, Params tensor([1.9266, 0.0993])\n",
      "Epoch 2101, Loss 33.603527, Params tensor([1.9268, 0.0993])\n",
      "Epoch 2102, Loss 33.598637, Params tensor([1.9270, 0.0993])\n",
      "Epoch 2103, Loss 33.593754, Params tensor([1.9272, 0.0993])\n",
      "Epoch 2104, Loss 33.588882, Params tensor([1.9275, 0.0993])\n",
      "Epoch 2105, Loss 33.584011, Params tensor([1.9277, 0.0994])\n",
      "Epoch 2106, Loss 33.579159, Params tensor([1.9279, 0.0994])\n",
      "Epoch 2107, Loss 33.574303, Params tensor([1.9281, 0.0994])\n",
      "Epoch 2108, Loss 33.569450, Params tensor([1.9283, 0.0994])\n",
      "Epoch 2109, Loss 33.564610, Params tensor([1.9286, 0.0994])\n",
      "Epoch 2110, Loss 33.559772, Params tensor([1.9288, 0.0994])\n",
      "Epoch 2111, Loss 33.554935, Params tensor([1.9290, 0.0994])\n",
      "Epoch 2112, Loss 33.550114, Params tensor([1.9292, 0.0994])\n",
      "Epoch 2113, Loss 33.545292, Params tensor([1.9294, 0.0994])\n",
      "Epoch 2114, Loss 33.540478, Params tensor([1.9297, 0.0994])\n",
      "Epoch 2115, Loss 33.535667, Params tensor([1.9299, 0.0994])\n",
      "Epoch 2116, Loss 33.530861, Params tensor([1.9301, 0.0994])\n",
      "Epoch 2117, Loss 33.526062, Params tensor([1.9303, 0.0995])\n",
      "Epoch 2118, Loss 33.521275, Params tensor([1.9305, 0.0995])\n",
      "Epoch 2119, Loss 33.516487, Params tensor([1.9308, 0.0995])\n",
      "Epoch 2120, Loss 33.511703, Params tensor([1.9310, 0.0995])\n",
      "Epoch 2121, Loss 33.506935, Params tensor([1.9312, 0.0995])\n",
      "Epoch 2122, Loss 33.502163, Params tensor([1.9314, 0.0995])\n",
      "Epoch 2123, Loss 33.497402, Params tensor([1.9316, 0.0995])\n",
      "Epoch 2124, Loss 33.492641, Params tensor([1.9318, 0.0995])\n",
      "Epoch 2125, Loss 33.487888, Params tensor([1.9321, 0.0995])\n",
      "Epoch 2126, Loss 33.483139, Params tensor([1.9323, 0.0995])\n",
      "Epoch 2127, Loss 33.478394, Params tensor([1.9325, 0.0995])\n",
      "Epoch 2128, Loss 33.473667, Params tensor([1.9327, 0.0995])\n",
      "Epoch 2129, Loss 33.468933, Params tensor([1.9329, 0.0995])\n",
      "Epoch 2130, Loss 33.464207, Params tensor([1.9331, 0.0996])\n",
      "Epoch 2131, Loss 33.459488, Params tensor([1.9334, 0.0996])\n",
      "Epoch 2132, Loss 33.454781, Params tensor([1.9336, 0.0996])\n",
      "Epoch 2133, Loss 33.450073, Params tensor([1.9338, 0.0996])\n",
      "Epoch 2134, Loss 33.445374, Params tensor([1.9340, 0.0996])\n",
      "Epoch 2135, Loss 33.440678, Params tensor([1.9342, 0.0996])\n",
      "Epoch 2136, Loss 33.435982, Params tensor([1.9344, 0.0996])\n",
      "Epoch 2137, Loss 33.431297, Params tensor([1.9347, 0.0996])\n",
      "Epoch 2138, Loss 33.426620, Params tensor([1.9349, 0.0996])\n",
      "Epoch 2139, Loss 33.421947, Params tensor([1.9351, 0.0996])\n",
      "Epoch 2140, Loss 33.417274, Params tensor([1.9353, 0.0996])\n",
      "Epoch 2141, Loss 33.412613, Params tensor([1.9355, 0.0996])\n",
      "Epoch 2142, Loss 33.407959, Params tensor([1.9357, 0.0996])\n",
      "Epoch 2143, Loss 33.403301, Params tensor([1.9360, 0.0997])\n",
      "Epoch 2144, Loss 33.398659, Params tensor([1.9362, 0.0997])\n",
      "Epoch 2145, Loss 33.394020, Params tensor([1.9364, 0.0997])\n",
      "Epoch 2146, Loss 33.389389, Params tensor([1.9366, 0.0997])\n",
      "Epoch 2147, Loss 33.384754, Params tensor([1.9368, 0.0997])\n",
      "Epoch 2148, Loss 33.380131, Params tensor([1.9370, 0.0997])\n",
      "Epoch 2149, Loss 33.375515, Params tensor([1.9372, 0.0997])\n",
      "Epoch 2150, Loss 33.370899, Params tensor([1.9375, 0.0997])\n",
      "Epoch 2151, Loss 33.366287, Params tensor([1.9377, 0.0997])\n",
      "Epoch 2152, Loss 33.361694, Params tensor([1.9379, 0.0997])\n",
      "Epoch 2153, Loss 33.357094, Params tensor([1.9381, 0.0997])\n",
      "Epoch 2154, Loss 33.352505, Params tensor([1.9383, 0.0997])\n",
      "Epoch 2155, Loss 33.347912, Params tensor([1.9385, 0.0997])\n",
      "Epoch 2156, Loss 33.343334, Params tensor([1.9387, 0.0997])\n",
      "Epoch 2157, Loss 33.338757, Params tensor([1.9390, 0.0998])\n",
      "Epoch 2158, Loss 33.334190, Params tensor([1.9392, 0.0998])\n",
      "Epoch 2159, Loss 33.329628, Params tensor([1.9394, 0.0998])\n",
      "Epoch 2160, Loss 33.325069, Params tensor([1.9396, 0.0998])\n",
      "Epoch 2161, Loss 33.320518, Params tensor([1.9398, 0.0998])\n",
      "Epoch 2162, Loss 33.315971, Params tensor([1.9400, 0.0998])\n",
      "Epoch 2163, Loss 33.311428, Params tensor([1.9402, 0.0998])\n",
      "Epoch 2164, Loss 33.306892, Params tensor([1.9405, 0.0998])\n",
      "Epoch 2165, Loss 33.302364, Params tensor([1.9407, 0.0998])\n",
      "Epoch 2166, Loss 33.297836, Params tensor([1.9409, 0.0998])\n",
      "Epoch 2167, Loss 33.293320, Params tensor([1.9411, 0.0998])\n",
      "Epoch 2168, Loss 33.288795, Params tensor([1.9413, 0.0998])\n",
      "Epoch 2169, Loss 33.284286, Params tensor([1.9415, 0.0998])\n",
      "Epoch 2170, Loss 33.279785, Params tensor([1.9417, 0.0998])\n",
      "Epoch 2171, Loss 33.275284, Params tensor([1.9419, 0.0999])\n",
      "Epoch 2172, Loss 33.270786, Params tensor([1.9422, 0.0999])\n",
      "Epoch 2173, Loss 33.266296, Params tensor([1.9424, 0.0999])\n",
      "Epoch 2174, Loss 33.261814, Params tensor([1.9426, 0.0999])\n",
      "Epoch 2175, Loss 33.257336, Params tensor([1.9428, 0.0999])\n",
      "Epoch 2176, Loss 33.252865, Params tensor([1.9430, 0.0999])\n",
      "Epoch 2177, Loss 33.248398, Params tensor([1.9432, 0.0999])\n",
      "Epoch 2178, Loss 33.243935, Params tensor([1.9434, 0.0999])\n",
      "Epoch 2179, Loss 33.239479, Params tensor([1.9436, 0.0999])\n",
      "Epoch 2180, Loss 33.235031, Params tensor([1.9438, 0.0999])\n",
      "Epoch 2181, Loss 33.230583, Params tensor([1.9441, 0.0999])\n",
      "Epoch 2182, Loss 33.226151, Params tensor([1.9443, 0.0999])\n",
      "Epoch 2183, Loss 33.221710, Params tensor([1.9445, 0.0999])\n",
      "Epoch 2184, Loss 33.217281, Params tensor([1.9447, 0.0999])\n",
      "Epoch 2185, Loss 33.212852, Params tensor([1.9449, 0.0999])\n",
      "Epoch 2186, Loss 33.208431, Params tensor([1.9451, 0.1000])\n",
      "Epoch 2187, Loss 33.204018, Params tensor([1.9453, 0.1000])\n",
      "Epoch 2188, Loss 33.199612, Params tensor([1.9455, 0.1000])\n",
      "Epoch 2189, Loss 33.195206, Params tensor([1.9457, 0.1000])\n",
      "Epoch 2190, Loss 33.190804, Params tensor([1.9459, 0.1000])\n",
      "Epoch 2191, Loss 33.186413, Params tensor([1.9462, 0.1000])\n",
      "Epoch 2192, Loss 33.182022, Params tensor([1.9464, 0.1000])\n",
      "Epoch 2193, Loss 33.177635, Params tensor([1.9466, 0.1000])\n",
      "Epoch 2194, Loss 33.173264, Params tensor([1.9468, 0.1000])\n",
      "Epoch 2195, Loss 33.168884, Params tensor([1.9470, 0.1000])\n",
      "Epoch 2196, Loss 33.164516, Params tensor([1.9472, 0.1000])\n",
      "Epoch 2197, Loss 33.160152, Params tensor([1.9474, 0.1000])\n",
      "Epoch 2198, Loss 33.155800, Params tensor([1.9476, 0.1000])\n",
      "Epoch 2199, Loss 33.151451, Params tensor([1.9478, 0.1000])\n",
      "Epoch 2200, Loss 33.147099, Params tensor([1.9480, 0.1000])\n",
      "Epoch 2201, Loss 33.142761, Params tensor([1.9482, 0.1000])\n",
      "Epoch 2202, Loss 33.138424, Params tensor([1.9484, 0.1001])\n",
      "Epoch 2203, Loss 33.134098, Params tensor([1.9487, 0.1001])\n",
      "Epoch 2204, Loss 33.129765, Params tensor([1.9489, 0.1001])\n",
      "Epoch 2205, Loss 33.125450, Params tensor([1.9491, 0.1001])\n",
      "Epoch 2206, Loss 33.121128, Params tensor([1.9493, 0.1001])\n",
      "Epoch 2207, Loss 33.116825, Params tensor([1.9495, 0.1001])\n",
      "Epoch 2208, Loss 33.112518, Params tensor([1.9497, 0.1001])\n",
      "Epoch 2209, Loss 33.108219, Params tensor([1.9499, 0.1001])\n",
      "Epoch 2210, Loss 33.103920, Params tensor([1.9501, 0.1001])\n",
      "Epoch 2211, Loss 33.099636, Params tensor([1.9503, 0.1001])\n",
      "Epoch 2212, Loss 33.095348, Params tensor([1.9505, 0.1001])\n",
      "Epoch 2213, Loss 33.091068, Params tensor([1.9507, 0.1001])\n",
      "Epoch 2214, Loss 33.086788, Params tensor([1.9509, 0.1001])\n",
      "Epoch 2215, Loss 33.082520, Params tensor([1.9511, 0.1001])\n",
      "Epoch 2216, Loss 33.078259, Params tensor([1.9513, 0.1001])\n",
      "Epoch 2217, Loss 33.073997, Params tensor([1.9516, 0.1001])\n",
      "Epoch 2218, Loss 33.069736, Params tensor([1.9518, 0.1002])\n",
      "Epoch 2219, Loss 33.065491, Params tensor([1.9520, 0.1002])\n",
      "Epoch 2220, Loss 33.061245, Params tensor([1.9522, 0.1002])\n",
      "Epoch 2221, Loss 33.057011, Params tensor([1.9524, 0.1002])\n",
      "Epoch 2222, Loss 33.052769, Params tensor([1.9526, 0.1002])\n",
      "Epoch 2223, Loss 33.048538, Params tensor([1.9528, 0.1002])\n",
      "Epoch 2224, Loss 33.044315, Params tensor([1.9530, 0.1002])\n",
      "Epoch 2225, Loss 33.040096, Params tensor([1.9532, 0.1002])\n",
      "Epoch 2226, Loss 33.035877, Params tensor([1.9534, 0.1002])\n",
      "Epoch 2227, Loss 33.031670, Params tensor([1.9536, 0.1002])\n",
      "Epoch 2228, Loss 33.027462, Params tensor([1.9538, 0.1002])\n",
      "Epoch 2229, Loss 33.023266, Params tensor([1.9540, 0.1002])\n",
      "Epoch 2230, Loss 33.019070, Params tensor([1.9542, 0.1002])\n",
      "Epoch 2231, Loss 33.014877, Params tensor([1.9544, 0.1002])\n",
      "Epoch 2232, Loss 33.010693, Params tensor([1.9546, 0.1002])\n",
      "Epoch 2233, Loss 33.006512, Params tensor([1.9548, 0.1002])\n",
      "Epoch 2234, Loss 33.002335, Params tensor([1.9550, 0.1002])\n",
      "Epoch 2235, Loss 32.998165, Params tensor([1.9552, 0.1002])\n",
      "Epoch 2236, Loss 32.993996, Params tensor([1.9554, 0.1003])\n",
      "Epoch 2237, Loss 32.989838, Params tensor([1.9557, 0.1003])\n",
      "Epoch 2238, Loss 32.985687, Params tensor([1.9559, 0.1003])\n",
      "Epoch 2239, Loss 32.981533, Params tensor([1.9561, 0.1003])\n",
      "Epoch 2240, Loss 32.977386, Params tensor([1.9563, 0.1003])\n",
      "Epoch 2241, Loss 32.973244, Params tensor([1.9565, 0.1003])\n",
      "Epoch 2242, Loss 32.969112, Params tensor([1.9567, 0.1003])\n",
      "Epoch 2243, Loss 32.964981, Params tensor([1.9569, 0.1003])\n",
      "Epoch 2244, Loss 32.960850, Params tensor([1.9571, 0.1003])\n",
      "Epoch 2245, Loss 32.956722, Params tensor([1.9573, 0.1003])\n",
      "Epoch 2246, Loss 32.952614, Params tensor([1.9575, 0.1003])\n",
      "Epoch 2247, Loss 32.948498, Params tensor([1.9577, 0.1003])\n",
      "Epoch 2248, Loss 32.944393, Params tensor([1.9579, 0.1003])\n",
      "Epoch 2249, Loss 32.940292, Params tensor([1.9581, 0.1003])\n",
      "Epoch 2250, Loss 32.936192, Params tensor([1.9583, 0.1003])\n",
      "Epoch 2251, Loss 32.932106, Params tensor([1.9585, 0.1003])\n",
      "Epoch 2252, Loss 32.928020, Params tensor([1.9587, 0.1003])\n",
      "Epoch 2253, Loss 32.923943, Params tensor([1.9589, 0.1003])\n",
      "Epoch 2254, Loss 32.919865, Params tensor([1.9591, 0.1003])\n",
      "Epoch 2255, Loss 32.915787, Params tensor([1.9593, 0.1004])\n",
      "Epoch 2256, Loss 32.911720, Params tensor([1.9595, 0.1004])\n",
      "Epoch 2257, Loss 32.907665, Params tensor([1.9597, 0.1004])\n",
      "Epoch 2258, Loss 32.903606, Params tensor([1.9599, 0.1004])\n",
      "Epoch 2259, Loss 32.899559, Params tensor([1.9601, 0.1004])\n",
      "Epoch 2260, Loss 32.895512, Params tensor([1.9603, 0.1004])\n",
      "Epoch 2261, Loss 32.891464, Params tensor([1.9605, 0.1004])\n",
      "Epoch 2262, Loss 32.887428, Params tensor([1.9607, 0.1004])\n",
      "Epoch 2263, Loss 32.883396, Params tensor([1.9609, 0.1004])\n",
      "Epoch 2264, Loss 32.879360, Params tensor([1.9611, 0.1004])\n",
      "Epoch 2265, Loss 32.875343, Params tensor([1.9613, 0.1004])\n",
      "Epoch 2266, Loss 32.871319, Params tensor([1.9615, 0.1004])\n",
      "Epoch 2267, Loss 32.867306, Params tensor([1.9617, 0.1004])\n",
      "Epoch 2268, Loss 32.863289, Params tensor([1.9619, 0.1004])\n",
      "Epoch 2269, Loss 32.859283, Params tensor([1.9621, 0.1004])\n",
      "Epoch 2270, Loss 32.855282, Params tensor([1.9623, 0.1004])\n",
      "Epoch 2271, Loss 32.851284, Params tensor([1.9625, 0.1004])\n",
      "Epoch 2272, Loss 32.847294, Params tensor([1.9627, 0.1004])\n",
      "Epoch 2273, Loss 32.843307, Params tensor([1.9629, 0.1004])\n",
      "Epoch 2274, Loss 32.839329, Params tensor([1.9631, 0.1004])\n",
      "Epoch 2275, Loss 32.835346, Params tensor([1.9633, 0.1004])\n",
      "Epoch 2276, Loss 32.831375, Params tensor([1.9635, 0.1005])\n",
      "Epoch 2277, Loss 32.827408, Params tensor([1.9637, 0.1005])\n",
      "Epoch 2278, Loss 32.823444, Params tensor([1.9639, 0.1005])\n",
      "Epoch 2279, Loss 32.819485, Params tensor([1.9641, 0.1005])\n",
      "Epoch 2280, Loss 32.815536, Params tensor([1.9643, 0.1005])\n",
      "Epoch 2281, Loss 32.811581, Params tensor([1.9645, 0.1005])\n",
      "Epoch 2282, Loss 32.807640, Params tensor([1.9647, 0.1005])\n",
      "Epoch 2283, Loss 32.803696, Params tensor([1.9649, 0.1005])\n",
      "Epoch 2284, Loss 32.799767, Params tensor([1.9651, 0.1005])\n",
      "Epoch 2285, Loss 32.795834, Params tensor([1.9653, 0.1005])\n",
      "Epoch 2286, Loss 32.791904, Params tensor([1.9655, 0.1005])\n",
      "Epoch 2287, Loss 32.787991, Params tensor([1.9657, 0.1005])\n",
      "Epoch 2288, Loss 32.784073, Params tensor([1.9659, 0.1005])\n",
      "Epoch 2289, Loss 32.780163, Params tensor([1.9661, 0.1005])\n",
      "Epoch 2290, Loss 32.776249, Params tensor([1.9663, 0.1005])\n",
      "Epoch 2291, Loss 32.772354, Params tensor([1.9665, 0.1005])\n",
      "Epoch 2292, Loss 32.768456, Params tensor([1.9667, 0.1005])\n",
      "Epoch 2293, Loss 32.764565, Params tensor([1.9669, 0.1005])\n",
      "Epoch 2294, Loss 32.760666, Params tensor([1.9671, 0.1005])\n",
      "Epoch 2295, Loss 32.756790, Params tensor([1.9673, 0.1005])\n",
      "Epoch 2296, Loss 32.752911, Params tensor([1.9675, 0.1005])\n",
      "Epoch 2297, Loss 32.749031, Params tensor([1.9677, 0.1005])\n",
      "Epoch 2298, Loss 32.745163, Params tensor([1.9679, 0.1005])\n",
      "Epoch 2299, Loss 32.741306, Params tensor([1.9681, 0.1006])\n",
      "Epoch 2300, Loss 32.737438, Params tensor([1.9683, 0.1006])\n",
      "Epoch 2301, Loss 32.733582, Params tensor([1.9684, 0.1006])\n",
      "Epoch 2302, Loss 32.729733, Params tensor([1.9686, 0.1006])\n",
      "Epoch 2303, Loss 32.725887, Params tensor([1.9688, 0.1006])\n",
      "Epoch 2304, Loss 32.722050, Params tensor([1.9690, 0.1006])\n",
      "Epoch 2305, Loss 32.718212, Params tensor([1.9692, 0.1006])\n",
      "Epoch 2306, Loss 32.714371, Params tensor([1.9694, 0.1006])\n",
      "Epoch 2307, Loss 32.710548, Params tensor([1.9696, 0.1006])\n",
      "Epoch 2308, Loss 32.706730, Params tensor([1.9698, 0.1006])\n",
      "Epoch 2309, Loss 32.702908, Params tensor([1.9700, 0.1006])\n",
      "Epoch 2310, Loss 32.699089, Params tensor([1.9702, 0.1006])\n",
      "Epoch 2311, Loss 32.695274, Params tensor([1.9704, 0.1006])\n",
      "Epoch 2312, Loss 32.691475, Params tensor([1.9706, 0.1006])\n",
      "Epoch 2313, Loss 32.687679, Params tensor([1.9708, 0.1006])\n",
      "Epoch 2314, Loss 32.683872, Params tensor([1.9710, 0.1006])\n",
      "Epoch 2315, Loss 32.680084, Params tensor([1.9712, 0.1006])\n",
      "Epoch 2316, Loss 32.676296, Params tensor([1.9714, 0.1006])\n",
      "Epoch 2317, Loss 32.672512, Params tensor([1.9716, 0.1006])\n",
      "Epoch 2318, Loss 32.668732, Params tensor([1.9718, 0.1006])\n",
      "Epoch 2319, Loss 32.664959, Params tensor([1.9720, 0.1006])\n",
      "Epoch 2320, Loss 32.661182, Params tensor([1.9722, 0.1006])\n",
      "Epoch 2321, Loss 32.657421, Params tensor([1.9724, 0.1006])\n",
      "Epoch 2322, Loss 32.653656, Params tensor([1.9725, 0.1006])\n",
      "Epoch 2323, Loss 32.649899, Params tensor([1.9727, 0.1006])\n",
      "Epoch 2324, Loss 32.646149, Params tensor([1.9729, 0.1006])\n",
      "Epoch 2325, Loss 32.642399, Params tensor([1.9731, 0.1007])\n",
      "Epoch 2326, Loss 32.638657, Params tensor([1.9733, 0.1007])\n",
      "Epoch 2327, Loss 32.634918, Params tensor([1.9735, 0.1007])\n",
      "Epoch 2328, Loss 32.631184, Params tensor([1.9737, 0.1007])\n",
      "Epoch 2329, Loss 32.627449, Params tensor([1.9739, 0.1007])\n",
      "Epoch 2330, Loss 32.623730, Params tensor([1.9741, 0.1007])\n",
      "Epoch 2331, Loss 32.620010, Params tensor([1.9743, 0.1007])\n",
      "Epoch 2332, Loss 32.616295, Params tensor([1.9745, 0.1007])\n",
      "Epoch 2333, Loss 32.612583, Params tensor([1.9747, 0.1007])\n",
      "Epoch 2334, Loss 32.608871, Params tensor([1.9749, 0.1007])\n",
      "Epoch 2335, Loss 32.605167, Params tensor([1.9751, 0.1007])\n",
      "Epoch 2336, Loss 32.601475, Params tensor([1.9752, 0.1007])\n",
      "Epoch 2337, Loss 32.597775, Params tensor([1.9754, 0.1007])\n",
      "Epoch 2338, Loss 32.594086, Params tensor([1.9756, 0.1007])\n",
      "Epoch 2339, Loss 32.590397, Params tensor([1.9758, 0.1007])\n",
      "Epoch 2340, Loss 32.586727, Params tensor([1.9760, 0.1007])\n",
      "Epoch 2341, Loss 32.583038, Params tensor([1.9762, 0.1007])\n",
      "Epoch 2342, Loss 32.579365, Params tensor([1.9764, 0.1007])\n",
      "Epoch 2343, Loss 32.575695, Params tensor([1.9766, 0.1007])\n",
      "Epoch 2344, Loss 32.572025, Params tensor([1.9768, 0.1007])\n",
      "Epoch 2345, Loss 32.568363, Params tensor([1.9770, 0.1007])\n",
      "Epoch 2346, Loss 32.564713, Params tensor([1.9772, 0.1007])\n",
      "Epoch 2347, Loss 32.561062, Params tensor([1.9774, 0.1007])\n",
      "Epoch 2348, Loss 32.557415, Params tensor([1.9775, 0.1007])\n",
      "Epoch 2349, Loss 32.553772, Params tensor([1.9777, 0.1007])\n",
      "Epoch 2350, Loss 32.550137, Params tensor([1.9779, 0.1007])\n",
      "Epoch 2351, Loss 32.546497, Params tensor([1.9781, 0.1007])\n",
      "Epoch 2352, Loss 32.542870, Params tensor([1.9783, 0.1007])\n",
      "Epoch 2353, Loss 32.539246, Params tensor([1.9785, 0.1007])\n",
      "Epoch 2354, Loss 32.535622, Params tensor([1.9787, 0.1007])\n",
      "Epoch 2355, Loss 32.532009, Params tensor([1.9789, 0.1007])\n",
      "Epoch 2356, Loss 32.528393, Params tensor([1.9791, 0.1008])\n",
      "Epoch 2357, Loss 32.524788, Params tensor([1.9793, 0.1008])\n",
      "Epoch 2358, Loss 32.521175, Params tensor([1.9794, 0.1008])\n",
      "Epoch 2359, Loss 32.517582, Params tensor([1.9796, 0.1008])\n",
      "Epoch 2360, Loss 32.513985, Params tensor([1.9798, 0.1008])\n",
      "Epoch 2361, Loss 32.510387, Params tensor([1.9800, 0.1008])\n",
      "Epoch 2362, Loss 32.506802, Params tensor([1.9802, 0.1008])\n",
      "Epoch 2363, Loss 32.503216, Params tensor([1.9804, 0.1008])\n",
      "Epoch 2364, Loss 32.499641, Params tensor([1.9806, 0.1008])\n",
      "Epoch 2365, Loss 32.496059, Params tensor([1.9808, 0.1008])\n",
      "Epoch 2366, Loss 32.492500, Params tensor([1.9810, 0.1008])\n",
      "Epoch 2367, Loss 32.488930, Params tensor([1.9811, 0.1008])\n",
      "Epoch 2368, Loss 32.485367, Params tensor([1.9813, 0.1008])\n",
      "Epoch 2369, Loss 32.481815, Params tensor([1.9815, 0.1008])\n",
      "Epoch 2370, Loss 32.478260, Params tensor([1.9817, 0.1008])\n",
      "Epoch 2371, Loss 32.474712, Params tensor([1.9819, 0.1008])\n",
      "Epoch 2372, Loss 32.471161, Params tensor([1.9821, 0.1008])\n",
      "Epoch 2373, Loss 32.467625, Params tensor([1.9823, 0.1008])\n",
      "Epoch 2374, Loss 32.464085, Params tensor([1.9825, 0.1008])\n",
      "Epoch 2375, Loss 32.460552, Params tensor([1.9827, 0.1008])\n",
      "Epoch 2376, Loss 32.457027, Params tensor([1.9828, 0.1008])\n",
      "Epoch 2377, Loss 32.453506, Params tensor([1.9830, 0.1008])\n",
      "Epoch 2378, Loss 32.449978, Params tensor([1.9832, 0.1008])\n",
      "Epoch 2379, Loss 32.446461, Params tensor([1.9834, 0.1008])\n",
      "Epoch 2380, Loss 32.442951, Params tensor([1.9836, 0.1008])\n",
      "Epoch 2381, Loss 32.439442, Params tensor([1.9838, 0.1008])\n",
      "Epoch 2382, Loss 32.435940, Params tensor([1.9840, 0.1008])\n",
      "Epoch 2383, Loss 32.432442, Params tensor([1.9842, 0.1008])\n",
      "Epoch 2384, Loss 32.428951, Params tensor([1.9843, 0.1008])\n",
      "Epoch 2385, Loss 32.425453, Params tensor([1.9845, 0.1008])\n",
      "Epoch 2386, Loss 32.421970, Params tensor([1.9847, 0.1008])\n",
      "Epoch 2387, Loss 32.418488, Params tensor([1.9849, 0.1008])\n",
      "Epoch 2388, Loss 32.415009, Params tensor([1.9851, 0.1008])\n",
      "Epoch 2389, Loss 32.411533, Params tensor([1.9853, 0.1008])\n",
      "Epoch 2390, Loss 32.408058, Params tensor([1.9855, 0.1008])\n",
      "Epoch 2391, Loss 32.404598, Params tensor([1.9856, 0.1008])\n",
      "Epoch 2392, Loss 32.401131, Params tensor([1.9858, 0.1008])\n",
      "Epoch 2393, Loss 32.397675, Params tensor([1.9860, 0.1008])\n",
      "Epoch 2394, Loss 32.394222, Params tensor([1.9862, 0.1009])\n",
      "Epoch 2395, Loss 32.390774, Params tensor([1.9864, 0.1009])\n",
      "Epoch 2396, Loss 32.387325, Params tensor([1.9866, 0.1009])\n",
      "Epoch 2397, Loss 32.383884, Params tensor([1.9868, 0.1009])\n",
      "Epoch 2398, Loss 32.380447, Params tensor([1.9869, 0.1009])\n",
      "Epoch 2399, Loss 32.377010, Params tensor([1.9871, 0.1009])\n",
      "Epoch 2400, Loss 32.373581, Params tensor([1.9873, 0.1009])\n",
      "Epoch 2401, Loss 32.370155, Params tensor([1.9875, 0.1009])\n",
      "Epoch 2402, Loss 32.366734, Params tensor([1.9877, 0.1009])\n",
      "Epoch 2403, Loss 32.363316, Params tensor([1.9879, 0.1009])\n",
      "Epoch 2404, Loss 32.359901, Params tensor([1.9881, 0.1009])\n",
      "Epoch 2405, Loss 32.356495, Params tensor([1.9882, 0.1009])\n",
      "Epoch 2406, Loss 32.353088, Params tensor([1.9884, 0.1009])\n",
      "Epoch 2407, Loss 32.349686, Params tensor([1.9886, 0.1009])\n",
      "Epoch 2408, Loss 32.346287, Params tensor([1.9888, 0.1009])\n",
      "Epoch 2409, Loss 32.342899, Params tensor([1.9890, 0.1009])\n",
      "Epoch 2410, Loss 32.339508, Params tensor([1.9892, 0.1009])\n",
      "Epoch 2411, Loss 32.336121, Params tensor([1.9893, 0.1009])\n",
      "Epoch 2412, Loss 32.332745, Params tensor([1.9895, 0.1009])\n",
      "Epoch 2413, Loss 32.329361, Params tensor([1.9897, 0.1009])\n",
      "Epoch 2414, Loss 32.325989, Params tensor([1.9899, 0.1009])\n",
      "Epoch 2415, Loss 32.322617, Params tensor([1.9901, 0.1009])\n",
      "Epoch 2416, Loss 32.319252, Params tensor([1.9903, 0.1009])\n",
      "Epoch 2417, Loss 32.315895, Params tensor([1.9904, 0.1009])\n",
      "Epoch 2418, Loss 32.312534, Params tensor([1.9906, 0.1009])\n",
      "Epoch 2419, Loss 32.309181, Params tensor([1.9908, 0.1009])\n",
      "Epoch 2420, Loss 32.305832, Params tensor([1.9910, 0.1009])\n",
      "Epoch 2421, Loss 32.302486, Params tensor([1.9912, 0.1009])\n",
      "Epoch 2422, Loss 32.299137, Params tensor([1.9914, 0.1009])\n",
      "Epoch 2423, Loss 32.295807, Params tensor([1.9915, 0.1009])\n",
      "Epoch 2424, Loss 32.292469, Params tensor([1.9917, 0.1009])\n",
      "Epoch 2425, Loss 32.289143, Params tensor([1.9919, 0.1009])\n",
      "Epoch 2426, Loss 32.285824, Params tensor([1.9921, 0.1009])\n",
      "Epoch 2427, Loss 32.282497, Params tensor([1.9923, 0.1009])\n",
      "Epoch 2428, Loss 32.279175, Params tensor([1.9925, 0.1009])\n",
      "Epoch 2429, Loss 32.275860, Params tensor([1.9926, 0.1009])\n",
      "Epoch 2430, Loss 32.272552, Params tensor([1.9928, 0.1009])\n",
      "Epoch 2431, Loss 32.269249, Params tensor([1.9930, 0.1009])\n",
      "Epoch 2432, Loss 32.265942, Params tensor([1.9932, 0.1009])\n",
      "Epoch 2433, Loss 32.262642, Params tensor([1.9934, 0.1009])\n",
      "Epoch 2434, Loss 32.259346, Params tensor([1.9935, 0.1009])\n",
      "Epoch 2435, Loss 32.256058, Params tensor([1.9937, 0.1009])\n",
      "Epoch 2436, Loss 32.252769, Params tensor([1.9939, 0.1009])\n",
      "Epoch 2437, Loss 32.249485, Params tensor([1.9941, 0.1009])\n",
      "Epoch 2438, Loss 32.246208, Params tensor([1.9943, 0.1009])\n",
      "Epoch 2439, Loss 32.242931, Params tensor([1.9944, 0.1009])\n",
      "Epoch 2440, Loss 32.239666, Params tensor([1.9946, 0.1009])\n",
      "Epoch 2441, Loss 32.236393, Params tensor([1.9948, 0.1009])\n",
      "Epoch 2442, Loss 32.233131, Params tensor([1.9950, 0.1009])\n",
      "Epoch 2443, Loss 32.229870, Params tensor([1.9952, 0.1009])\n",
      "Epoch 2444, Loss 32.226612, Params tensor([1.9954, 0.1009])\n",
      "Epoch 2445, Loss 32.223354, Params tensor([1.9955, 0.1009])\n",
      "Epoch 2446, Loss 32.220119, Params tensor([1.9957, 0.1009])\n",
      "Epoch 2447, Loss 32.216866, Params tensor([1.9959, 0.1009])\n",
      "Epoch 2448, Loss 32.213627, Params tensor([1.9961, 0.1009])\n",
      "Epoch 2449, Loss 32.210392, Params tensor([1.9963, 0.1009])\n",
      "Epoch 2450, Loss 32.207157, Params tensor([1.9964, 0.1009])\n",
      "Epoch 2451, Loss 32.203922, Params tensor([1.9966, 0.1009])\n",
      "Epoch 2452, Loss 32.200699, Params tensor([1.9968, 0.1009])\n",
      "Epoch 2453, Loss 32.197475, Params tensor([1.9970, 0.1009])\n",
      "Epoch 2454, Loss 32.194260, Params tensor([1.9971, 0.1010])\n",
      "Epoch 2455, Loss 32.191048, Params tensor([1.9973, 0.1010])\n",
      "Epoch 2456, Loss 32.187836, Params tensor([1.9975, 0.1010])\n",
      "Epoch 2457, Loss 32.184635, Params tensor([1.9977, 0.1010])\n",
      "Epoch 2458, Loss 32.181431, Params tensor([1.9979, 0.1010])\n",
      "Epoch 2459, Loss 32.178230, Params tensor([1.9980, 0.1010])\n",
      "Epoch 2460, Loss 32.175034, Params tensor([1.9982, 0.1010])\n",
      "Epoch 2461, Loss 32.171841, Params tensor([1.9984, 0.1010])\n",
      "Epoch 2462, Loss 32.168652, Params tensor([1.9986, 0.1010])\n",
      "Epoch 2463, Loss 32.165470, Params tensor([1.9988, 0.1010])\n",
      "Epoch 2464, Loss 32.162292, Params tensor([1.9989, 0.1010])\n",
      "Epoch 2465, Loss 32.159115, Params tensor([1.9991, 0.1010])\n",
      "Epoch 2466, Loss 32.155941, Params tensor([1.9993, 0.1010])\n",
      "Epoch 2467, Loss 32.152767, Params tensor([1.9995, 0.1010])\n",
      "Epoch 2468, Loss 32.149605, Params tensor([1.9996, 0.1010])\n",
      "Epoch 2469, Loss 32.146446, Params tensor([1.9998, 0.1010])\n",
      "Epoch 2470, Loss 32.143284, Params tensor([2.0000, 0.1010])\n",
      "Epoch 2471, Loss 32.140133, Params tensor([2.0002, 0.1010])\n",
      "Epoch 2472, Loss 32.136982, Params tensor([2.0004, 0.1010])\n",
      "Epoch 2473, Loss 32.133835, Params tensor([2.0005, 0.1010])\n",
      "Epoch 2474, Loss 32.130692, Params tensor([2.0007, 0.1010])\n",
      "Epoch 2475, Loss 32.127552, Params tensor([2.0009, 0.1010])\n",
      "Epoch 2476, Loss 32.124416, Params tensor([2.0011, 0.1010])\n",
      "Epoch 2477, Loss 32.121292, Params tensor([2.0012, 0.1010])\n",
      "Epoch 2478, Loss 32.118156, Params tensor([2.0014, 0.1010])\n",
      "Epoch 2479, Loss 32.115025, Params tensor([2.0016, 0.1010])\n",
      "Epoch 2480, Loss 32.111912, Params tensor([2.0018, 0.1010])\n",
      "Epoch 2481, Loss 32.108791, Params tensor([2.0020, 0.1010])\n",
      "Epoch 2482, Loss 32.105679, Params tensor([2.0021, 0.1010])\n",
      "Epoch 2483, Loss 32.102570, Params tensor([2.0023, 0.1010])\n",
      "Epoch 2484, Loss 32.099461, Params tensor([2.0025, 0.1010])\n",
      "Epoch 2485, Loss 32.096359, Params tensor([2.0027, 0.1010])\n",
      "Epoch 2486, Loss 32.093262, Params tensor([2.0028, 0.1010])\n",
      "Epoch 2487, Loss 32.090164, Params tensor([2.0030, 0.1010])\n",
      "Epoch 2488, Loss 32.087074, Params tensor([2.0032, 0.1010])\n",
      "Epoch 2489, Loss 32.083988, Params tensor([2.0034, 0.1010])\n",
      "Epoch 2490, Loss 32.080898, Params tensor([2.0035, 0.1010])\n",
      "Epoch 2491, Loss 32.077824, Params tensor([2.0037, 0.1010])\n",
      "Epoch 2492, Loss 32.074741, Params tensor([2.0039, 0.1010])\n",
      "Epoch 2493, Loss 32.071671, Params tensor([2.0041, 0.1010])\n",
      "Epoch 2494, Loss 32.068600, Params tensor([2.0042, 0.1010])\n",
      "Epoch 2495, Loss 32.065536, Params tensor([2.0044, 0.1010])\n",
      "Epoch 2496, Loss 32.062477, Params tensor([2.0046, 0.1010])\n",
      "Epoch 2497, Loss 32.059410, Params tensor([2.0048, 0.1010])\n",
      "Epoch 2498, Loss 32.056362, Params tensor([2.0049, 0.1010])\n",
      "Epoch 2499, Loss 32.053303, Params tensor([2.0051, 0.1010])\n",
      "Epoch 2500, Loss 32.050255, Params tensor([2.0053, 0.1010])\n",
      "Epoch 2501, Loss 32.047215, Params tensor([2.0055, 0.1010])\n",
      "Epoch 2502, Loss 32.044174, Params tensor([2.0056, 0.1010])\n",
      "Epoch 2503, Loss 32.041134, Params tensor([2.0058, 0.1010])\n",
      "Epoch 2504, Loss 32.038101, Params tensor([2.0060, 0.1010])\n",
      "Epoch 2505, Loss 32.035069, Params tensor([2.0062, 0.1010])\n",
      "Epoch 2506, Loss 32.032040, Params tensor([2.0063, 0.1010])\n",
      "Epoch 2507, Loss 32.029018, Params tensor([2.0065, 0.1010])\n",
      "Epoch 2508, Loss 32.025997, Params tensor([2.0067, 0.1010])\n",
      "Epoch 2509, Loss 32.022984, Params tensor([2.0069, 0.1010])\n",
      "Epoch 2510, Loss 32.019970, Params tensor([2.0070, 0.1010])\n",
      "Epoch 2511, Loss 32.016960, Params tensor([2.0072, 0.1010])\n",
      "Epoch 2512, Loss 32.013954, Params tensor([2.0074, 0.1010])\n",
      "Epoch 2513, Loss 32.010952, Params tensor([2.0075, 0.1010])\n",
      "Epoch 2514, Loss 32.007950, Params tensor([2.0077, 0.1010])\n",
      "Epoch 2515, Loss 32.004959, Params tensor([2.0079, 0.1010])\n",
      "Epoch 2516, Loss 32.001968, Params tensor([2.0081, 0.1010])\n",
      "Epoch 2517, Loss 31.998985, Params tensor([2.0082, 0.1010])\n",
      "Epoch 2518, Loss 31.995995, Params tensor([2.0084, 0.1010])\n",
      "Epoch 2519, Loss 31.993013, Params tensor([2.0086, 0.1010])\n",
      "Epoch 2520, Loss 31.990028, Params tensor([2.0088, 0.1010])\n",
      "Epoch 2521, Loss 31.987061, Params tensor([2.0089, 0.1010])\n",
      "Epoch 2522, Loss 31.984100, Params tensor([2.0091, 0.1010])\n",
      "Epoch 2523, Loss 31.981134, Params tensor([2.0093, 0.1010])\n",
      "Epoch 2524, Loss 31.978161, Params tensor([2.0094, 0.1010])\n",
      "Epoch 2525, Loss 31.975201, Params tensor([2.0096, 0.1010])\n",
      "Epoch 2526, Loss 31.972246, Params tensor([2.0098, 0.1010])\n",
      "Epoch 2527, Loss 31.969294, Params tensor([2.0100, 0.1010])\n",
      "Epoch 2528, Loss 31.966347, Params tensor([2.0101, 0.1010])\n",
      "Epoch 2529, Loss 31.963402, Params tensor([2.0103, 0.1010])\n",
      "Epoch 2530, Loss 31.960455, Params tensor([2.0105, 0.1010])\n",
      "Epoch 2531, Loss 31.957520, Params tensor([2.0106, 0.1010])\n",
      "Epoch 2532, Loss 31.954578, Params tensor([2.0108, 0.1010])\n",
      "Epoch 2533, Loss 31.951654, Params tensor([2.0110, 0.1010])\n",
      "Epoch 2534, Loss 31.948723, Params tensor([2.0112, 0.1010])\n",
      "Epoch 2535, Loss 31.945795, Params tensor([2.0113, 0.1010])\n",
      "Epoch 2536, Loss 31.942873, Params tensor([2.0115, 0.1010])\n",
      "Epoch 2537, Loss 31.939959, Params tensor([2.0117, 0.1010])\n",
      "Epoch 2538, Loss 31.937042, Params tensor([2.0118, 0.1010])\n",
      "Epoch 2539, Loss 31.934130, Params tensor([2.0120, 0.1010])\n",
      "Epoch 2540, Loss 31.931215, Params tensor([2.0122, 0.1010])\n",
      "Epoch 2541, Loss 31.928316, Params tensor([2.0124, 0.1010])\n",
      "Epoch 2542, Loss 31.925413, Params tensor([2.0125, 0.1010])\n",
      "Epoch 2543, Loss 31.922518, Params tensor([2.0127, 0.1010])\n",
      "Epoch 2544, Loss 31.919619, Params tensor([2.0129, 0.1010])\n",
      "Epoch 2545, Loss 31.916737, Params tensor([2.0130, 0.1010])\n",
      "Epoch 2546, Loss 31.913847, Params tensor([2.0132, 0.1010])\n",
      "Epoch 2547, Loss 31.910957, Params tensor([2.0134, 0.1010])\n",
      "Epoch 2548, Loss 31.908081, Params tensor([2.0135, 0.1010])\n",
      "Epoch 2549, Loss 31.905201, Params tensor([2.0137, 0.1010])\n",
      "Epoch 2550, Loss 31.902325, Params tensor([2.0139, 0.1010])\n",
      "Epoch 2551, Loss 31.899456, Params tensor([2.0141, 0.1010])\n",
      "Epoch 2552, Loss 31.896587, Params tensor([2.0142, 0.1010])\n",
      "Epoch 2553, Loss 31.893724, Params tensor([2.0144, 0.1010])\n",
      "Epoch 2554, Loss 31.890867, Params tensor([2.0146, 0.1010])\n",
      "Epoch 2555, Loss 31.888012, Params tensor([2.0147, 0.1010])\n",
      "Epoch 2556, Loss 31.885155, Params tensor([2.0149, 0.1010])\n",
      "Epoch 2557, Loss 31.882301, Params tensor([2.0151, 0.1010])\n",
      "Epoch 2558, Loss 31.879457, Params tensor([2.0152, 0.1010])\n",
      "Epoch 2559, Loss 31.876617, Params tensor([2.0154, 0.1010])\n",
      "Epoch 2560, Loss 31.873774, Params tensor([2.0156, 0.1010])\n",
      "Epoch 2561, Loss 31.870935, Params tensor([2.0157, 0.1010])\n",
      "Epoch 2562, Loss 31.868103, Params tensor([2.0159, 0.1010])\n",
      "Epoch 2563, Loss 31.865271, Params tensor([2.0161, 0.1010])\n",
      "Epoch 2564, Loss 31.862450, Params tensor([2.0162, 0.1010])\n",
      "Epoch 2565, Loss 31.859619, Params tensor([2.0164, 0.1010])\n",
      "Epoch 2566, Loss 31.856800, Params tensor([2.0166, 0.1010])\n",
      "Epoch 2567, Loss 31.853979, Params tensor([2.0167, 0.1010])\n",
      "Epoch 2568, Loss 31.851168, Params tensor([2.0169, 0.1010])\n",
      "Epoch 2569, Loss 31.848352, Params tensor([2.0171, 0.1010])\n",
      "Epoch 2570, Loss 31.845549, Params tensor([2.0172, 0.1010])\n",
      "Epoch 2571, Loss 31.842749, Params tensor([2.0174, 0.1010])\n",
      "Epoch 2572, Loss 31.839947, Params tensor([2.0176, 0.1010])\n",
      "Epoch 2573, Loss 31.837145, Params tensor([2.0178, 0.1010])\n",
      "Epoch 2574, Loss 31.834356, Params tensor([2.0179, 0.1009])\n",
      "Epoch 2575, Loss 31.831560, Params tensor([2.0181, 0.1009])\n",
      "Epoch 2576, Loss 31.828777, Params tensor([2.0183, 0.1009])\n",
      "Epoch 2577, Loss 31.825987, Params tensor([2.0184, 0.1009])\n",
      "Epoch 2578, Loss 31.823210, Params tensor([2.0186, 0.1009])\n",
      "Epoch 2579, Loss 31.820435, Params tensor([2.0188, 0.1009])\n",
      "Epoch 2580, Loss 31.817656, Params tensor([2.0189, 0.1009])\n",
      "Epoch 2581, Loss 31.814886, Params tensor([2.0191, 0.1009])\n",
      "Epoch 2582, Loss 31.812115, Params tensor([2.0193, 0.1009])\n",
      "Epoch 2583, Loss 31.809349, Params tensor([2.0194, 0.1009])\n",
      "Epoch 2584, Loss 31.806597, Params tensor([2.0196, 0.1009])\n",
      "Epoch 2585, Loss 31.803833, Params tensor([2.0198, 0.1009])\n",
      "Epoch 2586, Loss 31.801075, Params tensor([2.0199, 0.1009])\n",
      "Epoch 2587, Loss 31.798321, Params tensor([2.0201, 0.1009])\n",
      "Epoch 2588, Loss 31.795576, Params tensor([2.0202, 0.1009])\n",
      "Epoch 2589, Loss 31.792830, Params tensor([2.0204, 0.1009])\n",
      "Epoch 2590, Loss 31.790087, Params tensor([2.0206, 0.1009])\n",
      "Epoch 2591, Loss 31.787348, Params tensor([2.0207, 0.1009])\n",
      "Epoch 2592, Loss 31.784613, Params tensor([2.0209, 0.1009])\n",
      "Epoch 2593, Loss 31.781885, Params tensor([2.0211, 0.1009])\n",
      "Epoch 2594, Loss 31.779152, Params tensor([2.0212, 0.1009])\n",
      "Epoch 2595, Loss 31.776426, Params tensor([2.0214, 0.1009])\n",
      "Epoch 2596, Loss 31.773705, Params tensor([2.0216, 0.1009])\n",
      "Epoch 2597, Loss 31.770979, Params tensor([2.0217, 0.1009])\n",
      "Epoch 2598, Loss 31.768267, Params tensor([2.0219, 0.1009])\n",
      "Epoch 2599, Loss 31.765556, Params tensor([2.0221, 0.1009])\n",
      "Epoch 2600, Loss 31.762840, Params tensor([2.0222, 0.1009])\n",
      "Epoch 2601, Loss 31.760138, Params tensor([2.0224, 0.1009])\n",
      "Epoch 2602, Loss 31.757427, Params tensor([2.0226, 0.1009])\n",
      "Epoch 2603, Loss 31.754732, Params tensor([2.0227, 0.1009])\n",
      "Epoch 2604, Loss 31.752033, Params tensor([2.0229, 0.1009])\n",
      "Epoch 2605, Loss 31.749336, Params tensor([2.0230, 0.1009])\n",
      "Epoch 2606, Loss 31.746643, Params tensor([2.0232, 0.1009])\n",
      "Epoch 2607, Loss 31.743958, Params tensor([2.0234, 0.1009])\n",
      "Epoch 2608, Loss 31.741274, Params tensor([2.0235, 0.1009])\n",
      "Epoch 2609, Loss 31.738598, Params tensor([2.0237, 0.1009])\n",
      "Epoch 2610, Loss 31.735909, Params tensor([2.0239, 0.1009])\n",
      "Epoch 2611, Loss 31.733232, Params tensor([2.0240, 0.1009])\n",
      "Epoch 2612, Loss 31.730558, Params tensor([2.0242, 0.1009])\n",
      "Epoch 2613, Loss 31.727894, Params tensor([2.0244, 0.1009])\n",
      "Epoch 2614, Loss 31.725225, Params tensor([2.0245, 0.1009])\n",
      "Epoch 2615, Loss 31.722567, Params tensor([2.0247, 0.1009])\n",
      "Epoch 2616, Loss 31.719904, Params tensor([2.0248, 0.1009])\n",
      "Epoch 2617, Loss 31.717253, Params tensor([2.0250, 0.1009])\n",
      "Epoch 2618, Loss 31.714592, Params tensor([2.0252, 0.1009])\n",
      "Epoch 2619, Loss 31.711943, Params tensor([2.0253, 0.1009])\n",
      "Epoch 2620, Loss 31.709297, Params tensor([2.0255, 0.1009])\n",
      "Epoch 2621, Loss 31.706652, Params tensor([2.0257, 0.1009])\n",
      "Epoch 2622, Loss 31.704008, Params tensor([2.0258, 0.1009])\n",
      "Epoch 2623, Loss 31.701366, Params tensor([2.0260, 0.1009])\n",
      "Epoch 2624, Loss 31.698730, Params tensor([2.0261, 0.1009])\n",
      "Epoch 2625, Loss 31.696100, Params tensor([2.0263, 0.1009])\n",
      "Epoch 2626, Loss 31.693468, Params tensor([2.0265, 0.1009])\n",
      "Epoch 2627, Loss 31.690849, Params tensor([2.0266, 0.1009])\n",
      "Epoch 2628, Loss 31.688227, Params tensor([2.0268, 0.1009])\n",
      "Epoch 2629, Loss 31.685606, Params tensor([2.0270, 0.1009])\n",
      "Epoch 2630, Loss 31.682985, Params tensor([2.0271, 0.1009])\n",
      "Epoch 2631, Loss 31.680372, Params tensor([2.0273, 0.1009])\n",
      "Epoch 2632, Loss 31.677763, Params tensor([2.0274, 0.1009])\n",
      "Epoch 2633, Loss 31.675158, Params tensor([2.0276, 0.1009])\n",
      "Epoch 2634, Loss 31.672548, Params tensor([2.0278, 0.1009])\n",
      "Epoch 2635, Loss 31.669950, Params tensor([2.0279, 0.1009])\n",
      "Epoch 2636, Loss 31.667351, Params tensor([2.0281, 0.1009])\n",
      "Epoch 2637, Loss 31.664751, Params tensor([2.0282, 0.1008])\n",
      "Epoch 2638, Loss 31.662165, Params tensor([2.0284, 0.1008])\n",
      "Epoch 2639, Loss 31.659571, Params tensor([2.0286, 0.1008])\n",
      "Epoch 2640, Loss 31.656984, Params tensor([2.0287, 0.1008])\n",
      "Epoch 2641, Loss 31.654402, Params tensor([2.0289, 0.1008])\n",
      "Epoch 2642, Loss 31.651823, Params tensor([2.0291, 0.1008])\n",
      "Epoch 2643, Loss 31.649248, Params tensor([2.0292, 0.1008])\n",
      "Epoch 2644, Loss 31.646673, Params tensor([2.0294, 0.1008])\n",
      "Epoch 2645, Loss 31.644098, Params tensor([2.0295, 0.1008])\n",
      "Epoch 2646, Loss 31.641533, Params tensor([2.0297, 0.1008])\n",
      "Epoch 2647, Loss 31.638966, Params tensor([2.0299, 0.1008])\n",
      "Epoch 2648, Loss 31.636402, Params tensor([2.0300, 0.1008])\n",
      "Epoch 2649, Loss 31.633842, Params tensor([2.0302, 0.1008])\n",
      "Epoch 2650, Loss 31.631287, Params tensor([2.0303, 0.1008])\n",
      "Epoch 2651, Loss 31.628736, Params tensor([2.0305, 0.1008])\n",
      "Epoch 2652, Loss 31.626184, Params tensor([2.0307, 0.1008])\n",
      "Epoch 2653, Loss 31.623638, Params tensor([2.0308, 0.1008])\n",
      "Epoch 2654, Loss 31.621099, Params tensor([2.0310, 0.1008])\n",
      "Epoch 2655, Loss 31.618559, Params tensor([2.0311, 0.1008])\n",
      "Epoch 2656, Loss 31.616020, Params tensor([2.0313, 0.1008])\n",
      "Epoch 2657, Loss 31.613476, Params tensor([2.0315, 0.1008])\n",
      "Epoch 2658, Loss 31.610949, Params tensor([2.0316, 0.1008])\n",
      "Epoch 2659, Loss 31.608421, Params tensor([2.0318, 0.1008])\n",
      "Epoch 2660, Loss 31.605894, Params tensor([2.0319, 0.1008])\n",
      "Epoch 2661, Loss 31.603371, Params tensor([2.0321, 0.1008])\n",
      "Epoch 2662, Loss 31.600853, Params tensor([2.0322, 0.1008])\n",
      "Epoch 2663, Loss 31.598333, Params tensor([2.0324, 0.1008])\n",
      "Epoch 2664, Loss 31.595819, Params tensor([2.0326, 0.1008])\n",
      "Epoch 2665, Loss 31.593306, Params tensor([2.0327, 0.1008])\n",
      "Epoch 2666, Loss 31.590801, Params tensor([2.0329, 0.1008])\n",
      "Epoch 2667, Loss 31.588295, Params tensor([2.0330, 0.1008])\n",
      "Epoch 2668, Loss 31.585791, Params tensor([2.0332, 0.1008])\n",
      "Epoch 2669, Loss 31.583284, Params tensor([2.0334, 0.1008])\n",
      "Epoch 2670, Loss 31.580797, Params tensor([2.0335, 0.1008])\n",
      "Epoch 2671, Loss 31.578302, Params tensor([2.0337, 0.1008])\n",
      "Epoch 2672, Loss 31.575811, Params tensor([2.0338, 0.1008])\n",
      "Epoch 2673, Loss 31.573322, Params tensor([2.0340, 0.1008])\n",
      "Epoch 2674, Loss 31.570833, Params tensor([2.0341, 0.1008])\n",
      "Epoch 2675, Loss 31.568348, Params tensor([2.0343, 0.1008])\n",
      "Epoch 2676, Loss 31.565874, Params tensor([2.0345, 0.1008])\n",
      "Epoch 2677, Loss 31.563398, Params tensor([2.0346, 0.1007])\n",
      "Epoch 2678, Loss 31.560919, Params tensor([2.0348, 0.1007])\n",
      "Epoch 2679, Loss 31.558449, Params tensor([2.0349, 0.1007])\n",
      "Epoch 2680, Loss 31.555986, Params tensor([2.0351, 0.1007])\n",
      "Epoch 2681, Loss 31.553516, Params tensor([2.0352, 0.1007])\n",
      "Epoch 2682, Loss 31.551056, Params tensor([2.0354, 0.1007])\n",
      "Epoch 2683, Loss 31.548592, Params tensor([2.0356, 0.1007])\n",
      "Epoch 2684, Loss 31.546143, Params tensor([2.0357, 0.1007])\n",
      "Epoch 2685, Loss 31.543688, Params tensor([2.0359, 0.1007])\n",
      "Epoch 2686, Loss 31.541237, Params tensor([2.0360, 0.1007])\n",
      "Epoch 2687, Loss 31.538788, Params tensor([2.0362, 0.1007])\n",
      "Epoch 2688, Loss 31.536341, Params tensor([2.0363, 0.1007])\n",
      "Epoch 2689, Loss 31.533905, Params tensor([2.0365, 0.1007])\n",
      "Epoch 2690, Loss 31.531464, Params tensor([2.0366, 0.1007])\n",
      "Epoch 2691, Loss 31.529024, Params tensor([2.0368, 0.1007])\n",
      "Epoch 2692, Loss 31.526594, Params tensor([2.0370, 0.1007])\n",
      "Epoch 2693, Loss 31.524158, Params tensor([2.0371, 0.1007])\n",
      "Epoch 2694, Loss 31.521734, Params tensor([2.0373, 0.1007])\n",
      "Epoch 2695, Loss 31.519310, Params tensor([2.0374, 0.1007])\n",
      "Epoch 2696, Loss 31.516884, Params tensor([2.0376, 0.1007])\n",
      "Epoch 2697, Loss 31.514465, Params tensor([2.0377, 0.1007])\n",
      "Epoch 2698, Loss 31.512054, Params tensor([2.0379, 0.1007])\n",
      "Epoch 2699, Loss 31.509636, Params tensor([2.0381, 0.1007])\n",
      "Epoch 2700, Loss 31.507231, Params tensor([2.0382, 0.1007])\n",
      "Epoch 2701, Loss 31.504816, Params tensor([2.0384, 0.1007])\n",
      "Epoch 2702, Loss 31.502413, Params tensor([2.0385, 0.1007])\n",
      "Epoch 2703, Loss 31.500008, Params tensor([2.0387, 0.1007])\n",
      "Epoch 2704, Loss 31.497608, Params tensor([2.0388, 0.1007])\n",
      "Epoch 2705, Loss 31.495214, Params tensor([2.0390, 0.1007])\n",
      "Epoch 2706, Loss 31.492821, Params tensor([2.0391, 0.1007])\n",
      "Epoch 2707, Loss 31.490429, Params tensor([2.0393, 0.1007])\n",
      "Epoch 2708, Loss 31.488039, Params tensor([2.0394, 0.1007])\n",
      "Epoch 2709, Loss 31.485655, Params tensor([2.0396, 0.1007])\n",
      "Epoch 2710, Loss 31.483265, Params tensor([2.0398, 0.1006])\n",
      "Epoch 2711, Loss 31.480890, Params tensor([2.0399, 0.1006])\n",
      "Epoch 2712, Loss 31.478510, Params tensor([2.0401, 0.1006])\n",
      "Epoch 2713, Loss 31.476137, Params tensor([2.0402, 0.1006])\n",
      "Epoch 2714, Loss 31.473761, Params tensor([2.0404, 0.1006])\n",
      "Epoch 2715, Loss 31.471397, Params tensor([2.0405, 0.1006])\n",
      "Epoch 2716, Loss 31.469025, Params tensor([2.0407, 0.1006])\n",
      "Epoch 2717, Loss 31.466667, Params tensor([2.0408, 0.1006])\n",
      "Epoch 2718, Loss 31.464308, Params tensor([2.0410, 0.1006])\n",
      "Epoch 2719, Loss 31.461946, Params tensor([2.0411, 0.1006])\n",
      "Epoch 2720, Loss 31.459593, Params tensor([2.0413, 0.1006])\n",
      "Epoch 2721, Loss 31.457243, Params tensor([2.0414, 0.1006])\n",
      "Epoch 2722, Loss 31.454893, Params tensor([2.0416, 0.1006])\n",
      "Epoch 2723, Loss 31.452543, Params tensor([2.0417, 0.1006])\n",
      "Epoch 2724, Loss 31.450201, Params tensor([2.0419, 0.1006])\n",
      "Epoch 2725, Loss 31.447857, Params tensor([2.0421, 0.1006])\n",
      "Epoch 2726, Loss 31.445518, Params tensor([2.0422, 0.1006])\n",
      "Epoch 2727, Loss 31.443182, Params tensor([2.0424, 0.1006])\n",
      "Epoch 2728, Loss 31.440851, Params tensor([2.0425, 0.1006])\n",
      "Epoch 2729, Loss 31.438520, Params tensor([2.0427, 0.1006])\n",
      "Epoch 2730, Loss 31.436195, Params tensor([2.0428, 0.1006])\n",
      "Epoch 2731, Loss 31.433867, Params tensor([2.0430, 0.1006])\n",
      "Epoch 2732, Loss 31.431541, Params tensor([2.0431, 0.1006])\n",
      "Epoch 2733, Loss 31.429228, Params tensor([2.0433, 0.1006])\n",
      "Epoch 2734, Loss 31.426905, Params tensor([2.0434, 0.1006])\n",
      "Epoch 2735, Loss 31.424593, Params tensor([2.0436, 0.1006])\n",
      "Epoch 2736, Loss 31.422283, Params tensor([2.0437, 0.1006])\n",
      "Epoch 2737, Loss 31.419975, Params tensor([2.0439, 0.1006])\n",
      "Epoch 2738, Loss 31.417669, Params tensor([2.0440, 0.1005])\n",
      "Epoch 2739, Loss 31.415367, Params tensor([2.0442, 0.1005])\n",
      "Epoch 2740, Loss 31.413057, Params tensor([2.0443, 0.1005])\n",
      "Epoch 2741, Loss 31.410761, Params tensor([2.0445, 0.1005])\n",
      "Epoch 2742, Loss 31.408470, Params tensor([2.0446, 0.1005])\n",
      "Epoch 2743, Loss 31.406178, Params tensor([2.0448, 0.1005])\n",
      "Epoch 2744, Loss 31.403887, Params tensor([2.0449, 0.1005])\n",
      "Epoch 2745, Loss 31.401598, Params tensor([2.0451, 0.1005])\n",
      "Epoch 2746, Loss 31.399315, Params tensor([2.0452, 0.1005])\n",
      "Epoch 2747, Loss 31.397032, Params tensor([2.0454, 0.1005])\n",
      "Epoch 2748, Loss 31.394753, Params tensor([2.0455, 0.1005])\n",
      "Epoch 2749, Loss 31.392479, Params tensor([2.0457, 0.1005])\n",
      "Epoch 2750, Loss 31.390203, Params tensor([2.0458, 0.1005])\n",
      "Epoch 2751, Loss 31.387928, Params tensor([2.0460, 0.1005])\n",
      "Epoch 2752, Loss 31.385662, Params tensor([2.0462, 0.1005])\n",
      "Epoch 2753, Loss 31.383390, Params tensor([2.0463, 0.1005])\n",
      "Epoch 2754, Loss 31.381132, Params tensor([2.0465, 0.1005])\n",
      "Epoch 2755, Loss 31.378874, Params tensor([2.0466, 0.1005])\n",
      "Epoch 2756, Loss 31.376610, Params tensor([2.0468, 0.1005])\n",
      "Epoch 2757, Loss 31.374353, Params tensor([2.0469, 0.1005])\n",
      "Epoch 2758, Loss 31.372101, Params tensor([2.0471, 0.1005])\n",
      "Epoch 2759, Loss 31.369850, Params tensor([2.0472, 0.1005])\n",
      "Epoch 2760, Loss 31.367603, Params tensor([2.0474, 0.1005])\n",
      "Epoch 2761, Loss 31.365358, Params tensor([2.0475, 0.1005])\n",
      "Epoch 2762, Loss 31.363115, Params tensor([2.0477, 0.1005])\n",
      "Epoch 2763, Loss 31.360872, Params tensor([2.0478, 0.1005])\n",
      "Epoch 2764, Loss 31.358637, Params tensor([2.0479, 0.1004])\n",
      "Epoch 2765, Loss 31.356401, Params tensor([2.0481, 0.1004])\n",
      "Epoch 2766, Loss 31.354168, Params tensor([2.0482, 0.1004])\n",
      "Epoch 2767, Loss 31.351936, Params tensor([2.0484, 0.1004])\n",
      "Epoch 2768, Loss 31.349712, Params tensor([2.0485, 0.1004])\n",
      "Epoch 2769, Loss 31.347490, Params tensor([2.0487, 0.1004])\n",
      "Epoch 2770, Loss 31.345264, Params tensor([2.0488, 0.1004])\n",
      "Epoch 2771, Loss 31.343046, Params tensor([2.0490, 0.1004])\n",
      "Epoch 2772, Loss 31.340834, Params tensor([2.0491, 0.1004])\n",
      "Epoch 2773, Loss 31.338621, Params tensor([2.0493, 0.1004])\n",
      "Epoch 2774, Loss 31.336403, Params tensor([2.0494, 0.1004])\n",
      "Epoch 2775, Loss 31.334196, Params tensor([2.0496, 0.1004])\n",
      "Epoch 2776, Loss 31.331987, Params tensor([2.0497, 0.1004])\n",
      "Epoch 2777, Loss 31.329781, Params tensor([2.0499, 0.1004])\n",
      "Epoch 2778, Loss 31.327581, Params tensor([2.0500, 0.1004])\n",
      "Epoch 2779, Loss 31.325384, Params tensor([2.0502, 0.1004])\n",
      "Epoch 2780, Loss 31.323193, Params tensor([2.0503, 0.1004])\n",
      "Epoch 2781, Loss 31.320995, Params tensor([2.0505, 0.1004])\n",
      "Epoch 2782, Loss 31.318804, Params tensor([2.0506, 0.1004])\n",
      "Epoch 2783, Loss 31.316618, Params tensor([2.0508, 0.1004])\n",
      "Epoch 2784, Loss 31.314430, Params tensor([2.0509, 0.1004])\n",
      "Epoch 2785, Loss 31.312244, Params tensor([2.0511, 0.1004])\n",
      "Epoch 2786, Loss 31.310066, Params tensor([2.0512, 0.1004])\n",
      "Epoch 2787, Loss 31.307886, Params tensor([2.0514, 0.1003])\n",
      "Epoch 2788, Loss 31.305708, Params tensor([2.0515, 0.1003])\n",
      "Epoch 2789, Loss 31.303541, Params tensor([2.0517, 0.1003])\n",
      "Epoch 2790, Loss 31.301367, Params tensor([2.0518, 0.1003])\n",
      "Epoch 2791, Loss 31.299202, Params tensor([2.0520, 0.1003])\n",
      "Epoch 2792, Loss 31.297035, Params tensor([2.0521, 0.1003])\n",
      "Epoch 2793, Loss 31.294867, Params tensor([2.0522, 0.1003])\n",
      "Epoch 2794, Loss 31.292717, Params tensor([2.0524, 0.1003])\n",
      "Epoch 2795, Loss 31.290552, Params tensor([2.0525, 0.1003])\n",
      "Epoch 2796, Loss 31.288393, Params tensor([2.0527, 0.1003])\n",
      "Epoch 2797, Loss 31.286243, Params tensor([2.0528, 0.1003])\n",
      "Epoch 2798, Loss 31.284094, Params tensor([2.0530, 0.1003])\n",
      "Epoch 2799, Loss 31.281940, Params tensor([2.0531, 0.1003])\n",
      "Epoch 2800, Loss 31.279797, Params tensor([2.0533, 0.1003])\n",
      "Epoch 2801, Loss 31.277651, Params tensor([2.0534, 0.1003])\n",
      "Epoch 2802, Loss 31.275513, Params tensor([2.0536, 0.1003])\n",
      "Epoch 2803, Loss 31.273376, Params tensor([2.0537, 0.1003])\n",
      "Epoch 2804, Loss 31.271240, Params tensor([2.0539, 0.1003])\n",
      "Epoch 2805, Loss 31.269110, Params tensor([2.0540, 0.1003])\n",
      "Epoch 2806, Loss 31.266975, Params tensor([2.0541, 0.1003])\n",
      "Epoch 2807, Loss 31.264849, Params tensor([2.0543, 0.1003])\n",
      "Epoch 2808, Loss 31.262718, Params tensor([2.0544, 0.1002])\n",
      "Epoch 2809, Loss 31.260603, Params tensor([2.0546, 0.1002])\n",
      "Epoch 2810, Loss 31.258472, Params tensor([2.0547, 0.1002])\n",
      "Epoch 2811, Loss 31.256361, Params tensor([2.0549, 0.1002])\n",
      "Epoch 2812, Loss 31.254242, Params tensor([2.0550, 0.1002])\n",
      "Epoch 2813, Loss 31.252125, Params tensor([2.0552, 0.1002])\n",
      "Epoch 2814, Loss 31.250023, Params tensor([2.0553, 0.1002])\n",
      "Epoch 2815, Loss 31.247908, Params tensor([2.0555, 0.1002])\n",
      "Epoch 2816, Loss 31.245802, Params tensor([2.0556, 0.1002])\n",
      "Epoch 2817, Loss 31.243696, Params tensor([2.0557, 0.1002])\n",
      "Epoch 2818, Loss 31.241596, Params tensor([2.0559, 0.1002])\n",
      "Epoch 2819, Loss 31.239500, Params tensor([2.0560, 0.1002])\n",
      "Epoch 2820, Loss 31.237402, Params tensor([2.0562, 0.1002])\n",
      "Epoch 2821, Loss 31.235304, Params tensor([2.0563, 0.1002])\n",
      "Epoch 2822, Loss 31.233221, Params tensor([2.0565, 0.1002])\n",
      "Epoch 2823, Loss 31.231127, Params tensor([2.0566, 0.1002])\n",
      "Epoch 2824, Loss 31.229040, Params tensor([2.0568, 0.1002])\n",
      "Epoch 2825, Loss 31.226957, Params tensor([2.0569, 0.1002])\n",
      "Epoch 2826, Loss 31.224873, Params tensor([2.0570, 0.1002])\n",
      "Epoch 2827, Loss 31.222792, Params tensor([2.0572, 0.1002])\n",
      "Epoch 2828, Loss 31.220720, Params tensor([2.0573, 0.1001])\n",
      "Epoch 2829, Loss 31.218639, Params tensor([2.0575, 0.1001])\n",
      "Epoch 2830, Loss 31.216570, Params tensor([2.0576, 0.1001])\n",
      "Epoch 2831, Loss 31.214506, Params tensor([2.0578, 0.1001])\n",
      "Epoch 2832, Loss 31.212435, Params tensor([2.0579, 0.1001])\n",
      "Epoch 2833, Loss 31.210369, Params tensor([2.0581, 0.1001])\n",
      "Epoch 2834, Loss 31.208307, Params tensor([2.0582, 0.1001])\n",
      "Epoch 2835, Loss 31.206249, Params tensor([2.0583, 0.1001])\n",
      "Epoch 2836, Loss 31.204187, Params tensor([2.0585, 0.1001])\n",
      "Epoch 2837, Loss 31.202135, Params tensor([2.0586, 0.1001])\n",
      "Epoch 2838, Loss 31.200079, Params tensor([2.0588, 0.1001])\n",
      "Epoch 2839, Loss 31.198034, Params tensor([2.0589, 0.1001])\n",
      "Epoch 2840, Loss 31.195978, Params tensor([2.0591, 0.1001])\n",
      "Epoch 2841, Loss 31.193932, Params tensor([2.0592, 0.1001])\n",
      "Epoch 2842, Loss 31.191893, Params tensor([2.0593, 0.1001])\n",
      "Epoch 2843, Loss 31.189852, Params tensor([2.0595, 0.1001])\n",
      "Epoch 2844, Loss 31.187805, Params tensor([2.0596, 0.1001])\n",
      "Epoch 2845, Loss 31.185774, Params tensor([2.0598, 0.1001])\n",
      "Epoch 2846, Loss 31.183739, Params tensor([2.0599, 0.1001])\n",
      "Epoch 2847, Loss 31.181707, Params tensor([2.0601, 0.1000])\n",
      "Epoch 2848, Loss 31.179682, Params tensor([2.0602, 0.1000])\n",
      "Epoch 2849, Loss 31.177650, Params tensor([2.0603, 0.1000])\n",
      "Epoch 2850, Loss 31.175627, Params tensor([2.0605, 0.1000])\n",
      "Epoch 2851, Loss 31.173607, Params tensor([2.0606, 0.1000])\n",
      "Epoch 2852, Loss 31.171581, Params tensor([2.0608, 0.1000])\n",
      "Epoch 2853, Loss 31.169567, Params tensor([2.0609, 0.1000])\n",
      "Epoch 2854, Loss 31.167555, Params tensor([2.0610, 0.1000])\n",
      "Epoch 2855, Loss 31.165541, Params tensor([2.0612, 0.1000])\n",
      "Epoch 2856, Loss 31.163525, Params tensor([2.0613, 0.1000])\n",
      "Epoch 2857, Loss 31.161522, Params tensor([2.0615, 0.1000])\n",
      "Epoch 2858, Loss 31.159515, Params tensor([2.0616, 0.1000])\n",
      "Epoch 2859, Loss 31.157509, Params tensor([2.0618, 0.1000])\n",
      "Epoch 2860, Loss 31.155512, Params tensor([2.0619, 0.1000])\n",
      "Epoch 2861, Loss 31.153509, Params tensor([2.0620, 0.1000])\n",
      "Epoch 2862, Loss 31.151512, Params tensor([2.0622, 0.1000])\n",
      "Epoch 2863, Loss 31.149519, Params tensor([2.0623, 0.1000])\n",
      "Epoch 2864, Loss 31.147524, Params tensor([2.0625, 0.1000])\n",
      "Epoch 2865, Loss 31.145536, Params tensor([2.0626, 0.0999])\n",
      "Epoch 2866, Loss 31.143549, Params tensor([2.0627, 0.0999])\n",
      "Epoch 2867, Loss 31.141563, Params tensor([2.0629, 0.0999])\n",
      "Epoch 2868, Loss 31.139582, Params tensor([2.0630, 0.0999])\n",
      "Epoch 2869, Loss 31.137602, Params tensor([2.0632, 0.0999])\n",
      "Epoch 2870, Loss 31.135620, Params tensor([2.0633, 0.0999])\n",
      "Epoch 2871, Loss 31.133642, Params tensor([2.0634, 0.0999])\n",
      "Epoch 2872, Loss 31.131672, Params tensor([2.0636, 0.0999])\n",
      "Epoch 2873, Loss 31.129698, Params tensor([2.0637, 0.0999])\n",
      "Epoch 2874, Loss 31.127724, Params tensor([2.0639, 0.0999])\n",
      "Epoch 2875, Loss 31.125757, Params tensor([2.0640, 0.0999])\n",
      "Epoch 2876, Loss 31.123796, Params tensor([2.0641, 0.0999])\n",
      "Epoch 2877, Loss 31.121834, Params tensor([2.0643, 0.0999])\n",
      "Epoch 2878, Loss 31.119873, Params tensor([2.0644, 0.0999])\n",
      "Epoch 2879, Loss 31.117914, Params tensor([2.0646, 0.0999])\n",
      "Epoch 2880, Loss 31.115961, Params tensor([2.0647, 0.0999])\n",
      "Epoch 2881, Loss 31.114012, Params tensor([2.0648, 0.0999])\n",
      "Epoch 2882, Loss 31.112055, Params tensor([2.0650, 0.0999])\n",
      "Epoch 2883, Loss 31.110109, Params tensor([2.0651, 0.0998])\n",
      "Epoch 2884, Loss 31.108166, Params tensor([2.0653, 0.0998])\n",
      "Epoch 2885, Loss 31.106220, Params tensor([2.0654, 0.0998])\n",
      "Epoch 2886, Loss 31.104277, Params tensor([2.0655, 0.0998])\n",
      "Epoch 2887, Loss 31.102337, Params tensor([2.0657, 0.0998])\n",
      "Epoch 2888, Loss 31.100397, Params tensor([2.0658, 0.0998])\n",
      "Epoch 2889, Loss 31.098467, Params tensor([2.0660, 0.0998])\n",
      "Epoch 2890, Loss 31.096529, Params tensor([2.0661, 0.0998])\n",
      "Epoch 2891, Loss 31.094603, Params tensor([2.0662, 0.0998])\n",
      "Epoch 2892, Loss 31.092674, Params tensor([2.0664, 0.0998])\n",
      "Epoch 2893, Loss 31.090746, Params tensor([2.0665, 0.0998])\n",
      "Epoch 2894, Loss 31.088818, Params tensor([2.0667, 0.0998])\n",
      "Epoch 2895, Loss 31.086903, Params tensor([2.0668, 0.0998])\n",
      "Epoch 2896, Loss 31.084980, Params tensor([2.0669, 0.0998])\n",
      "Epoch 2897, Loss 31.083063, Params tensor([2.0671, 0.0998])\n",
      "Epoch 2898, Loss 31.081146, Params tensor([2.0672, 0.0998])\n",
      "Epoch 2899, Loss 31.079229, Params tensor([2.0673, 0.0997])\n",
      "Epoch 2900, Loss 31.077324, Params tensor([2.0675, 0.0997])\n",
      "Epoch 2901, Loss 31.075417, Params tensor([2.0676, 0.0997])\n",
      "Epoch 2902, Loss 31.073505, Params tensor([2.0678, 0.0997])\n",
      "Epoch 2903, Loss 31.071600, Params tensor([2.0679, 0.0997])\n",
      "Epoch 2904, Loss 31.069700, Params tensor([2.0680, 0.0997])\n",
      "Epoch 2905, Loss 31.067799, Params tensor([2.0682, 0.0997])\n",
      "Epoch 2906, Loss 31.065901, Params tensor([2.0683, 0.0997])\n",
      "Epoch 2907, Loss 31.064001, Params tensor([2.0684, 0.0997])\n",
      "Epoch 2908, Loss 31.062115, Params tensor([2.0686, 0.0997])\n",
      "Epoch 2909, Loss 31.060223, Params tensor([2.0687, 0.0997])\n",
      "Epoch 2910, Loss 31.058332, Params tensor([2.0689, 0.0997])\n",
      "Epoch 2911, Loss 31.056446, Params tensor([2.0690, 0.0997])\n",
      "Epoch 2912, Loss 31.054564, Params tensor([2.0691, 0.0997])\n",
      "Epoch 2913, Loss 31.052675, Params tensor([2.0693, 0.0997])\n",
      "Epoch 2914, Loss 31.050800, Params tensor([2.0694, 0.0997])\n",
      "Epoch 2915, Loss 31.048920, Params tensor([2.0695, 0.0996])\n",
      "Epoch 2916, Loss 31.047045, Params tensor([2.0697, 0.0996])\n",
      "Epoch 2917, Loss 31.045172, Params tensor([2.0698, 0.0996])\n",
      "Epoch 2918, Loss 31.043299, Params tensor([2.0700, 0.0996])\n",
      "Epoch 2919, Loss 31.041430, Params tensor([2.0701, 0.0996])\n",
      "Epoch 2920, Loss 31.039562, Params tensor([2.0702, 0.0996])\n",
      "Epoch 2921, Loss 31.037695, Params tensor([2.0704, 0.0996])\n",
      "Epoch 2922, Loss 31.035835, Params tensor([2.0705, 0.0996])\n",
      "Epoch 2923, Loss 31.033968, Params tensor([2.0706, 0.0996])\n",
      "Epoch 2924, Loss 31.032116, Params tensor([2.0708, 0.0996])\n",
      "Epoch 2925, Loss 31.030256, Params tensor([2.0709, 0.0996])\n",
      "Epoch 2926, Loss 31.028399, Params tensor([2.0710, 0.0996])\n",
      "Epoch 2927, Loss 31.026550, Params tensor([2.0712, 0.0996])\n",
      "Epoch 2928, Loss 31.024696, Params tensor([2.0713, 0.0996])\n",
      "Epoch 2929, Loss 31.022852, Params tensor([2.0715, 0.0996])\n",
      "Epoch 2930, Loss 31.021002, Params tensor([2.0716, 0.0995])\n",
      "Epoch 2931, Loss 31.019159, Params tensor([2.0717, 0.0995])\n",
      "Epoch 2932, Loss 31.017317, Params tensor([2.0719, 0.0995])\n",
      "Epoch 2933, Loss 31.015480, Params tensor([2.0720, 0.0995])\n",
      "Epoch 2934, Loss 31.013641, Params tensor([2.0721, 0.0995])\n",
      "Epoch 2935, Loss 31.011808, Params tensor([2.0723, 0.0995])\n",
      "Epoch 2936, Loss 31.009972, Params tensor([2.0724, 0.0995])\n",
      "Epoch 2937, Loss 31.008146, Params tensor([2.0725, 0.0995])\n",
      "Epoch 2938, Loss 31.006311, Params tensor([2.0727, 0.0995])\n",
      "Epoch 2939, Loss 31.004484, Params tensor([2.0728, 0.0995])\n",
      "Epoch 2940, Loss 31.002663, Params tensor([2.0729, 0.0995])\n",
      "Epoch 2941, Loss 31.000835, Params tensor([2.0731, 0.0995])\n",
      "Epoch 2942, Loss 30.999018, Params tensor([2.0732, 0.0995])\n",
      "Epoch 2943, Loss 30.997198, Params tensor([2.0733, 0.0995])\n",
      "Epoch 2944, Loss 30.995384, Params tensor([2.0735, 0.0995])\n",
      "Epoch 2945, Loss 30.993568, Params tensor([2.0736, 0.0994])\n",
      "Epoch 2946, Loss 30.991755, Params tensor([2.0737, 0.0994])\n",
      "Epoch 2947, Loss 30.989946, Params tensor([2.0739, 0.0994])\n",
      "Epoch 2948, Loss 30.988136, Params tensor([2.0740, 0.0994])\n",
      "Epoch 2949, Loss 30.986334, Params tensor([2.0741, 0.0994])\n",
      "Epoch 2950, Loss 30.984526, Params tensor([2.0743, 0.0994])\n",
      "Epoch 2951, Loss 30.982725, Params tensor([2.0744, 0.0994])\n",
      "Epoch 2952, Loss 30.980932, Params tensor([2.0746, 0.0994])\n",
      "Epoch 2953, Loss 30.979128, Params tensor([2.0747, 0.0994])\n",
      "Epoch 2954, Loss 30.977333, Params tensor([2.0748, 0.0994])\n",
      "Epoch 2955, Loss 30.975548, Params tensor([2.0750, 0.0994])\n",
      "Epoch 2956, Loss 30.973749, Params tensor([2.0751, 0.0994])\n",
      "Epoch 2957, Loss 30.971960, Params tensor([2.0752, 0.0994])\n",
      "Epoch 2958, Loss 30.970171, Params tensor([2.0754, 0.0994])\n",
      "Epoch 2959, Loss 30.968390, Params tensor([2.0755, 0.0994])\n",
      "Epoch 2960, Loss 30.966606, Params tensor([2.0756, 0.0993])\n",
      "Epoch 2961, Loss 30.964825, Params tensor([2.0758, 0.0993])\n",
      "Epoch 2962, Loss 30.963045, Params tensor([2.0759, 0.0993])\n",
      "Epoch 2963, Loss 30.961271, Params tensor([2.0760, 0.0993])\n",
      "Epoch 2964, Loss 30.959496, Params tensor([2.0762, 0.0993])\n",
      "Epoch 2965, Loss 30.957720, Params tensor([2.0763, 0.0993])\n",
      "Epoch 2966, Loss 30.955952, Params tensor([2.0764, 0.0993])\n",
      "Epoch 2967, Loss 30.954187, Params tensor([2.0766, 0.0993])\n",
      "Epoch 2968, Loss 30.952415, Params tensor([2.0767, 0.0993])\n",
      "Epoch 2969, Loss 30.950651, Params tensor([2.0768, 0.0993])\n",
      "Epoch 2970, Loss 30.948889, Params tensor([2.0769, 0.0993])\n",
      "Epoch 2971, Loss 30.947130, Params tensor([2.0771, 0.0993])\n",
      "Epoch 2972, Loss 30.945374, Params tensor([2.0772, 0.0993])\n",
      "Epoch 2973, Loss 30.943611, Params tensor([2.0773, 0.0993])\n",
      "Epoch 2974, Loss 30.941862, Params tensor([2.0775, 0.0992])\n",
      "Epoch 2975, Loss 30.940105, Params tensor([2.0776, 0.0992])\n",
      "Epoch 2976, Loss 30.938354, Params tensor([2.0777, 0.0992])\n",
      "Epoch 2977, Loss 30.936613, Params tensor([2.0779, 0.0992])\n",
      "Epoch 2978, Loss 30.934864, Params tensor([2.0780, 0.0992])\n",
      "Epoch 2979, Loss 30.933117, Params tensor([2.0781, 0.0992])\n",
      "Epoch 2980, Loss 30.931374, Params tensor([2.0783, 0.0992])\n",
      "Epoch 2981, Loss 30.929626, Params tensor([2.0784, 0.0992])\n",
      "Epoch 2982, Loss 30.927893, Params tensor([2.0785, 0.0992])\n",
      "Epoch 2983, Loss 30.926155, Params tensor([2.0787, 0.0992])\n",
      "Epoch 2984, Loss 30.924421, Params tensor([2.0788, 0.0992])\n",
      "Epoch 2985, Loss 30.922691, Params tensor([2.0789, 0.0992])\n",
      "Epoch 2986, Loss 30.920961, Params tensor([2.0791, 0.0992])\n",
      "Epoch 2987, Loss 30.919233, Params tensor([2.0792, 0.0992])\n",
      "Epoch 2988, Loss 30.917509, Params tensor([2.0793, 0.0991])\n",
      "Epoch 2989, Loss 30.915777, Params tensor([2.0795, 0.0991])\n",
      "Epoch 2990, Loss 30.914051, Params tensor([2.0796, 0.0991])\n",
      "Epoch 2991, Loss 30.912334, Params tensor([2.0797, 0.0991])\n",
      "Epoch 2992, Loss 30.910616, Params tensor([2.0798, 0.0991])\n",
      "Epoch 2993, Loss 30.908903, Params tensor([2.0800, 0.0991])\n",
      "Epoch 2994, Loss 30.907188, Params tensor([2.0801, 0.0991])\n",
      "Epoch 2995, Loss 30.905474, Params tensor([2.0802, 0.0991])\n",
      "Epoch 2996, Loss 30.903767, Params tensor([2.0804, 0.0991])\n",
      "Epoch 2997, Loss 30.902056, Params tensor([2.0805, 0.0991])\n",
      "Epoch 2998, Loss 30.900349, Params tensor([2.0806, 0.0991])\n",
      "Epoch 2999, Loss 30.898643, Params tensor([2.0808, 0.0991])\n",
      "Epoch 3000, Loss 30.896944, Params tensor([2.0809, 0.0991])\n",
      "Epoch 3001, Loss 30.895241, Params tensor([2.0810, 0.0990])\n",
      "Epoch 3002, Loss 30.893538, Params tensor([2.0811, 0.0990])\n",
      "Epoch 3003, Loss 30.891844, Params tensor([2.0813, 0.0990])\n",
      "Epoch 3004, Loss 30.890150, Params tensor([2.0814, 0.0990])\n",
      "Epoch 3005, Loss 30.888453, Params tensor([2.0815, 0.0990])\n",
      "Epoch 3006, Loss 30.886768, Params tensor([2.0817, 0.0990])\n",
      "Epoch 3007, Loss 30.885078, Params tensor([2.0818, 0.0990])\n",
      "Epoch 3008, Loss 30.883390, Params tensor([2.0819, 0.0990])\n",
      "Epoch 3009, Loss 30.881702, Params tensor([2.0821, 0.0990])\n",
      "Epoch 3010, Loss 30.880022, Params tensor([2.0822, 0.0990])\n",
      "Epoch 3011, Loss 30.878338, Params tensor([2.0823, 0.0990])\n",
      "Epoch 3012, Loss 30.876659, Params tensor([2.0824, 0.0990])\n",
      "Epoch 3013, Loss 30.874981, Params tensor([2.0826, 0.0990])\n",
      "Epoch 3014, Loss 30.873308, Params tensor([2.0827, 0.0989])\n",
      "Epoch 3015, Loss 30.871630, Params tensor([2.0828, 0.0989])\n",
      "Epoch 3016, Loss 30.869959, Params tensor([2.0830, 0.0989])\n",
      "Epoch 3017, Loss 30.868292, Params tensor([2.0831, 0.0989])\n",
      "Epoch 3018, Loss 30.866625, Params tensor([2.0832, 0.0989])\n",
      "Epoch 3019, Loss 30.864960, Params tensor([2.0833, 0.0989])\n",
      "Epoch 3020, Loss 30.863298, Params tensor([2.0835, 0.0989])\n",
      "Epoch 3021, Loss 30.861631, Params tensor([2.0836, 0.0989])\n",
      "Epoch 3022, Loss 30.859972, Params tensor([2.0837, 0.0989])\n",
      "Epoch 3023, Loss 30.858315, Params tensor([2.0839, 0.0989])\n",
      "Epoch 3024, Loss 30.856653, Params tensor([2.0840, 0.0989])\n",
      "Epoch 3025, Loss 30.854998, Params tensor([2.0841, 0.0989])\n",
      "Epoch 3026, Loss 30.853344, Params tensor([2.0842, 0.0989])\n",
      "Epoch 3027, Loss 30.851702, Params tensor([2.0844, 0.0988])\n",
      "Epoch 3028, Loss 30.850050, Params tensor([2.0845, 0.0988])\n",
      "Epoch 3029, Loss 30.848396, Params tensor([2.0846, 0.0988])\n",
      "Epoch 3030, Loss 30.846754, Params tensor([2.0848, 0.0988])\n",
      "Epoch 3031, Loss 30.845112, Params tensor([2.0849, 0.0988])\n",
      "Epoch 3032, Loss 30.843468, Params tensor([2.0850, 0.0988])\n",
      "Epoch 3033, Loss 30.841835, Params tensor([2.0851, 0.0988])\n",
      "Epoch 3034, Loss 30.840193, Params tensor([2.0853, 0.0988])\n",
      "Epoch 3035, Loss 30.838562, Params tensor([2.0854, 0.0988])\n",
      "Epoch 3036, Loss 30.836926, Params tensor([2.0855, 0.0988])\n",
      "Epoch 3037, Loss 30.835295, Params tensor([2.0857, 0.0988])\n",
      "Epoch 3038, Loss 30.833668, Params tensor([2.0858, 0.0988])\n",
      "Epoch 3039, Loss 30.832037, Params tensor([2.0859, 0.0987])\n",
      "Epoch 3040, Loss 30.830406, Params tensor([2.0860, 0.0987])\n",
      "Epoch 3041, Loss 30.828783, Params tensor([2.0862, 0.0987])\n",
      "Epoch 3042, Loss 30.827162, Params tensor([2.0863, 0.0987])\n",
      "Epoch 3043, Loss 30.825539, Params tensor([2.0864, 0.0987])\n",
      "Epoch 3044, Loss 30.823921, Params tensor([2.0865, 0.0987])\n",
      "Epoch 3045, Loss 30.822302, Params tensor([2.0867, 0.0987])\n",
      "Epoch 3046, Loss 30.820690, Params tensor([2.0868, 0.0987])\n",
      "Epoch 3047, Loss 30.819078, Params tensor([2.0869, 0.0987])\n",
      "Epoch 3048, Loss 30.817463, Params tensor([2.0871, 0.0987])\n",
      "Epoch 3049, Loss 30.815849, Params tensor([2.0872, 0.0987])\n",
      "Epoch 3050, Loss 30.814247, Params tensor([2.0873, 0.0987])\n",
      "Epoch 3051, Loss 30.812635, Params tensor([2.0874, 0.0987])\n",
      "Epoch 3052, Loss 30.811035, Params tensor([2.0876, 0.0986])\n",
      "Epoch 3053, Loss 30.809431, Params tensor([2.0877, 0.0986])\n",
      "Epoch 3054, Loss 30.807829, Params tensor([2.0878, 0.0986])\n",
      "Epoch 3055, Loss 30.806231, Params tensor([2.0879, 0.0986])\n",
      "Epoch 3056, Loss 30.804634, Params tensor([2.0881, 0.0986])\n",
      "Epoch 3057, Loss 30.803040, Params tensor([2.0882, 0.0986])\n",
      "Epoch 3058, Loss 30.801445, Params tensor([2.0883, 0.0986])\n",
      "Epoch 3059, Loss 30.799858, Params tensor([2.0884, 0.0986])\n",
      "Epoch 3060, Loss 30.798262, Params tensor([2.0886, 0.0986])\n",
      "Epoch 3061, Loss 30.796680, Params tensor([2.0887, 0.0986])\n",
      "Epoch 3062, Loss 30.795094, Params tensor([2.0888, 0.0986])\n",
      "Epoch 3063, Loss 30.793510, Params tensor([2.0889, 0.0986])\n",
      "Epoch 3064, Loss 30.791925, Params tensor([2.0891, 0.0985])\n",
      "Epoch 3065, Loss 30.790344, Params tensor([2.0892, 0.0985])\n",
      "Epoch 3066, Loss 30.788765, Params tensor([2.0893, 0.0985])\n",
      "Epoch 3067, Loss 30.787188, Params tensor([2.0894, 0.0985])\n",
      "Epoch 3068, Loss 30.785612, Params tensor([2.0896, 0.0985])\n",
      "Epoch 3069, Loss 30.784046, Params tensor([2.0897, 0.0985])\n",
      "Epoch 3070, Loss 30.782465, Params tensor([2.0898, 0.0985])\n",
      "Epoch 3071, Loss 30.780895, Params tensor([2.0899, 0.0985])\n",
      "Epoch 3072, Loss 30.779329, Params tensor([2.0901, 0.0985])\n",
      "Epoch 3073, Loss 30.777763, Params tensor([2.0902, 0.0985])\n",
      "Epoch 3074, Loss 30.776201, Params tensor([2.0903, 0.0985])\n",
      "Epoch 3075, Loss 30.774635, Params tensor([2.0904, 0.0985])\n",
      "Epoch 3076, Loss 30.773079, Params tensor([2.0906, 0.0984])\n",
      "Epoch 3077, Loss 30.771513, Params tensor([2.0907, 0.0984])\n",
      "Epoch 3078, Loss 30.769958, Params tensor([2.0908, 0.0984])\n",
      "Epoch 3079, Loss 30.768404, Params tensor([2.0909, 0.0984])\n",
      "Epoch 3080, Loss 30.766851, Params tensor([2.0911, 0.0984])\n",
      "Epoch 3081, Loss 30.765297, Params tensor([2.0912, 0.0984])\n",
      "Epoch 3082, Loss 30.763750, Params tensor([2.0913, 0.0984])\n",
      "Epoch 3083, Loss 30.762201, Params tensor([2.0914, 0.0984])\n",
      "Epoch 3084, Loss 30.760656, Params tensor([2.0916, 0.0984])\n",
      "Epoch 3085, Loss 30.759108, Params tensor([2.0917, 0.0984])\n",
      "Epoch 3086, Loss 30.757568, Params tensor([2.0918, 0.0984])\n",
      "Epoch 3087, Loss 30.756020, Params tensor([2.0919, 0.0983])\n",
      "Epoch 3088, Loss 30.754486, Params tensor([2.0921, 0.0983])\n",
      "Epoch 3089, Loss 30.752943, Params tensor([2.0922, 0.0983])\n",
      "Epoch 3090, Loss 30.751411, Params tensor([2.0923, 0.0983])\n",
      "Epoch 3091, Loss 30.749876, Params tensor([2.0924, 0.0983])\n",
      "Epoch 3092, Loss 30.748344, Params tensor([2.0926, 0.0983])\n",
      "Epoch 3093, Loss 30.746815, Params tensor([2.0927, 0.0983])\n",
      "Epoch 3094, Loss 30.745281, Params tensor([2.0928, 0.0983])\n",
      "Epoch 3095, Loss 30.743757, Params tensor([2.0929, 0.0983])\n",
      "Epoch 3096, Loss 30.742231, Params tensor([2.0930, 0.0983])\n",
      "Epoch 3097, Loss 30.740705, Params tensor([2.0932, 0.0983])\n",
      "Epoch 3098, Loss 30.739185, Params tensor([2.0933, 0.0983])\n",
      "Epoch 3099, Loss 30.737665, Params tensor([2.0934, 0.0982])\n",
      "Epoch 3100, Loss 30.736143, Params tensor([2.0935, 0.0982])\n",
      "Epoch 3101, Loss 30.734625, Params tensor([2.0937, 0.0982])\n",
      "Epoch 3102, Loss 30.733112, Params tensor([2.0938, 0.0982])\n",
      "Epoch 3103, Loss 30.731598, Params tensor([2.0939, 0.0982])\n",
      "Epoch 3104, Loss 30.730091, Params tensor([2.0940, 0.0982])\n",
      "Epoch 3105, Loss 30.728577, Params tensor([2.0941, 0.0982])\n",
      "Epoch 3106, Loss 30.727064, Params tensor([2.0943, 0.0982])\n",
      "Epoch 3107, Loss 30.725563, Params tensor([2.0944, 0.0982])\n",
      "Epoch 3108, Loss 30.724058, Params tensor([2.0945, 0.0982])\n",
      "Epoch 3109, Loss 30.722553, Params tensor([2.0946, 0.0982])\n",
      "Epoch 3110, Loss 30.721052, Params tensor([2.0948, 0.0981])\n",
      "Epoch 3111, Loss 30.719551, Params tensor([2.0949, 0.0981])\n",
      "Epoch 3112, Loss 30.718054, Params tensor([2.0950, 0.0981])\n",
      "Epoch 3113, Loss 30.716558, Params tensor([2.0951, 0.0981])\n",
      "Epoch 3114, Loss 30.715063, Params tensor([2.0952, 0.0981])\n",
      "Epoch 3115, Loss 30.713573, Params tensor([2.0954, 0.0981])\n",
      "Epoch 3116, Loss 30.712080, Params tensor([2.0955, 0.0981])\n",
      "Epoch 3117, Loss 30.710594, Params tensor([2.0956, 0.0981])\n",
      "Epoch 3118, Loss 30.709105, Params tensor([2.0957, 0.0981])\n",
      "Epoch 3119, Loss 30.707613, Params tensor([2.0959, 0.0981])\n",
      "Epoch 3120, Loss 30.706133, Params tensor([2.0960, 0.0981])\n",
      "Epoch 3121, Loss 30.704651, Params tensor([2.0961, 0.0980])\n",
      "Epoch 3122, Loss 30.703167, Params tensor([2.0962, 0.0980])\n",
      "Epoch 3123, Loss 30.701689, Params tensor([2.0963, 0.0980])\n",
      "Epoch 3124, Loss 30.700214, Params tensor([2.0965, 0.0980])\n",
      "Epoch 3125, Loss 30.698742, Params tensor([2.0966, 0.0980])\n",
      "Epoch 3126, Loss 30.697266, Params tensor([2.0967, 0.0980])\n",
      "Epoch 3127, Loss 30.695789, Params tensor([2.0968, 0.0980])\n",
      "Epoch 3128, Loss 30.694323, Params tensor([2.0969, 0.0980])\n",
      "Epoch 3129, Loss 30.692854, Params tensor([2.0971, 0.0980])\n",
      "Epoch 3130, Loss 30.691381, Params tensor([2.0972, 0.0980])\n",
      "Epoch 3131, Loss 30.689919, Params tensor([2.0973, 0.0980])\n",
      "Epoch 3132, Loss 30.688457, Params tensor([2.0974, 0.0979])\n",
      "Epoch 3133, Loss 30.686989, Params tensor([2.0975, 0.0979])\n",
      "Epoch 3134, Loss 30.685530, Params tensor([2.0977, 0.0979])\n",
      "Epoch 3135, Loss 30.684069, Params tensor([2.0978, 0.0979])\n",
      "Epoch 3136, Loss 30.682617, Params tensor([2.0979, 0.0979])\n",
      "Epoch 3137, Loss 30.681158, Params tensor([2.0980, 0.0979])\n",
      "Epoch 3138, Loss 30.679705, Params tensor([2.0982, 0.0979])\n",
      "Epoch 3139, Loss 30.678251, Params tensor([2.0983, 0.0979])\n",
      "Epoch 3140, Loss 30.676802, Params tensor([2.0984, 0.0979])\n",
      "Epoch 3141, Loss 30.675348, Params tensor([2.0985, 0.0979])\n",
      "Epoch 3142, Loss 30.673901, Params tensor([2.0986, 0.0979])\n",
      "Epoch 3143, Loss 30.672457, Params tensor([2.0988, 0.0978])\n",
      "Epoch 3144, Loss 30.671013, Params tensor([2.0989, 0.0978])\n",
      "Epoch 3145, Loss 30.669569, Params tensor([2.0990, 0.0978])\n",
      "Epoch 3146, Loss 30.668127, Params tensor([2.0991, 0.0978])\n",
      "Epoch 3147, Loss 30.666689, Params tensor([2.0992, 0.0978])\n",
      "Epoch 3148, Loss 30.665253, Params tensor([2.0993, 0.0978])\n",
      "Epoch 3149, Loss 30.663816, Params tensor([2.0995, 0.0978])\n",
      "Epoch 3150, Loss 30.662382, Params tensor([2.0996, 0.0978])\n",
      "Epoch 3151, Loss 30.660950, Params tensor([2.0997, 0.0978])\n",
      "Epoch 3152, Loss 30.659517, Params tensor([2.0998, 0.0978])\n",
      "Epoch 3153, Loss 30.658087, Params tensor([2.0999, 0.0977])\n",
      "Epoch 3154, Loss 30.656660, Params tensor([2.1001, 0.0977])\n",
      "Epoch 3155, Loss 30.655235, Params tensor([2.1002, 0.0977])\n",
      "Epoch 3156, Loss 30.653809, Params tensor([2.1003, 0.0977])\n",
      "Epoch 3157, Loss 30.652386, Params tensor([2.1004, 0.0977])\n",
      "Epoch 3158, Loss 30.650963, Params tensor([2.1005, 0.0977])\n",
      "Epoch 3159, Loss 30.649548, Params tensor([2.1007, 0.0977])\n",
      "Epoch 3160, Loss 30.648127, Params tensor([2.1008, 0.0977])\n",
      "Epoch 3161, Loss 30.646706, Params tensor([2.1009, 0.0977])\n",
      "Epoch 3162, Loss 30.645292, Params tensor([2.1010, 0.0977])\n",
      "Epoch 3163, Loss 30.643879, Params tensor([2.1011, 0.0977])\n",
      "Epoch 3164, Loss 30.642469, Params tensor([2.1013, 0.0976])\n",
      "Epoch 3165, Loss 30.641058, Params tensor([2.1014, 0.0976])\n",
      "Epoch 3166, Loss 30.639648, Params tensor([2.1015, 0.0976])\n",
      "Epoch 3167, Loss 30.638239, Params tensor([2.1016, 0.0976])\n",
      "Epoch 3168, Loss 30.636835, Params tensor([2.1017, 0.0976])\n",
      "Epoch 3169, Loss 30.635431, Params tensor([2.1018, 0.0976])\n",
      "Epoch 3170, Loss 30.634027, Params tensor([2.1020, 0.0976])\n",
      "Epoch 3171, Loss 30.632624, Params tensor([2.1021, 0.0976])\n",
      "Epoch 3172, Loss 30.631226, Params tensor([2.1022, 0.0976])\n",
      "Epoch 3173, Loss 30.629829, Params tensor([2.1023, 0.0976])\n",
      "Epoch 3174, Loss 30.628437, Params tensor([2.1024, 0.0975])\n",
      "Epoch 3175, Loss 30.627039, Params tensor([2.1025, 0.0975])\n",
      "Epoch 3176, Loss 30.625652, Params tensor([2.1027, 0.0975])\n",
      "Epoch 3177, Loss 30.624260, Params tensor([2.1028, 0.0975])\n",
      "Epoch 3178, Loss 30.622866, Params tensor([2.1029, 0.0975])\n",
      "Epoch 3179, Loss 30.621473, Params tensor([2.1030, 0.0975])\n",
      "Epoch 3180, Loss 30.620092, Params tensor([2.1031, 0.0975])\n",
      "Epoch 3181, Loss 30.618706, Params tensor([2.1033, 0.0975])\n",
      "Epoch 3182, Loss 30.617321, Params tensor([2.1034, 0.0975])\n",
      "Epoch 3183, Loss 30.615944, Params tensor([2.1035, 0.0975])\n",
      "Epoch 3184, Loss 30.614561, Params tensor([2.1036, 0.0974])\n",
      "Epoch 3185, Loss 30.613176, Params tensor([2.1037, 0.0974])\n",
      "Epoch 3186, Loss 30.611805, Params tensor([2.1038, 0.0974])\n",
      "Epoch 3187, Loss 30.610430, Params tensor([2.1040, 0.0974])\n",
      "Epoch 3188, Loss 30.609053, Params tensor([2.1041, 0.0974])\n",
      "Epoch 3189, Loss 30.607683, Params tensor([2.1042, 0.0974])\n",
      "Epoch 3190, Loss 30.606310, Params tensor([2.1043, 0.0974])\n",
      "Epoch 3191, Loss 30.604942, Params tensor([2.1044, 0.0974])\n",
      "Epoch 3192, Loss 30.603577, Params tensor([2.1045, 0.0974])\n",
      "Epoch 3193, Loss 30.602205, Params tensor([2.1047, 0.0974])\n",
      "Epoch 3194, Loss 30.600847, Params tensor([2.1048, 0.0973])\n",
      "Epoch 3195, Loss 30.599480, Params tensor([2.1049, 0.0973])\n",
      "Epoch 3196, Loss 30.598116, Params tensor([2.1050, 0.0973])\n",
      "Epoch 3197, Loss 30.596758, Params tensor([2.1051, 0.0973])\n",
      "Epoch 3198, Loss 30.595398, Params tensor([2.1052, 0.0973])\n",
      "Epoch 3199, Loss 30.594042, Params tensor([2.1054, 0.0973])\n",
      "Epoch 3200, Loss 30.592688, Params tensor([2.1055, 0.0973])\n",
      "Epoch 3201, Loss 30.591333, Params tensor([2.1056, 0.0973])\n",
      "Epoch 3202, Loss 30.589979, Params tensor([2.1057, 0.0973])\n",
      "Epoch 3203, Loss 30.588629, Params tensor([2.1058, 0.0973])\n",
      "Epoch 3204, Loss 30.587280, Params tensor([2.1059, 0.0972])\n",
      "Epoch 3205, Loss 30.585932, Params tensor([2.1060, 0.0972])\n",
      "Epoch 3206, Loss 30.584589, Params tensor([2.1062, 0.0972])\n",
      "Epoch 3207, Loss 30.583246, Params tensor([2.1063, 0.0972])\n",
      "Epoch 3208, Loss 30.581898, Params tensor([2.1064, 0.0972])\n",
      "Epoch 3209, Loss 30.580559, Params tensor([2.1065, 0.0972])\n",
      "Epoch 3210, Loss 30.579218, Params tensor([2.1066, 0.0972])\n",
      "Epoch 3211, Loss 30.577881, Params tensor([2.1067, 0.0972])\n",
      "Epoch 3212, Loss 30.576540, Params tensor([2.1069, 0.0972])\n",
      "Epoch 3213, Loss 30.575207, Params tensor([2.1070, 0.0972])\n",
      "Epoch 3214, Loss 30.573870, Params tensor([2.1071, 0.0971])\n",
      "Epoch 3215, Loss 30.572538, Params tensor([2.1072, 0.0971])\n",
      "Epoch 3216, Loss 30.571205, Params tensor([2.1073, 0.0971])\n",
      "Epoch 3217, Loss 30.569880, Params tensor([2.1074, 0.0971])\n",
      "Epoch 3218, Loss 30.568544, Params tensor([2.1075, 0.0971])\n",
      "Epoch 3219, Loss 30.567228, Params tensor([2.1077, 0.0971])\n",
      "Epoch 3220, Loss 30.565895, Params tensor([2.1078, 0.0971])\n",
      "Epoch 3221, Loss 30.564575, Params tensor([2.1079, 0.0971])\n",
      "Epoch 3222, Loss 30.563255, Params tensor([2.1080, 0.0971])\n",
      "Epoch 3223, Loss 30.561928, Params tensor([2.1081, 0.0971])\n",
      "Epoch 3224, Loss 30.560616, Params tensor([2.1082, 0.0970])\n",
      "Epoch 3225, Loss 30.559296, Params tensor([2.1083, 0.0970])\n",
      "Epoch 3226, Loss 30.557978, Params tensor([2.1085, 0.0970])\n",
      "Epoch 3227, Loss 30.556664, Params tensor([2.1086, 0.0970])\n",
      "Epoch 3228, Loss 30.555351, Params tensor([2.1087, 0.0970])\n",
      "Epoch 3229, Loss 30.554039, Params tensor([2.1088, 0.0970])\n",
      "Epoch 3230, Loss 30.552729, Params tensor([2.1089, 0.0970])\n",
      "Epoch 3231, Loss 30.551420, Params tensor([2.1090, 0.0970])\n",
      "Epoch 3232, Loss 30.550116, Params tensor([2.1091, 0.0970])\n",
      "Epoch 3233, Loss 30.548811, Params tensor([2.1093, 0.0969])\n",
      "Epoch 3234, Loss 30.547503, Params tensor([2.1094, 0.0969])\n",
      "Epoch 3235, Loss 30.546204, Params tensor([2.1095, 0.0969])\n",
      "Epoch 3236, Loss 30.544897, Params tensor([2.1096, 0.0969])\n",
      "Epoch 3237, Loss 30.543598, Params tensor([2.1097, 0.0969])\n",
      "Epoch 3238, Loss 30.542299, Params tensor([2.1098, 0.0969])\n",
      "Epoch 3239, Loss 30.541004, Params tensor([2.1099, 0.0969])\n",
      "Epoch 3240, Loss 30.539711, Params tensor([2.1101, 0.0969])\n",
      "Epoch 3241, Loss 30.538414, Params tensor([2.1102, 0.0969])\n",
      "Epoch 3242, Loss 30.537121, Params tensor([2.1103, 0.0969])\n",
      "Epoch 3243, Loss 30.535830, Params tensor([2.1104, 0.0968])\n",
      "Epoch 3244, Loss 30.534534, Params tensor([2.1105, 0.0968])\n",
      "Epoch 3245, Loss 30.533253, Params tensor([2.1106, 0.0968])\n",
      "Epoch 3246, Loss 30.531969, Params tensor([2.1107, 0.0968])\n",
      "Epoch 3247, Loss 30.530682, Params tensor([2.1108, 0.0968])\n",
      "Epoch 3248, Loss 30.529394, Params tensor([2.1110, 0.0968])\n",
      "Epoch 3249, Loss 30.528112, Params tensor([2.1111, 0.0968])\n",
      "Epoch 3250, Loss 30.526836, Params tensor([2.1112, 0.0968])\n",
      "Epoch 3251, Loss 30.525555, Params tensor([2.1113, 0.0968])\n",
      "Epoch 3252, Loss 30.524279, Params tensor([2.1114, 0.0967])\n",
      "Epoch 3253, Loss 30.522999, Params tensor([2.1115, 0.0967])\n",
      "Epoch 3254, Loss 30.521723, Params tensor([2.1116, 0.0967])\n",
      "Epoch 3255, Loss 30.520452, Params tensor([2.1117, 0.0967])\n",
      "Epoch 3256, Loss 30.519176, Params tensor([2.1119, 0.0967])\n",
      "Epoch 3257, Loss 30.517912, Params tensor([2.1120, 0.0967])\n",
      "Epoch 3258, Loss 30.516640, Params tensor([2.1121, 0.0967])\n",
      "Epoch 3259, Loss 30.515369, Params tensor([2.1122, 0.0967])\n",
      "Epoch 3260, Loss 30.514107, Params tensor([2.1123, 0.0967])\n",
      "Epoch 3261, Loss 30.512840, Params tensor([2.1124, 0.0967])\n",
      "Epoch 3262, Loss 30.511574, Params tensor([2.1125, 0.0966])\n",
      "Epoch 3263, Loss 30.510317, Params tensor([2.1126, 0.0966])\n",
      "Epoch 3264, Loss 30.509050, Params tensor([2.1128, 0.0966])\n",
      "Epoch 3265, Loss 30.507790, Params tensor([2.1129, 0.0966])\n",
      "Epoch 3266, Loss 30.506536, Params tensor([2.1130, 0.0966])\n",
      "Epoch 3267, Loss 30.505278, Params tensor([2.1131, 0.0966])\n",
      "Epoch 3268, Loss 30.504023, Params tensor([2.1132, 0.0966])\n",
      "Epoch 3269, Loss 30.502769, Params tensor([2.1133, 0.0966])\n",
      "Epoch 3270, Loss 30.501514, Params tensor([2.1134, 0.0966])\n",
      "Epoch 3271, Loss 30.500267, Params tensor([2.1135, 0.0965])\n",
      "Epoch 3272, Loss 30.499016, Params tensor([2.1136, 0.0965])\n",
      "Epoch 3273, Loss 30.497772, Params tensor([2.1138, 0.0965])\n",
      "Epoch 3274, Loss 30.496515, Params tensor([2.1139, 0.0965])\n",
      "Epoch 3275, Loss 30.495272, Params tensor([2.1140, 0.0965])\n",
      "Epoch 3276, Loss 30.494032, Params tensor([2.1141, 0.0965])\n",
      "Epoch 3277, Loss 30.492792, Params tensor([2.1142, 0.0965])\n",
      "Epoch 3278, Loss 30.491547, Params tensor([2.1143, 0.0965])\n",
      "Epoch 3279, Loss 30.490309, Params tensor([2.1144, 0.0965])\n",
      "Epoch 3280, Loss 30.489069, Params tensor([2.1145, 0.0964])\n",
      "Epoch 3281, Loss 30.487831, Params tensor([2.1146, 0.0964])\n",
      "Epoch 3282, Loss 30.486595, Params tensor([2.1148, 0.0964])\n",
      "Epoch 3283, Loss 30.485363, Params tensor([2.1149, 0.0964])\n",
      "Epoch 3284, Loss 30.484131, Params tensor([2.1150, 0.0964])\n",
      "Epoch 3285, Loss 30.482903, Params tensor([2.1151, 0.0964])\n",
      "Epoch 3286, Loss 30.481667, Params tensor([2.1152, 0.0964])\n",
      "Epoch 3287, Loss 30.480438, Params tensor([2.1153, 0.0964])\n",
      "Epoch 3288, Loss 30.479212, Params tensor([2.1154, 0.0964])\n",
      "Epoch 3289, Loss 30.477991, Params tensor([2.1155, 0.0963])\n",
      "Epoch 3290, Loss 30.476768, Params tensor([2.1156, 0.0963])\n",
      "Epoch 3291, Loss 30.475536, Params tensor([2.1157, 0.0963])\n",
      "Epoch 3292, Loss 30.474316, Params tensor([2.1159, 0.0963])\n",
      "Epoch 3293, Loss 30.473095, Params tensor([2.1160, 0.0963])\n",
      "Epoch 3294, Loss 30.471880, Params tensor([2.1161, 0.0963])\n",
      "Epoch 3295, Loss 30.470659, Params tensor([2.1162, 0.0963])\n",
      "Epoch 3296, Loss 30.469450, Params tensor([2.1163, 0.0963])\n",
      "Epoch 3297, Loss 30.468229, Params tensor([2.1164, 0.0963])\n",
      "Epoch 3298, Loss 30.467016, Params tensor([2.1165, 0.0962])\n",
      "Epoch 3299, Loss 30.465803, Params tensor([2.1166, 0.0962])\n",
      "Epoch 3300, Loss 30.464594, Params tensor([2.1167, 0.0962])\n",
      "Epoch 3301, Loss 30.463387, Params tensor([2.1168, 0.0962])\n",
      "Epoch 3302, Loss 30.462175, Params tensor([2.1169, 0.0962])\n",
      "Epoch 3303, Loss 30.460970, Params tensor([2.1171, 0.0962])\n",
      "Epoch 3304, Loss 30.459764, Params tensor([2.1172, 0.0962])\n",
      "Epoch 3305, Loss 30.458557, Params tensor([2.1173, 0.0962])\n",
      "Epoch 3306, Loss 30.457354, Params tensor([2.1174, 0.0962])\n",
      "Epoch 3307, Loss 30.456154, Params tensor([2.1175, 0.0961])\n",
      "Epoch 3308, Loss 30.454956, Params tensor([2.1176, 0.0961])\n",
      "Epoch 3309, Loss 30.453758, Params tensor([2.1177, 0.0961])\n",
      "Epoch 3310, Loss 30.452559, Params tensor([2.1178, 0.0961])\n",
      "Epoch 3311, Loss 30.451363, Params tensor([2.1179, 0.0961])\n",
      "Epoch 3312, Loss 30.450167, Params tensor([2.1180, 0.0961])\n",
      "Epoch 3313, Loss 30.448973, Params tensor([2.1181, 0.0961])\n",
      "Epoch 3314, Loss 30.447783, Params tensor([2.1183, 0.0961])\n",
      "Epoch 3315, Loss 30.446592, Params tensor([2.1184, 0.0961])\n",
      "Epoch 3316, Loss 30.445402, Params tensor([2.1185, 0.0960])\n",
      "Epoch 3317, Loss 30.444212, Params tensor([2.1186, 0.0960])\n",
      "Epoch 3318, Loss 30.443029, Params tensor([2.1187, 0.0960])\n",
      "Epoch 3319, Loss 30.441845, Params tensor([2.1188, 0.0960])\n",
      "Epoch 3320, Loss 30.440657, Params tensor([2.1189, 0.0960])\n",
      "Epoch 3321, Loss 30.439476, Params tensor([2.1190, 0.0960])\n",
      "Epoch 3322, Loss 30.438295, Params tensor([2.1191, 0.0960])\n",
      "Epoch 3323, Loss 30.437117, Params tensor([2.1192, 0.0960])\n",
      "Epoch 3324, Loss 30.435936, Params tensor([2.1193, 0.0959])\n",
      "Epoch 3325, Loss 30.434753, Params tensor([2.1194, 0.0959])\n",
      "Epoch 3326, Loss 30.433586, Params tensor([2.1196, 0.0959])\n",
      "Epoch 3327, Loss 30.432409, Params tensor([2.1197, 0.0959])\n",
      "Epoch 3328, Loss 30.431236, Params tensor([2.1198, 0.0959])\n",
      "Epoch 3329, Loss 30.430059, Params tensor([2.1199, 0.0959])\n",
      "Epoch 3330, Loss 30.428896, Params tensor([2.1200, 0.0959])\n",
      "Epoch 3331, Loss 30.427723, Params tensor([2.1201, 0.0959])\n",
      "Epoch 3332, Loss 30.426550, Params tensor([2.1202, 0.0959])\n",
      "Epoch 3333, Loss 30.425383, Params tensor([2.1203, 0.0958])\n",
      "Epoch 3334, Loss 30.424223, Params tensor([2.1204, 0.0958])\n",
      "Epoch 3335, Loss 30.423058, Params tensor([2.1205, 0.0958])\n",
      "Epoch 3336, Loss 30.421888, Params tensor([2.1206, 0.0958])\n",
      "Epoch 3337, Loss 30.420732, Params tensor([2.1207, 0.0958])\n",
      "Epoch 3338, Loss 30.419569, Params tensor([2.1208, 0.0958])\n",
      "Epoch 3339, Loss 30.418409, Params tensor([2.1209, 0.0958])\n",
      "Epoch 3340, Loss 30.417259, Params tensor([2.1211, 0.0958])\n",
      "Epoch 3341, Loss 30.416101, Params tensor([2.1212, 0.0958])\n",
      "Epoch 3342, Loss 30.414946, Params tensor([2.1213, 0.0957])\n",
      "Epoch 3343, Loss 30.413790, Params tensor([2.1214, 0.0957])\n",
      "Epoch 3344, Loss 30.412636, Params tensor([2.1215, 0.0957])\n",
      "Epoch 3345, Loss 30.411488, Params tensor([2.1216, 0.0957])\n",
      "Epoch 3346, Loss 30.410337, Params tensor([2.1217, 0.0957])\n",
      "Epoch 3347, Loss 30.409185, Params tensor([2.1218, 0.0957])\n",
      "Epoch 3348, Loss 30.408045, Params tensor([2.1219, 0.0957])\n",
      "Epoch 3349, Loss 30.406898, Params tensor([2.1220, 0.0957])\n",
      "Epoch 3350, Loss 30.405754, Params tensor([2.1221, 0.0956])\n",
      "Epoch 3351, Loss 30.404608, Params tensor([2.1222, 0.0956])\n",
      "Epoch 3352, Loss 30.403465, Params tensor([2.1223, 0.0956])\n",
      "Epoch 3353, Loss 30.402325, Params tensor([2.1224, 0.0956])\n",
      "Epoch 3354, Loss 30.401184, Params tensor([2.1225, 0.0956])\n",
      "Epoch 3355, Loss 30.400049, Params tensor([2.1227, 0.0956])\n",
      "Epoch 3356, Loss 30.398903, Params tensor([2.1228, 0.0956])\n",
      "Epoch 3357, Loss 30.397774, Params tensor([2.1229, 0.0956])\n",
      "Epoch 3358, Loss 30.396639, Params tensor([2.1230, 0.0956])\n",
      "Epoch 3359, Loss 30.395506, Params tensor([2.1231, 0.0955])\n",
      "Epoch 3360, Loss 30.394371, Params tensor([2.1232, 0.0955])\n",
      "Epoch 3361, Loss 30.393242, Params tensor([2.1233, 0.0955])\n",
      "Epoch 3362, Loss 30.392107, Params tensor([2.1234, 0.0955])\n",
      "Epoch 3363, Loss 30.390980, Params tensor([2.1235, 0.0955])\n",
      "Epoch 3364, Loss 30.389854, Params tensor([2.1236, 0.0955])\n",
      "Epoch 3365, Loss 30.388727, Params tensor([2.1237, 0.0955])\n",
      "Epoch 3366, Loss 30.387602, Params tensor([2.1238, 0.0955])\n",
      "Epoch 3367, Loss 30.386477, Params tensor([2.1239, 0.0954])\n",
      "Epoch 3368, Loss 30.385357, Params tensor([2.1240, 0.0954])\n",
      "Epoch 3369, Loss 30.384235, Params tensor([2.1241, 0.0954])\n",
      "Epoch 3370, Loss 30.383118, Params tensor([2.1242, 0.0954])\n",
      "Epoch 3371, Loss 30.381996, Params tensor([2.1243, 0.0954])\n",
      "Epoch 3372, Loss 30.380882, Params tensor([2.1244, 0.0954])\n",
      "Epoch 3373, Loss 30.379761, Params tensor([2.1245, 0.0954])\n",
      "Epoch 3374, Loss 30.378649, Params tensor([2.1247, 0.0954])\n",
      "Epoch 3375, Loss 30.377535, Params tensor([2.1248, 0.0954])\n",
      "Epoch 3376, Loss 30.376423, Params tensor([2.1249, 0.0953])\n",
      "Epoch 3377, Loss 30.375317, Params tensor([2.1250, 0.0953])\n",
      "Epoch 3378, Loss 30.374207, Params tensor([2.1251, 0.0953])\n",
      "Epoch 3379, Loss 30.373096, Params tensor([2.1252, 0.0953])\n",
      "Epoch 3380, Loss 30.371986, Params tensor([2.1253, 0.0953])\n",
      "Epoch 3381, Loss 30.370886, Params tensor([2.1254, 0.0953])\n",
      "Epoch 3382, Loss 30.369781, Params tensor([2.1255, 0.0953])\n",
      "Epoch 3383, Loss 30.368675, Params tensor([2.1256, 0.0953])\n",
      "Epoch 3384, Loss 30.367577, Params tensor([2.1257, 0.0952])\n",
      "Epoch 3385, Loss 30.366472, Params tensor([2.1258, 0.0952])\n",
      "Epoch 3386, Loss 30.365374, Params tensor([2.1259, 0.0952])\n",
      "Epoch 3387, Loss 30.364277, Params tensor([2.1260, 0.0952])\n",
      "Epoch 3388, Loss 30.363178, Params tensor([2.1261, 0.0952])\n",
      "Epoch 3389, Loss 30.362083, Params tensor([2.1262, 0.0952])\n",
      "Epoch 3390, Loss 30.360992, Params tensor([2.1263, 0.0952])\n",
      "Epoch 3391, Loss 30.359892, Params tensor([2.1264, 0.0952])\n",
      "Epoch 3392, Loss 30.358803, Params tensor([2.1265, 0.0951])\n",
      "Epoch 3393, Loss 30.357716, Params tensor([2.1266, 0.0951])\n",
      "Epoch 3394, Loss 30.356621, Params tensor([2.1267, 0.0951])\n",
      "Epoch 3395, Loss 30.355536, Params tensor([2.1268, 0.0951])\n",
      "Epoch 3396, Loss 30.354445, Params tensor([2.1269, 0.0951])\n",
      "Epoch 3397, Loss 30.353363, Params tensor([2.1270, 0.0951])\n",
      "Epoch 3398, Loss 30.352276, Params tensor([2.1272, 0.0951])\n",
      "Epoch 3399, Loss 30.351191, Params tensor([2.1273, 0.0951])\n",
      "Epoch 3400, Loss 30.350109, Params tensor([2.1274, 0.0950])\n",
      "Epoch 3401, Loss 30.349028, Params tensor([2.1275, 0.0950])\n",
      "Epoch 3402, Loss 30.347948, Params tensor([2.1276, 0.0950])\n",
      "Epoch 3403, Loss 30.346865, Params tensor([2.1277, 0.0950])\n",
      "Epoch 3404, Loss 30.345787, Params tensor([2.1278, 0.0950])\n",
      "Epoch 3405, Loss 30.344713, Params tensor([2.1279, 0.0950])\n",
      "Epoch 3406, Loss 30.343639, Params tensor([2.1280, 0.0950])\n",
      "Epoch 3407, Loss 30.342566, Params tensor([2.1281, 0.0950])\n",
      "Epoch 3408, Loss 30.341492, Params tensor([2.1282, 0.0949])\n",
      "Epoch 3409, Loss 30.340422, Params tensor([2.1283, 0.0949])\n",
      "Epoch 3410, Loss 30.339350, Params tensor([2.1284, 0.0949])\n",
      "Epoch 3411, Loss 30.338280, Params tensor([2.1285, 0.0949])\n",
      "Epoch 3412, Loss 30.337212, Params tensor([2.1286, 0.0949])\n",
      "Epoch 3413, Loss 30.336143, Params tensor([2.1287, 0.0949])\n",
      "Epoch 3414, Loss 30.335081, Params tensor([2.1288, 0.0949])\n",
      "Epoch 3415, Loss 30.334013, Params tensor([2.1289, 0.0949])\n",
      "Epoch 3416, Loss 30.332954, Params tensor([2.1290, 0.0948])\n",
      "Epoch 3417, Loss 30.331890, Params tensor([2.1291, 0.0948])\n",
      "Epoch 3418, Loss 30.330828, Params tensor([2.1292, 0.0948])\n",
      "Epoch 3419, Loss 30.329765, Params tensor([2.1293, 0.0948])\n",
      "Epoch 3420, Loss 30.328705, Params tensor([2.1294, 0.0948])\n",
      "Epoch 3421, Loss 30.327648, Params tensor([2.1295, 0.0948])\n",
      "Epoch 3422, Loss 30.326593, Params tensor([2.1296, 0.0948])\n",
      "Epoch 3423, Loss 30.325533, Params tensor([2.1297, 0.0948])\n",
      "Epoch 3424, Loss 30.324480, Params tensor([2.1298, 0.0947])\n",
      "Epoch 3425, Loss 30.323427, Params tensor([2.1299, 0.0947])\n",
      "Epoch 3426, Loss 30.322376, Params tensor([2.1300, 0.0947])\n",
      "Epoch 3427, Loss 30.321325, Params tensor([2.1301, 0.0947])\n",
      "Epoch 3428, Loss 30.320274, Params tensor([2.1302, 0.0947])\n",
      "Epoch 3429, Loss 30.319225, Params tensor([2.1303, 0.0947])\n",
      "Epoch 3430, Loss 30.318176, Params tensor([2.1304, 0.0947])\n",
      "Epoch 3431, Loss 30.317133, Params tensor([2.1305, 0.0947])\n",
      "Epoch 3432, Loss 30.316084, Params tensor([2.1306, 0.0946])\n",
      "Epoch 3433, Loss 30.315041, Params tensor([2.1307, 0.0946])\n",
      "Epoch 3434, Loss 30.313997, Params tensor([2.1308, 0.0946])\n",
      "Epoch 3435, Loss 30.312960, Params tensor([2.1309, 0.0946])\n",
      "Epoch 3436, Loss 30.311918, Params tensor([2.1310, 0.0946])\n",
      "Epoch 3437, Loss 30.310881, Params tensor([2.1311, 0.0946])\n",
      "Epoch 3438, Loss 30.309843, Params tensor([2.1312, 0.0946])\n",
      "Epoch 3439, Loss 30.308805, Params tensor([2.1313, 0.0946])\n",
      "Epoch 3440, Loss 30.307764, Params tensor([2.1314, 0.0945])\n",
      "Epoch 3441, Loss 30.306730, Params tensor([2.1315, 0.0945])\n",
      "Epoch 3442, Loss 30.305700, Params tensor([2.1316, 0.0945])\n",
      "Epoch 3443, Loss 30.304665, Params tensor([2.1317, 0.0945])\n",
      "Epoch 3444, Loss 30.303631, Params tensor([2.1318, 0.0945])\n",
      "Epoch 3445, Loss 30.302605, Params tensor([2.1319, 0.0945])\n",
      "Epoch 3446, Loss 30.301577, Params tensor([2.1320, 0.0945])\n",
      "Epoch 3447, Loss 30.300545, Params tensor([2.1321, 0.0945])\n",
      "Epoch 3448, Loss 30.299519, Params tensor([2.1322, 0.0944])\n",
      "Epoch 3449, Loss 30.298500, Params tensor([2.1323, 0.0944])\n",
      "Epoch 3450, Loss 30.297472, Params tensor([2.1324, 0.0944])\n",
      "Epoch 3451, Loss 30.296448, Params tensor([2.1325, 0.0944])\n",
      "Epoch 3452, Loss 30.295427, Params tensor([2.1326, 0.0944])\n",
      "Epoch 3453, Loss 30.294405, Params tensor([2.1327, 0.0944])\n",
      "Epoch 3454, Loss 30.293385, Params tensor([2.1328, 0.0944])\n",
      "Epoch 3455, Loss 30.292366, Params tensor([2.1329, 0.0944])\n",
      "Epoch 3456, Loss 30.291349, Params tensor([2.1330, 0.0943])\n",
      "Epoch 3457, Loss 30.290333, Params tensor([2.1331, 0.0943])\n",
      "Epoch 3458, Loss 30.289318, Params tensor([2.1332, 0.0943])\n",
      "Epoch 3459, Loss 30.288301, Params tensor([2.1333, 0.0943])\n",
      "Epoch 3460, Loss 30.287294, Params tensor([2.1334, 0.0943])\n",
      "Epoch 3461, Loss 30.286280, Params tensor([2.1335, 0.0943])\n",
      "Epoch 3462, Loss 30.285271, Params tensor([2.1336, 0.0943])\n",
      "Epoch 3463, Loss 30.284260, Params tensor([2.1337, 0.0943])\n",
      "Epoch 3464, Loss 30.283253, Params tensor([2.1338, 0.0942])\n",
      "Epoch 3465, Loss 30.282246, Params tensor([2.1339, 0.0942])\n",
      "Epoch 3466, Loss 30.281239, Params tensor([2.1340, 0.0942])\n",
      "Epoch 3467, Loss 30.280231, Params tensor([2.1341, 0.0942])\n",
      "Epoch 3468, Loss 30.279224, Params tensor([2.1342, 0.0942])\n",
      "Epoch 3469, Loss 30.278217, Params tensor([2.1343, 0.0942])\n",
      "Epoch 3470, Loss 30.277222, Params tensor([2.1344, 0.0942])\n",
      "Epoch 3471, Loss 30.276220, Params tensor([2.1345, 0.0941])\n",
      "Epoch 3472, Loss 30.275221, Params tensor([2.1346, 0.0941])\n",
      "Epoch 3473, Loss 30.274220, Params tensor([2.1347, 0.0941])\n",
      "Epoch 3474, Loss 30.273226, Params tensor([2.1348, 0.0941])\n",
      "Epoch 3475, Loss 30.272230, Params tensor([2.1349, 0.0941])\n",
      "Epoch 3476, Loss 30.271235, Params tensor([2.1350, 0.0941])\n",
      "Epoch 3477, Loss 30.270239, Params tensor([2.1351, 0.0941])\n",
      "Epoch 3478, Loss 30.269243, Params tensor([2.1352, 0.0941])\n",
      "Epoch 3479, Loss 30.268251, Params tensor([2.1353, 0.0940])\n",
      "Epoch 3480, Loss 30.267262, Params tensor([2.1354, 0.0940])\n",
      "Epoch 3481, Loss 30.266268, Params tensor([2.1355, 0.0940])\n",
      "Epoch 3482, Loss 30.265287, Params tensor([2.1356, 0.0940])\n",
      "Epoch 3483, Loss 30.264299, Params tensor([2.1357, 0.0940])\n",
      "Epoch 3484, Loss 30.263311, Params tensor([2.1358, 0.0940])\n",
      "Epoch 3485, Loss 30.262329, Params tensor([2.1359, 0.0940])\n",
      "Epoch 3486, Loss 30.261339, Params tensor([2.1360, 0.0940])\n",
      "Epoch 3487, Loss 30.260357, Params tensor([2.1361, 0.0939])\n",
      "Epoch 3488, Loss 30.259371, Params tensor([2.1362, 0.0939])\n",
      "Epoch 3489, Loss 30.258392, Params tensor([2.1363, 0.0939])\n",
      "Epoch 3490, Loss 30.257416, Params tensor([2.1364, 0.0939])\n",
      "Epoch 3491, Loss 30.256432, Params tensor([2.1365, 0.0939])\n",
      "Epoch 3492, Loss 30.255455, Params tensor([2.1366, 0.0939])\n",
      "Epoch 3493, Loss 30.254478, Params tensor([2.1367, 0.0939])\n",
      "Epoch 3494, Loss 30.253504, Params tensor([2.1368, 0.0938])\n",
      "Epoch 3495, Loss 30.252531, Params tensor([2.1369, 0.0938])\n",
      "Epoch 3496, Loss 30.251554, Params tensor([2.1370, 0.0938])\n",
      "Epoch 3497, Loss 30.250586, Params tensor([2.1371, 0.0938])\n",
      "Epoch 3498, Loss 30.249615, Params tensor([2.1372, 0.0938])\n",
      "Epoch 3499, Loss 30.248644, Params tensor([2.1373, 0.0938])\n",
      "Epoch 3500, Loss 30.247673, Params tensor([2.1374, 0.0938])\n",
      "Epoch 3501, Loss 30.246706, Params tensor([2.1375, 0.0938])\n",
      "Epoch 3502, Loss 30.245739, Params tensor([2.1376, 0.0937])\n",
      "Epoch 3503, Loss 30.244768, Params tensor([2.1377, 0.0937])\n",
      "Epoch 3504, Loss 30.243805, Params tensor([2.1378, 0.0937])\n",
      "Epoch 3505, Loss 30.242840, Params tensor([2.1379, 0.0937])\n",
      "Epoch 3506, Loss 30.241875, Params tensor([2.1380, 0.0937])\n",
      "Epoch 3507, Loss 30.240906, Params tensor([2.1381, 0.0937])\n",
      "Epoch 3508, Loss 30.239954, Params tensor([2.1382, 0.0937])\n",
      "Epoch 3509, Loss 30.238991, Params tensor([2.1383, 0.0936])\n",
      "Epoch 3510, Loss 30.238037, Params tensor([2.1384, 0.0936])\n",
      "Epoch 3511, Loss 30.237078, Params tensor([2.1385, 0.0936])\n",
      "Epoch 3512, Loss 30.236122, Params tensor([2.1386, 0.0936])\n",
      "Epoch 3513, Loss 30.235168, Params tensor([2.1387, 0.0936])\n",
      "Epoch 3514, Loss 30.234215, Params tensor([2.1388, 0.0936])\n",
      "Epoch 3515, Loss 30.233253, Params tensor([2.1388, 0.0936])\n",
      "Epoch 3516, Loss 30.232307, Params tensor([2.1389, 0.0936])\n",
      "Epoch 3517, Loss 30.231356, Params tensor([2.1390, 0.0935])\n",
      "Epoch 3518, Loss 30.230406, Params tensor([2.1391, 0.0935])\n",
      "Epoch 3519, Loss 30.229454, Params tensor([2.1392, 0.0935])\n",
      "Epoch 3520, Loss 30.228508, Params tensor([2.1393, 0.0935])\n",
      "Epoch 3521, Loss 30.227562, Params tensor([2.1394, 0.0935])\n",
      "Epoch 3522, Loss 30.226612, Params tensor([2.1395, 0.0935])\n",
      "Epoch 3523, Loss 30.225666, Params tensor([2.1396, 0.0935])\n",
      "Epoch 3524, Loss 30.224724, Params tensor([2.1397, 0.0934])\n",
      "Epoch 3525, Loss 30.223778, Params tensor([2.1398, 0.0934])\n",
      "Epoch 3526, Loss 30.222837, Params tensor([2.1399, 0.0934])\n",
      "Epoch 3527, Loss 30.221901, Params tensor([2.1400, 0.0934])\n",
      "Epoch 3528, Loss 30.220959, Params tensor([2.1401, 0.0934])\n",
      "Epoch 3529, Loss 30.220020, Params tensor([2.1402, 0.0934])\n",
      "Epoch 3530, Loss 30.219080, Params tensor([2.1403, 0.0934])\n",
      "Epoch 3531, Loss 30.218145, Params tensor([2.1404, 0.0933])\n",
      "Epoch 3532, Loss 30.217207, Params tensor([2.1405, 0.0933])\n",
      "Epoch 3533, Loss 30.216276, Params tensor([2.1406, 0.0933])\n",
      "Epoch 3534, Loss 30.215338, Params tensor([2.1407, 0.0933])\n",
      "Epoch 3535, Loss 30.214409, Params tensor([2.1408, 0.0933])\n",
      "Epoch 3536, Loss 30.213476, Params tensor([2.1409, 0.0933])\n",
      "Epoch 3537, Loss 30.212543, Params tensor([2.1410, 0.0933])\n",
      "Epoch 3538, Loss 30.211611, Params tensor([2.1411, 0.0933])\n",
      "Epoch 3539, Loss 30.210686, Params tensor([2.1412, 0.0932])\n",
      "Epoch 3540, Loss 30.209755, Params tensor([2.1412, 0.0932])\n",
      "Epoch 3541, Loss 30.208834, Params tensor([2.1413, 0.0932])\n",
      "Epoch 3542, Loss 30.207903, Params tensor([2.1414, 0.0932])\n",
      "Epoch 3543, Loss 30.206984, Params tensor([2.1415, 0.0932])\n",
      "Epoch 3544, Loss 30.206055, Params tensor([2.1416, 0.0932])\n",
      "Epoch 3545, Loss 30.205137, Params tensor([2.1417, 0.0932])\n",
      "Epoch 3546, Loss 30.204216, Params tensor([2.1418, 0.0931])\n",
      "Epoch 3547, Loss 30.203297, Params tensor([2.1419, 0.0931])\n",
      "Epoch 3548, Loss 30.202370, Params tensor([2.1420, 0.0931])\n",
      "Epoch 3549, Loss 30.201454, Params tensor([2.1421, 0.0931])\n",
      "Epoch 3550, Loss 30.200531, Params tensor([2.1422, 0.0931])\n",
      "Epoch 3551, Loss 30.199617, Params tensor([2.1423, 0.0931])\n",
      "Epoch 3552, Loss 30.198708, Params tensor([2.1424, 0.0931])\n",
      "Epoch 3553, Loss 30.197792, Params tensor([2.1425, 0.0930])\n",
      "Epoch 3554, Loss 30.196877, Params tensor([2.1426, 0.0930])\n",
      "Epoch 3555, Loss 30.195967, Params tensor([2.1427, 0.0930])\n",
      "Epoch 3556, Loss 30.195057, Params tensor([2.1428, 0.0930])\n",
      "Epoch 3557, Loss 30.194139, Params tensor([2.1429, 0.0930])\n",
      "Epoch 3558, Loss 30.193230, Params tensor([2.1430, 0.0930])\n",
      "Epoch 3559, Loss 30.192322, Params tensor([2.1430, 0.0930])\n",
      "Epoch 3560, Loss 30.191414, Params tensor([2.1431, 0.0930])\n",
      "Epoch 3561, Loss 30.190508, Params tensor([2.1432, 0.0929])\n",
      "Epoch 3562, Loss 30.189604, Params tensor([2.1433, 0.0929])\n",
      "Epoch 3563, Loss 30.188698, Params tensor([2.1434, 0.0929])\n",
      "Epoch 3564, Loss 30.187798, Params tensor([2.1435, 0.0929])\n",
      "Epoch 3565, Loss 30.186890, Params tensor([2.1436, 0.0929])\n",
      "Epoch 3566, Loss 30.185991, Params tensor([2.1437, 0.0929])\n",
      "Epoch 3567, Loss 30.185089, Params tensor([2.1438, 0.0929])\n",
      "Epoch 3568, Loss 30.184191, Params tensor([2.1439, 0.0928])\n",
      "Epoch 3569, Loss 30.183290, Params tensor([2.1440, 0.0928])\n",
      "Epoch 3570, Loss 30.182396, Params tensor([2.1441, 0.0928])\n",
      "Epoch 3571, Loss 30.181496, Params tensor([2.1442, 0.0928])\n",
      "Epoch 3572, Loss 30.180603, Params tensor([2.1443, 0.0928])\n",
      "Epoch 3573, Loss 30.179707, Params tensor([2.1444, 0.0928])\n",
      "Epoch 3574, Loss 30.178810, Params tensor([2.1445, 0.0928])\n",
      "Epoch 3575, Loss 30.177923, Params tensor([2.1445, 0.0927])\n",
      "Epoch 3576, Loss 30.177031, Params tensor([2.1446, 0.0927])\n",
      "Epoch 3577, Loss 30.176134, Params tensor([2.1447, 0.0927])\n",
      "Epoch 3578, Loss 30.175249, Params tensor([2.1448, 0.0927])\n",
      "Epoch 3579, Loss 30.174358, Params tensor([2.1449, 0.0927])\n",
      "Epoch 3580, Loss 30.173470, Params tensor([2.1450, 0.0927])\n",
      "Epoch 3581, Loss 30.172583, Params tensor([2.1451, 0.0927])\n",
      "Epoch 3582, Loss 30.171694, Params tensor([2.1452, 0.0926])\n",
      "Epoch 3583, Loss 30.170815, Params tensor([2.1453, 0.0926])\n",
      "Epoch 3584, Loss 30.169928, Params tensor([2.1454, 0.0926])\n",
      "Epoch 3585, Loss 30.169043, Params tensor([2.1455, 0.0926])\n",
      "Epoch 3586, Loss 30.168163, Params tensor([2.1456, 0.0926])\n",
      "Epoch 3587, Loss 30.167280, Params tensor([2.1457, 0.0926])\n",
      "Epoch 3588, Loss 30.166405, Params tensor([2.1458, 0.0926])\n",
      "Epoch 3589, Loss 30.165522, Params tensor([2.1459, 0.0925])\n",
      "Epoch 3590, Loss 30.164642, Params tensor([2.1459, 0.0925])\n",
      "Epoch 3591, Loss 30.163769, Params tensor([2.1460, 0.0925])\n",
      "Epoch 3592, Loss 30.162889, Params tensor([2.1461, 0.0925])\n",
      "Epoch 3593, Loss 30.162012, Params tensor([2.1462, 0.0925])\n",
      "Epoch 3594, Loss 30.161140, Params tensor([2.1463, 0.0925])\n",
      "Epoch 3595, Loss 30.160265, Params tensor([2.1464, 0.0925])\n",
      "Epoch 3596, Loss 30.159393, Params tensor([2.1465, 0.0924])\n",
      "Epoch 3597, Loss 30.158525, Params tensor([2.1466, 0.0924])\n",
      "Epoch 3598, Loss 30.157648, Params tensor([2.1467, 0.0924])\n",
      "Epoch 3599, Loss 30.156776, Params tensor([2.1468, 0.0924])\n",
      "Epoch 3600, Loss 30.155912, Params tensor([2.1469, 0.0924])\n",
      "Epoch 3601, Loss 30.155043, Params tensor([2.1470, 0.0924])\n",
      "Epoch 3602, Loss 30.154177, Params tensor([2.1471, 0.0924])\n",
      "Epoch 3603, Loss 30.153313, Params tensor([2.1471, 0.0923])\n",
      "Epoch 3604, Loss 30.152443, Params tensor([2.1472, 0.0923])\n",
      "Epoch 3605, Loss 30.151579, Params tensor([2.1473, 0.0923])\n",
      "Epoch 3606, Loss 30.150719, Params tensor([2.1474, 0.0923])\n",
      "Epoch 3607, Loss 30.149853, Params tensor([2.1475, 0.0923])\n",
      "Epoch 3608, Loss 30.148993, Params tensor([2.1476, 0.0923])\n",
      "Epoch 3609, Loss 30.148132, Params tensor([2.1477, 0.0923])\n",
      "Epoch 3610, Loss 30.147276, Params tensor([2.1478, 0.0922])\n",
      "Epoch 3611, Loss 30.146412, Params tensor([2.1479, 0.0922])\n",
      "Epoch 3612, Loss 30.145557, Params tensor([2.1480, 0.0922])\n",
      "Epoch 3613, Loss 30.144701, Params tensor([2.1481, 0.0922])\n",
      "Epoch 3614, Loss 30.143843, Params tensor([2.1482, 0.0922])\n",
      "Epoch 3615, Loss 30.142986, Params tensor([2.1482, 0.0922])\n",
      "Epoch 3616, Loss 30.142138, Params tensor([2.1483, 0.0922])\n",
      "Epoch 3617, Loss 30.141285, Params tensor([2.1484, 0.0921])\n",
      "Epoch 3618, Loss 30.140434, Params tensor([2.1485, 0.0921])\n",
      "Epoch 3619, Loss 30.139582, Params tensor([2.1486, 0.0921])\n",
      "Epoch 3620, Loss 30.138731, Params tensor([2.1487, 0.0921])\n",
      "Epoch 3621, Loss 30.137884, Params tensor([2.1488, 0.0921])\n",
      "Epoch 3622, Loss 30.137030, Params tensor([2.1489, 0.0921])\n",
      "Epoch 3623, Loss 30.136183, Params tensor([2.1490, 0.0921])\n",
      "Epoch 3624, Loss 30.135344, Params tensor([2.1491, 0.0920])\n",
      "Epoch 3625, Loss 30.134491, Params tensor([2.1492, 0.0920])\n",
      "Epoch 3626, Loss 30.133644, Params tensor([2.1492, 0.0920])\n",
      "Epoch 3627, Loss 30.132805, Params tensor([2.1493, 0.0920])\n",
      "Epoch 3628, Loss 30.131958, Params tensor([2.1494, 0.0920])\n",
      "Epoch 3629, Loss 30.131123, Params tensor([2.1495, 0.0920])\n",
      "Epoch 3630, Loss 30.130278, Params tensor([2.1496, 0.0920])\n",
      "Epoch 3631, Loss 30.129436, Params tensor([2.1497, 0.0919])\n",
      "Epoch 3632, Loss 30.128595, Params tensor([2.1498, 0.0919])\n",
      "Epoch 3633, Loss 30.127758, Params tensor([2.1499, 0.0919])\n",
      "Epoch 3634, Loss 30.126925, Params tensor([2.1500, 0.0919])\n",
      "Epoch 3635, Loss 30.126085, Params tensor([2.1501, 0.0919])\n",
      "Epoch 3636, Loss 30.125246, Params tensor([2.1501, 0.0919])\n",
      "Epoch 3637, Loss 30.124414, Params tensor([2.1502, 0.0919])\n",
      "Epoch 3638, Loss 30.123583, Params tensor([2.1503, 0.0918])\n",
      "Epoch 3639, Loss 30.122749, Params tensor([2.1504, 0.0918])\n",
      "Epoch 3640, Loss 30.121918, Params tensor([2.1505, 0.0918])\n",
      "Epoch 3641, Loss 30.121082, Params tensor([2.1506, 0.0918])\n",
      "Epoch 3642, Loss 30.120256, Params tensor([2.1507, 0.0918])\n",
      "Epoch 3643, Loss 30.119429, Params tensor([2.1508, 0.0918])\n",
      "Epoch 3644, Loss 30.118597, Params tensor([2.1509, 0.0918])\n",
      "Epoch 3645, Loss 30.117767, Params tensor([2.1510, 0.0917])\n",
      "Epoch 3646, Loss 30.116949, Params tensor([2.1510, 0.0917])\n",
      "Epoch 3647, Loss 30.116119, Params tensor([2.1511, 0.0917])\n",
      "Epoch 3648, Loss 30.115295, Params tensor([2.1512, 0.0917])\n",
      "Epoch 3649, Loss 30.114471, Params tensor([2.1513, 0.0917])\n",
      "Epoch 3650, Loss 30.113642, Params tensor([2.1514, 0.0917])\n",
      "Epoch 3651, Loss 30.112825, Params tensor([2.1515, 0.0916])\n",
      "Epoch 3652, Loss 30.112005, Params tensor([2.1516, 0.0916])\n",
      "Epoch 3653, Loss 30.111183, Params tensor([2.1517, 0.0916])\n",
      "Epoch 3654, Loss 30.110359, Params tensor([2.1518, 0.0916])\n",
      "Epoch 3655, Loss 30.109541, Params tensor([2.1519, 0.0916])\n",
      "Epoch 3656, Loss 30.108727, Params tensor([2.1519, 0.0916])\n",
      "Epoch 3657, Loss 30.107908, Params tensor([2.1520, 0.0916])\n",
      "Epoch 3658, Loss 30.107094, Params tensor([2.1521, 0.0915])\n",
      "Epoch 3659, Loss 30.106279, Params tensor([2.1522, 0.0915])\n",
      "Epoch 3660, Loss 30.105467, Params tensor([2.1523, 0.0915])\n",
      "Epoch 3661, Loss 30.104652, Params tensor([2.1524, 0.0915])\n",
      "Epoch 3662, Loss 30.103838, Params tensor([2.1525, 0.0915])\n",
      "Epoch 3663, Loss 30.103027, Params tensor([2.1526, 0.0915])\n",
      "Epoch 3664, Loss 30.102217, Params tensor([2.1527, 0.0915])\n",
      "Epoch 3665, Loss 30.101410, Params tensor([2.1527, 0.0914])\n",
      "Epoch 3666, Loss 30.100597, Params tensor([2.1528, 0.0914])\n",
      "Epoch 3667, Loss 30.099791, Params tensor([2.1529, 0.0914])\n",
      "Epoch 3668, Loss 30.098980, Params tensor([2.1530, 0.0914])\n",
      "Epoch 3669, Loss 30.098177, Params tensor([2.1531, 0.0914])\n",
      "Epoch 3670, Loss 30.097370, Params tensor([2.1532, 0.0914])\n",
      "Epoch 3671, Loss 30.096569, Params tensor([2.1533, 0.0914])\n",
      "Epoch 3672, Loss 30.095764, Params tensor([2.1534, 0.0913])\n",
      "Epoch 3673, Loss 30.094959, Params tensor([2.1534, 0.0913])\n",
      "Epoch 3674, Loss 30.094158, Params tensor([2.1535, 0.0913])\n",
      "Epoch 3675, Loss 30.093355, Params tensor([2.1536, 0.0913])\n",
      "Epoch 3676, Loss 30.092554, Params tensor([2.1537, 0.0913])\n",
      "Epoch 3677, Loss 30.091759, Params tensor([2.1538, 0.0913])\n",
      "Epoch 3678, Loss 30.090960, Params tensor([2.1539, 0.0912])\n",
      "Epoch 3679, Loss 30.090160, Params tensor([2.1540, 0.0912])\n",
      "Epoch 3680, Loss 30.089367, Params tensor([2.1541, 0.0912])\n",
      "Epoch 3681, Loss 30.088568, Params tensor([2.1542, 0.0912])\n",
      "Epoch 3682, Loss 30.087770, Params tensor([2.1542, 0.0912])\n",
      "Epoch 3683, Loss 30.086975, Params tensor([2.1543, 0.0912])\n",
      "Epoch 3684, Loss 30.086182, Params tensor([2.1544, 0.0912])\n",
      "Epoch 3685, Loss 30.085394, Params tensor([2.1545, 0.0911])\n",
      "Epoch 3686, Loss 30.084600, Params tensor([2.1546, 0.0911])\n",
      "Epoch 3687, Loss 30.083807, Params tensor([2.1547, 0.0911])\n",
      "Epoch 3688, Loss 30.083021, Params tensor([2.1548, 0.0911])\n",
      "Epoch 3689, Loss 30.082237, Params tensor([2.1549, 0.0911])\n",
      "Epoch 3690, Loss 30.081444, Params tensor([2.1549, 0.0911])\n",
      "Epoch 3691, Loss 30.080652, Params tensor([2.1550, 0.0911])\n",
      "Epoch 3692, Loss 30.079866, Params tensor([2.1551, 0.0910])\n",
      "Epoch 3693, Loss 30.079082, Params tensor([2.1552, 0.0910])\n",
      "Epoch 3694, Loss 30.078297, Params tensor([2.1553, 0.0910])\n",
      "Epoch 3695, Loss 30.077515, Params tensor([2.1554, 0.0910])\n",
      "Epoch 3696, Loss 30.076729, Params tensor([2.1555, 0.0910])\n",
      "Epoch 3697, Loss 30.075947, Params tensor([2.1556, 0.0910])\n",
      "Epoch 3698, Loss 30.075167, Params tensor([2.1556, 0.0909])\n",
      "Epoch 3699, Loss 30.074385, Params tensor([2.1557, 0.0909])\n",
      "Epoch 3700, Loss 30.073608, Params tensor([2.1558, 0.0909])\n",
      "Epoch 3701, Loss 30.072826, Params tensor([2.1559, 0.0909])\n",
      "Epoch 3702, Loss 30.072052, Params tensor([2.1560, 0.0909])\n",
      "Epoch 3703, Loss 30.071272, Params tensor([2.1561, 0.0909])\n",
      "Epoch 3704, Loss 30.070496, Params tensor([2.1562, 0.0909])\n",
      "Epoch 3705, Loss 30.069714, Params tensor([2.1562, 0.0908])\n",
      "Epoch 3706, Loss 30.068939, Params tensor([2.1563, 0.0908])\n",
      "Epoch 3707, Loss 30.068165, Params tensor([2.1564, 0.0908])\n",
      "Epoch 3708, Loss 30.067394, Params tensor([2.1565, 0.0908])\n",
      "Epoch 3709, Loss 30.066620, Params tensor([2.1566, 0.0908])\n",
      "Epoch 3710, Loss 30.065851, Params tensor([2.1567, 0.0908])\n",
      "Epoch 3711, Loss 30.065077, Params tensor([2.1568, 0.0907])\n",
      "Epoch 3712, Loss 30.064308, Params tensor([2.1569, 0.0907])\n",
      "Epoch 3713, Loss 30.063540, Params tensor([2.1569, 0.0907])\n",
      "Epoch 3714, Loss 30.062769, Params tensor([2.1570, 0.0907])\n",
      "Epoch 3715, Loss 30.062004, Params tensor([2.1571, 0.0907])\n",
      "Epoch 3716, Loss 30.061235, Params tensor([2.1572, 0.0907])\n",
      "Epoch 3717, Loss 30.060474, Params tensor([2.1573, 0.0907])\n",
      "Epoch 3718, Loss 30.059710, Params tensor([2.1574, 0.0906])\n",
      "Epoch 3719, Loss 30.058943, Params tensor([2.1575, 0.0906])\n",
      "Epoch 3720, Loss 30.058180, Params tensor([2.1575, 0.0906])\n",
      "Epoch 3721, Loss 30.057411, Params tensor([2.1576, 0.0906])\n",
      "Epoch 3722, Loss 30.056658, Params tensor([2.1577, 0.0906])\n",
      "Epoch 3723, Loss 30.055897, Params tensor([2.1578, 0.0906])\n",
      "Epoch 3724, Loss 30.055140, Params tensor([2.1579, 0.0906])\n",
      "Epoch 3725, Loss 30.054377, Params tensor([2.1580, 0.0905])\n",
      "Epoch 3726, Loss 30.053619, Params tensor([2.1581, 0.0905])\n",
      "Epoch 3727, Loss 30.052862, Params tensor([2.1581, 0.0905])\n",
      "Epoch 3728, Loss 30.052107, Params tensor([2.1582, 0.0905])\n",
      "Epoch 3729, Loss 30.051348, Params tensor([2.1583, 0.0905])\n",
      "Epoch 3730, Loss 30.050592, Params tensor([2.1584, 0.0905])\n",
      "Epoch 3731, Loss 30.049837, Params tensor([2.1585, 0.0904])\n",
      "Epoch 3732, Loss 30.049084, Params tensor([2.1586, 0.0904])\n",
      "Epoch 3733, Loss 30.048332, Params tensor([2.1587, 0.0904])\n",
      "Epoch 3734, Loss 30.047577, Params tensor([2.1587, 0.0904])\n",
      "Epoch 3735, Loss 30.046825, Params tensor([2.1588, 0.0904])\n",
      "Epoch 3736, Loss 30.046076, Params tensor([2.1589, 0.0904])\n",
      "Epoch 3737, Loss 30.045330, Params tensor([2.1590, 0.0903])\n",
      "Epoch 3738, Loss 30.044579, Params tensor([2.1591, 0.0903])\n",
      "Epoch 3739, Loss 30.043829, Params tensor([2.1592, 0.0903])\n",
      "Epoch 3740, Loss 30.043085, Params tensor([2.1593, 0.0903])\n",
      "Epoch 3741, Loss 30.042336, Params tensor([2.1593, 0.0903])\n",
      "Epoch 3742, Loss 30.041590, Params tensor([2.1594, 0.0903])\n",
      "Epoch 3743, Loss 30.040846, Params tensor([2.1595, 0.0903])\n",
      "Epoch 3744, Loss 30.040102, Params tensor([2.1596, 0.0902])\n",
      "Epoch 3745, Loss 30.039356, Params tensor([2.1597, 0.0902])\n",
      "Epoch 3746, Loss 30.038618, Params tensor([2.1598, 0.0902])\n",
      "Epoch 3747, Loss 30.037872, Params tensor([2.1598, 0.0902])\n",
      "Epoch 3748, Loss 30.037132, Params tensor([2.1599, 0.0902])\n",
      "Epoch 3749, Loss 30.036394, Params tensor([2.1600, 0.0902])\n",
      "Epoch 3750, Loss 30.035650, Params tensor([2.1601, 0.0901])\n",
      "Epoch 3751, Loss 30.034914, Params tensor([2.1602, 0.0901])\n",
      "Epoch 3752, Loss 30.034178, Params tensor([2.1603, 0.0901])\n",
      "Epoch 3753, Loss 30.033436, Params tensor([2.1604, 0.0901])\n",
      "Epoch 3754, Loss 30.032701, Params tensor([2.1604, 0.0901])\n",
      "Epoch 3755, Loss 30.031965, Params tensor([2.1605, 0.0901])\n",
      "Epoch 3756, Loss 30.031233, Params tensor([2.1606, 0.0901])\n",
      "Epoch 3757, Loss 30.030499, Params tensor([2.1607, 0.0900])\n",
      "Epoch 3758, Loss 30.029762, Params tensor([2.1608, 0.0900])\n",
      "Epoch 3759, Loss 30.029030, Params tensor([2.1609, 0.0900])\n",
      "Epoch 3760, Loss 30.028301, Params tensor([2.1609, 0.0900])\n",
      "Epoch 3761, Loss 30.027575, Params tensor([2.1610, 0.0900])\n",
      "Epoch 3762, Loss 30.026842, Params tensor([2.1611, 0.0900])\n",
      "Epoch 3763, Loss 30.026112, Params tensor([2.1612, 0.0899])\n",
      "Epoch 3764, Loss 30.025383, Params tensor([2.1613, 0.0899])\n",
      "Epoch 3765, Loss 30.024651, Params tensor([2.1614, 0.0899])\n",
      "Epoch 3766, Loss 30.023928, Params tensor([2.1614, 0.0899])\n",
      "Epoch 3767, Loss 30.023199, Params tensor([2.1615, 0.0899])\n",
      "Epoch 3768, Loss 30.022474, Params tensor([2.1616, 0.0899])\n",
      "Epoch 3769, Loss 30.021751, Params tensor([2.1617, 0.0899])\n",
      "Epoch 3770, Loss 30.021029, Params tensor([2.1618, 0.0898])\n",
      "Epoch 3771, Loss 30.020306, Params tensor([2.1619, 0.0898])\n",
      "Epoch 3772, Loss 30.019581, Params tensor([2.1619, 0.0898])\n",
      "Epoch 3773, Loss 30.018860, Params tensor([2.1620, 0.0898])\n",
      "Epoch 3774, Loss 30.018139, Params tensor([2.1621, 0.0898])\n",
      "Epoch 3775, Loss 30.017418, Params tensor([2.1622, 0.0898])\n",
      "Epoch 3776, Loss 30.016695, Params tensor([2.1623, 0.0897])\n",
      "Epoch 3777, Loss 30.015984, Params tensor([2.1624, 0.0897])\n",
      "Epoch 3778, Loss 30.015265, Params tensor([2.1624, 0.0897])\n",
      "Epoch 3779, Loss 30.014549, Params tensor([2.1625, 0.0897])\n",
      "Epoch 3780, Loss 30.013830, Params tensor([2.1626, 0.0897])\n",
      "Epoch 3781, Loss 30.013111, Params tensor([2.1627, 0.0897])\n",
      "Epoch 3782, Loss 30.012402, Params tensor([2.1628, 0.0896])\n",
      "Epoch 3783, Loss 30.011686, Params tensor([2.1629, 0.0896])\n",
      "Epoch 3784, Loss 30.010973, Params tensor([2.1629, 0.0896])\n",
      "Epoch 3785, Loss 30.010260, Params tensor([2.1630, 0.0896])\n",
      "Epoch 3786, Loss 30.009550, Params tensor([2.1631, 0.0896])\n",
      "Epoch 3787, Loss 30.008839, Params tensor([2.1632, 0.0896])\n",
      "Epoch 3788, Loss 30.008129, Params tensor([2.1633, 0.0895])\n",
      "Epoch 3789, Loss 30.007418, Params tensor([2.1634, 0.0895])\n",
      "Epoch 3790, Loss 30.006712, Params tensor([2.1634, 0.0895])\n",
      "Epoch 3791, Loss 30.006004, Params tensor([2.1635, 0.0895])\n",
      "Epoch 3792, Loss 30.005291, Params tensor([2.1636, 0.0895])\n",
      "Epoch 3793, Loss 30.004585, Params tensor([2.1637, 0.0895])\n",
      "Epoch 3794, Loss 30.003883, Params tensor([2.1638, 0.0895])\n",
      "Epoch 3795, Loss 30.003180, Params tensor([2.1639, 0.0894])\n",
      "Epoch 3796, Loss 30.002474, Params tensor([2.1639, 0.0894])\n",
      "Epoch 3797, Loss 30.001768, Params tensor([2.1640, 0.0894])\n",
      "Epoch 3798, Loss 30.001066, Params tensor([2.1641, 0.0894])\n",
      "Epoch 3799, Loss 30.000366, Params tensor([2.1642, 0.0894])\n",
      "Epoch 3800, Loss 29.999664, Params tensor([2.1643, 0.0894])\n",
      "Epoch 3801, Loss 29.998964, Params tensor([2.1643, 0.0893])\n",
      "Epoch 3802, Loss 29.998262, Params tensor([2.1644, 0.0893])\n",
      "Epoch 3803, Loss 29.997561, Params tensor([2.1645, 0.0893])\n",
      "Epoch 3804, Loss 29.996870, Params tensor([2.1646, 0.0893])\n",
      "Epoch 3805, Loss 29.996168, Params tensor([2.1647, 0.0893])\n",
      "Epoch 3806, Loss 29.995476, Params tensor([2.1648, 0.0893])\n",
      "Epoch 3807, Loss 29.994780, Params tensor([2.1648, 0.0892])\n",
      "Epoch 3808, Loss 29.994080, Params tensor([2.1649, 0.0892])\n",
      "Epoch 3809, Loss 29.993389, Params tensor([2.1650, 0.0892])\n",
      "Epoch 3810, Loss 29.992693, Params tensor([2.1651, 0.0892])\n",
      "Epoch 3811, Loss 29.992002, Params tensor([2.1652, 0.0892])\n",
      "Epoch 3812, Loss 29.991308, Params tensor([2.1652, 0.0892])\n",
      "Epoch 3813, Loss 29.990618, Params tensor([2.1653, 0.0891])\n",
      "Epoch 3814, Loss 29.989929, Params tensor([2.1654, 0.0891])\n",
      "Epoch 3815, Loss 29.989241, Params tensor([2.1655, 0.0891])\n",
      "Epoch 3816, Loss 29.988544, Params tensor([2.1656, 0.0891])\n",
      "Epoch 3817, Loss 29.987860, Params tensor([2.1657, 0.0891])\n",
      "Epoch 3818, Loss 29.987171, Params tensor([2.1657, 0.0891])\n",
      "Epoch 3819, Loss 29.986486, Params tensor([2.1658, 0.0891])\n",
      "Epoch 3820, Loss 29.985796, Params tensor([2.1659, 0.0890])\n",
      "Epoch 3821, Loss 29.985113, Params tensor([2.1660, 0.0890])\n",
      "Epoch 3822, Loss 29.984430, Params tensor([2.1661, 0.0890])\n",
      "Epoch 3823, Loss 29.983746, Params tensor([2.1661, 0.0890])\n",
      "Epoch 3824, Loss 29.983063, Params tensor([2.1662, 0.0890])\n",
      "Epoch 3825, Loss 29.982378, Params tensor([2.1663, 0.0890])\n",
      "Epoch 3826, Loss 29.981697, Params tensor([2.1664, 0.0889])\n",
      "Epoch 3827, Loss 29.981012, Params tensor([2.1665, 0.0889])\n",
      "Epoch 3828, Loss 29.980330, Params tensor([2.1665, 0.0889])\n",
      "Epoch 3829, Loss 29.979650, Params tensor([2.1666, 0.0889])\n",
      "Epoch 3830, Loss 29.978973, Params tensor([2.1667, 0.0889])\n",
      "Epoch 3831, Loss 29.978291, Params tensor([2.1668, 0.0889])\n",
      "Epoch 3832, Loss 29.977613, Params tensor([2.1669, 0.0888])\n",
      "Epoch 3833, Loss 29.976936, Params tensor([2.1670, 0.0888])\n",
      "Epoch 3834, Loss 29.976263, Params tensor([2.1670, 0.0888])\n",
      "Epoch 3835, Loss 29.975588, Params tensor([2.1671, 0.0888])\n",
      "Epoch 3836, Loss 29.974915, Params tensor([2.1672, 0.0888])\n",
      "Epoch 3837, Loss 29.974237, Params tensor([2.1673, 0.0888])\n",
      "Epoch 3838, Loss 29.973564, Params tensor([2.1674, 0.0887])\n",
      "Epoch 3839, Loss 29.972893, Params tensor([2.1674, 0.0887])\n",
      "Epoch 3840, Loss 29.972221, Params tensor([2.1675, 0.0887])\n",
      "Epoch 3841, Loss 29.971552, Params tensor([2.1676, 0.0887])\n",
      "Epoch 3842, Loss 29.970875, Params tensor([2.1677, 0.0887])\n",
      "Epoch 3843, Loss 29.970207, Params tensor([2.1678, 0.0887])\n",
      "Epoch 3844, Loss 29.969538, Params tensor([2.1678, 0.0886])\n",
      "Epoch 3845, Loss 29.968872, Params tensor([2.1679, 0.0886])\n",
      "Epoch 3846, Loss 29.968201, Params tensor([2.1680, 0.0886])\n",
      "Epoch 3847, Loss 29.967535, Params tensor([2.1681, 0.0886])\n",
      "Epoch 3848, Loss 29.966869, Params tensor([2.1682, 0.0886])\n",
      "Epoch 3849, Loss 29.966200, Params tensor([2.1682, 0.0886])\n",
      "Epoch 3850, Loss 29.965540, Params tensor([2.1683, 0.0885])\n",
      "Epoch 3851, Loss 29.964869, Params tensor([2.1684, 0.0885])\n",
      "Epoch 3852, Loss 29.964205, Params tensor([2.1685, 0.0885])\n",
      "Epoch 3853, Loss 29.963545, Params tensor([2.1686, 0.0885])\n",
      "Epoch 3854, Loss 29.962879, Params tensor([2.1686, 0.0885])\n",
      "Epoch 3855, Loss 29.962225, Params tensor([2.1687, 0.0885])\n",
      "Epoch 3856, Loss 29.961561, Params tensor([2.1688, 0.0884])\n",
      "Epoch 3857, Loss 29.960901, Params tensor([2.1689, 0.0884])\n",
      "Epoch 3858, Loss 29.960241, Params tensor([2.1690, 0.0884])\n",
      "Epoch 3859, Loss 29.959583, Params tensor([2.1690, 0.0884])\n",
      "Epoch 3860, Loss 29.958925, Params tensor([2.1691, 0.0884])\n",
      "Epoch 3861, Loss 29.958269, Params tensor([2.1692, 0.0884])\n",
      "Epoch 3862, Loss 29.957609, Params tensor([2.1693, 0.0884])\n",
      "Epoch 3863, Loss 29.956953, Params tensor([2.1693, 0.0883])\n",
      "Epoch 3864, Loss 29.956299, Params tensor([2.1694, 0.0883])\n",
      "Epoch 3865, Loss 29.955645, Params tensor([2.1695, 0.0883])\n",
      "Epoch 3866, Loss 29.954994, Params tensor([2.1696, 0.0883])\n",
      "Epoch 3867, Loss 29.954340, Params tensor([2.1697, 0.0883])\n",
      "Epoch 3868, Loss 29.953682, Params tensor([2.1697, 0.0883])\n",
      "Epoch 3869, Loss 29.953032, Params tensor([2.1698, 0.0882])\n",
      "Epoch 3870, Loss 29.952381, Params tensor([2.1699, 0.0882])\n",
      "Epoch 3871, Loss 29.951727, Params tensor([2.1700, 0.0882])\n",
      "Epoch 3872, Loss 29.951078, Params tensor([2.1701, 0.0882])\n",
      "Epoch 3873, Loss 29.950432, Params tensor([2.1701, 0.0882])\n",
      "Epoch 3874, Loss 29.949780, Params tensor([2.1702, 0.0882])\n",
      "Epoch 3875, Loss 29.949135, Params tensor([2.1703, 0.0881])\n",
      "Epoch 3876, Loss 29.948488, Params tensor([2.1704, 0.0881])\n",
      "Epoch 3877, Loss 29.947838, Params tensor([2.1705, 0.0881])\n",
      "Epoch 3878, Loss 29.947193, Params tensor([2.1705, 0.0881])\n",
      "Epoch 3879, Loss 29.946550, Params tensor([2.1706, 0.0881])\n",
      "Epoch 3880, Loss 29.945910, Params tensor([2.1707, 0.0881])\n",
      "Epoch 3881, Loss 29.945263, Params tensor([2.1708, 0.0880])\n",
      "Epoch 3882, Loss 29.944618, Params tensor([2.1708, 0.0880])\n",
      "Epoch 3883, Loss 29.943975, Params tensor([2.1709, 0.0880])\n",
      "Epoch 3884, Loss 29.943329, Params tensor([2.1710, 0.0880])\n",
      "Epoch 3885, Loss 29.942688, Params tensor([2.1711, 0.0880])\n",
      "Epoch 3886, Loss 29.942049, Params tensor([2.1712, 0.0880])\n",
      "Epoch 3887, Loss 29.941414, Params tensor([2.1712, 0.0879])\n",
      "Epoch 3888, Loss 29.940773, Params tensor([2.1713, 0.0879])\n",
      "Epoch 3889, Loss 29.940132, Params tensor([2.1714, 0.0879])\n",
      "Epoch 3890, Loss 29.939495, Params tensor([2.1715, 0.0879])\n",
      "Epoch 3891, Loss 29.938862, Params tensor([2.1716, 0.0879])\n",
      "Epoch 3892, Loss 29.938221, Params tensor([2.1716, 0.0879])\n",
      "Epoch 3893, Loss 29.937584, Params tensor([2.1717, 0.0878])\n",
      "Epoch 3894, Loss 29.936953, Params tensor([2.1718, 0.0878])\n",
      "Epoch 3895, Loss 29.936317, Params tensor([2.1719, 0.0878])\n",
      "Epoch 3896, Loss 29.935686, Params tensor([2.1719, 0.0878])\n",
      "Epoch 3897, Loss 29.935045, Params tensor([2.1720, 0.0878])\n",
      "Epoch 3898, Loss 29.934412, Params tensor([2.1721, 0.0878])\n",
      "Epoch 3899, Loss 29.933783, Params tensor([2.1722, 0.0877])\n",
      "Epoch 3900, Loss 29.933155, Params tensor([2.1723, 0.0877])\n",
      "Epoch 3901, Loss 29.932524, Params tensor([2.1723, 0.0877])\n",
      "Epoch 3902, Loss 29.931890, Params tensor([2.1724, 0.0877])\n",
      "Epoch 3903, Loss 29.931261, Params tensor([2.1725, 0.0877])\n",
      "Epoch 3904, Loss 29.930635, Params tensor([2.1726, 0.0877])\n",
      "Epoch 3905, Loss 29.930006, Params tensor([2.1726, 0.0876])\n",
      "Epoch 3906, Loss 29.929380, Params tensor([2.1727, 0.0876])\n",
      "Epoch 3907, Loss 29.928753, Params tensor([2.1728, 0.0876])\n",
      "Epoch 3908, Loss 29.928125, Params tensor([2.1729, 0.0876])\n",
      "Epoch 3909, Loss 29.927502, Params tensor([2.1729, 0.0876])\n",
      "Epoch 3910, Loss 29.926878, Params tensor([2.1730, 0.0875])\n",
      "Epoch 3911, Loss 29.926252, Params tensor([2.1731, 0.0875])\n",
      "Epoch 3912, Loss 29.925631, Params tensor([2.1732, 0.0875])\n",
      "Epoch 3913, Loss 29.925011, Params tensor([2.1733, 0.0875])\n",
      "Epoch 3914, Loss 29.924383, Params tensor([2.1733, 0.0875])\n",
      "Epoch 3915, Loss 29.923761, Params tensor([2.1734, 0.0875])\n",
      "Epoch 3916, Loss 29.923145, Params tensor([2.1735, 0.0874])\n",
      "Epoch 3917, Loss 29.922522, Params tensor([2.1736, 0.0874])\n",
      "Epoch 3918, Loss 29.921904, Params tensor([2.1736, 0.0874])\n",
      "Epoch 3919, Loss 29.921288, Params tensor([2.1737, 0.0874])\n",
      "Epoch 3920, Loss 29.920668, Params tensor([2.1738, 0.0874])\n",
      "Epoch 3921, Loss 29.920044, Params tensor([2.1739, 0.0874])\n",
      "Epoch 3922, Loss 29.919428, Params tensor([2.1739, 0.0873])\n",
      "Epoch 3923, Loss 29.918812, Params tensor([2.1740, 0.0873])\n",
      "Epoch 3924, Loss 29.918200, Params tensor([2.1741, 0.0873])\n",
      "Epoch 3925, Loss 29.917583, Params tensor([2.1742, 0.0873])\n",
      "Epoch 3926, Loss 29.916969, Params tensor([2.1743, 0.0873])\n",
      "Epoch 3927, Loss 29.916357, Params tensor([2.1743, 0.0873])\n",
      "Epoch 3928, Loss 29.915743, Params tensor([2.1744, 0.0872])\n",
      "Epoch 3929, Loss 29.915131, Params tensor([2.1745, 0.0872])\n",
      "Epoch 3930, Loss 29.914520, Params tensor([2.1746, 0.0872])\n",
      "Epoch 3931, Loss 29.913908, Params tensor([2.1746, 0.0872])\n",
      "Epoch 3932, Loss 29.913294, Params tensor([2.1747, 0.0872])\n",
      "Epoch 3933, Loss 29.912683, Params tensor([2.1748, 0.0872])\n",
      "Epoch 3934, Loss 29.912077, Params tensor([2.1749, 0.0871])\n",
      "Epoch 3935, Loss 29.911467, Params tensor([2.1749, 0.0871])\n",
      "Epoch 3936, Loss 29.910856, Params tensor([2.1750, 0.0871])\n",
      "Epoch 3937, Loss 29.910254, Params tensor([2.1751, 0.0871])\n",
      "Epoch 3938, Loss 29.909639, Params tensor([2.1752, 0.0871])\n",
      "Epoch 3939, Loss 29.909039, Params tensor([2.1752, 0.0871])\n",
      "Epoch 3940, Loss 29.908434, Params tensor([2.1753, 0.0870])\n",
      "Epoch 3941, Loss 29.907831, Params tensor([2.1754, 0.0870])\n",
      "Epoch 3942, Loss 29.907227, Params tensor([2.1755, 0.0870])\n",
      "Epoch 3943, Loss 29.906622, Params tensor([2.1755, 0.0870])\n",
      "Epoch 3944, Loss 29.906017, Params tensor([2.1756, 0.0870])\n",
      "Epoch 3945, Loss 29.905413, Params tensor([2.1757, 0.0870])\n",
      "Epoch 3946, Loss 29.904816, Params tensor([2.1758, 0.0869])\n",
      "Epoch 3947, Loss 29.904207, Params tensor([2.1758, 0.0869])\n",
      "Epoch 3948, Loss 29.903612, Params tensor([2.1759, 0.0869])\n",
      "Epoch 3949, Loss 29.903009, Params tensor([2.1760, 0.0869])\n",
      "Epoch 3950, Loss 29.902412, Params tensor([2.1761, 0.0869])\n",
      "Epoch 3951, Loss 29.901814, Params tensor([2.1762, 0.0869])\n",
      "Epoch 3952, Loss 29.901217, Params tensor([2.1762, 0.0868])\n",
      "Epoch 3953, Loss 29.900616, Params tensor([2.1763, 0.0868])\n",
      "Epoch 3954, Loss 29.900023, Params tensor([2.1764, 0.0868])\n",
      "Epoch 3955, Loss 29.899420, Params tensor([2.1765, 0.0868])\n",
      "Epoch 3956, Loss 29.898829, Params tensor([2.1765, 0.0868])\n",
      "Epoch 3957, Loss 29.898232, Params tensor([2.1766, 0.0867])\n",
      "Epoch 3958, Loss 29.897642, Params tensor([2.1767, 0.0867])\n",
      "Epoch 3959, Loss 29.897045, Params tensor([2.1768, 0.0867])\n",
      "Epoch 3960, Loss 29.896454, Params tensor([2.1768, 0.0867])\n",
      "Epoch 3961, Loss 29.895855, Params tensor([2.1769, 0.0867])\n",
      "Epoch 3962, Loss 29.895264, Params tensor([2.1770, 0.0867])\n",
      "Epoch 3963, Loss 29.894672, Params tensor([2.1771, 0.0866])\n",
      "Epoch 3964, Loss 29.894081, Params tensor([2.1771, 0.0866])\n",
      "Epoch 3965, Loss 29.893494, Params tensor([2.1772, 0.0866])\n",
      "Epoch 3966, Loss 29.892900, Params tensor([2.1773, 0.0866])\n",
      "Epoch 3967, Loss 29.892311, Params tensor([2.1774, 0.0866])\n",
      "Epoch 3968, Loss 29.891729, Params tensor([2.1774, 0.0866])\n",
      "Epoch 3969, Loss 29.891142, Params tensor([2.1775, 0.0865])\n",
      "Epoch 3970, Loss 29.890553, Params tensor([2.1776, 0.0865])\n",
      "Epoch 3971, Loss 29.889971, Params tensor([2.1777, 0.0865])\n",
      "Epoch 3972, Loss 29.889380, Params tensor([2.1777, 0.0865])\n",
      "Epoch 3973, Loss 29.888794, Params tensor([2.1778, 0.0865])\n",
      "Epoch 3974, Loss 29.888208, Params tensor([2.1779, 0.0865])\n",
      "Epoch 3975, Loss 29.887623, Params tensor([2.1779, 0.0864])\n",
      "Epoch 3976, Loss 29.887041, Params tensor([2.1780, 0.0864])\n",
      "Epoch 3977, Loss 29.886456, Params tensor([2.1781, 0.0864])\n",
      "Epoch 3978, Loss 29.885876, Params tensor([2.1782, 0.0864])\n",
      "Epoch 3979, Loss 29.885292, Params tensor([2.1782, 0.0864])\n",
      "Epoch 3980, Loss 29.884716, Params tensor([2.1783, 0.0863])\n",
      "Epoch 3981, Loss 29.884132, Params tensor([2.1784, 0.0863])\n",
      "Epoch 3982, Loss 29.883551, Params tensor([2.1785, 0.0863])\n",
      "Epoch 3983, Loss 29.882977, Params tensor([2.1785, 0.0863])\n",
      "Epoch 3984, Loss 29.882393, Params tensor([2.1786, 0.0863])\n",
      "Epoch 3985, Loss 29.881817, Params tensor([2.1787, 0.0863])\n",
      "Epoch 3986, Loss 29.881237, Params tensor([2.1788, 0.0862])\n",
      "Epoch 3987, Loss 29.880663, Params tensor([2.1788, 0.0862])\n",
      "Epoch 3988, Loss 29.880089, Params tensor([2.1789, 0.0862])\n",
      "Epoch 3989, Loss 29.879511, Params tensor([2.1790, 0.0862])\n",
      "Epoch 3990, Loss 29.878935, Params tensor([2.1791, 0.0862])\n",
      "Epoch 3991, Loss 29.878359, Params tensor([2.1791, 0.0862])\n",
      "Epoch 3992, Loss 29.877789, Params tensor([2.1792, 0.0861])\n",
      "Epoch 3993, Loss 29.877211, Params tensor([2.1793, 0.0861])\n",
      "Epoch 3994, Loss 29.876640, Params tensor([2.1794, 0.0861])\n",
      "Epoch 3995, Loss 29.876070, Params tensor([2.1794, 0.0861])\n",
      "Epoch 3996, Loss 29.875494, Params tensor([2.1795, 0.0861])\n",
      "Epoch 3997, Loss 29.874926, Params tensor([2.1796, 0.0861])\n",
      "Epoch 3998, Loss 29.874353, Params tensor([2.1796, 0.0860])\n",
      "Epoch 3999, Loss 29.873785, Params tensor([2.1797, 0.0860])\n",
      "Epoch 4000, Loss 29.873217, Params tensor([2.1798, 0.0860])\n",
      "Epoch 4001, Loss 29.872644, Params tensor([2.1799, 0.0860])\n",
      "Epoch 4002, Loss 29.872072, Params tensor([2.1799, 0.0860])\n",
      "Epoch 4003, Loss 29.871508, Params tensor([2.1800, 0.0859])\n",
      "Epoch 4004, Loss 29.870943, Params tensor([2.1801, 0.0859])\n",
      "Epoch 4005, Loss 29.870378, Params tensor([2.1802, 0.0859])\n",
      "Epoch 4006, Loss 29.869810, Params tensor([2.1802, 0.0859])\n",
      "Epoch 4007, Loss 29.869240, Params tensor([2.1803, 0.0859])\n",
      "Epoch 4008, Loss 29.868677, Params tensor([2.1804, 0.0859])\n",
      "Epoch 4009, Loss 29.868114, Params tensor([2.1805, 0.0858])\n",
      "Epoch 4010, Loss 29.867554, Params tensor([2.1805, 0.0858])\n",
      "Epoch 4011, Loss 29.866987, Params tensor([2.1806, 0.0858])\n",
      "Epoch 4012, Loss 29.866425, Params tensor([2.1807, 0.0858])\n",
      "Epoch 4013, Loss 29.865862, Params tensor([2.1807, 0.0858])\n",
      "Epoch 4014, Loss 29.865301, Params tensor([2.1808, 0.0858])\n",
      "Epoch 4015, Loss 29.864744, Params tensor([2.1809, 0.0857])\n",
      "Epoch 4016, Loss 29.864180, Params tensor([2.1810, 0.0857])\n",
      "Epoch 4017, Loss 29.863623, Params tensor([2.1810, 0.0857])\n",
      "Epoch 4018, Loss 29.863060, Params tensor([2.1811, 0.0857])\n",
      "Epoch 4019, Loss 29.862505, Params tensor([2.1812, 0.0857])\n",
      "Epoch 4020, Loss 29.861946, Params tensor([2.1813, 0.0856])\n",
      "Epoch 4021, Loss 29.861389, Params tensor([2.1813, 0.0856])\n",
      "Epoch 4022, Loss 29.860834, Params tensor([2.1814, 0.0856])\n",
      "Epoch 4023, Loss 29.860277, Params tensor([2.1815, 0.0856])\n",
      "Epoch 4024, Loss 29.859722, Params tensor([2.1815, 0.0856])\n",
      "Epoch 4025, Loss 29.859167, Params tensor([2.1816, 0.0856])\n",
      "Epoch 4026, Loss 29.858612, Params tensor([2.1817, 0.0855])\n",
      "Epoch 4027, Loss 29.858057, Params tensor([2.1818, 0.0855])\n",
      "Epoch 4028, Loss 29.857506, Params tensor([2.1818, 0.0855])\n",
      "Epoch 4029, Loss 29.856953, Params tensor([2.1819, 0.0855])\n",
      "Epoch 4030, Loss 29.856401, Params tensor([2.1820, 0.0855])\n",
      "Epoch 4031, Loss 29.855848, Params tensor([2.1820, 0.0855])\n",
      "Epoch 4032, Loss 29.855293, Params tensor([2.1821, 0.0854])\n",
      "Epoch 4033, Loss 29.854744, Params tensor([2.1822, 0.0854])\n",
      "Epoch 4034, Loss 29.854200, Params tensor([2.1823, 0.0854])\n",
      "Epoch 4035, Loss 29.853645, Params tensor([2.1823, 0.0854])\n",
      "Epoch 4036, Loss 29.853094, Params tensor([2.1824, 0.0854])\n",
      "Epoch 4037, Loss 29.852551, Params tensor([2.1825, 0.0853])\n",
      "Epoch 4038, Loss 29.852001, Params tensor([2.1826, 0.0853])\n",
      "Epoch 4039, Loss 29.851452, Params tensor([2.1826, 0.0853])\n",
      "Epoch 4040, Loss 29.850908, Params tensor([2.1827, 0.0853])\n",
      "Epoch 4041, Loss 29.850365, Params tensor([2.1828, 0.0853])\n",
      "Epoch 4042, Loss 29.849815, Params tensor([2.1828, 0.0853])\n",
      "Epoch 4043, Loss 29.849272, Params tensor([2.1829, 0.0852])\n",
      "Epoch 4044, Loss 29.848724, Params tensor([2.1830, 0.0852])\n",
      "Epoch 4045, Loss 29.848181, Params tensor([2.1831, 0.0852])\n",
      "Epoch 4046, Loss 29.847637, Params tensor([2.1831, 0.0852])\n",
      "Epoch 4047, Loss 29.847095, Params tensor([2.1832, 0.0852])\n",
      "Epoch 4048, Loss 29.846552, Params tensor([2.1833, 0.0852])\n",
      "Epoch 4049, Loss 29.846010, Params tensor([2.1833, 0.0851])\n",
      "Epoch 4050, Loss 29.845470, Params tensor([2.1834, 0.0851])\n",
      "Epoch 4051, Loss 29.844929, Params tensor([2.1835, 0.0851])\n",
      "Epoch 4052, Loss 29.844389, Params tensor([2.1836, 0.0851])\n",
      "Epoch 4053, Loss 29.843847, Params tensor([2.1836, 0.0851])\n",
      "Epoch 4054, Loss 29.843309, Params tensor([2.1837, 0.0850])\n",
      "Epoch 4055, Loss 29.842772, Params tensor([2.1838, 0.0850])\n",
      "Epoch 4056, Loss 29.842236, Params tensor([2.1838, 0.0850])\n",
      "Epoch 4057, Loss 29.841698, Params tensor([2.1839, 0.0850])\n",
      "Epoch 4058, Loss 29.841162, Params tensor([2.1840, 0.0850])\n",
      "Epoch 4059, Loss 29.840626, Params tensor([2.1841, 0.0850])\n",
      "Epoch 4060, Loss 29.840088, Params tensor([2.1841, 0.0849])\n",
      "Epoch 4061, Loss 29.839556, Params tensor([2.1842, 0.0849])\n",
      "Epoch 4062, Loss 29.839018, Params tensor([2.1843, 0.0849])\n",
      "Epoch 4063, Loss 29.838484, Params tensor([2.1843, 0.0849])\n",
      "Epoch 4064, Loss 29.837950, Params tensor([2.1844, 0.0849])\n",
      "Epoch 4065, Loss 29.837416, Params tensor([2.1845, 0.0848])\n",
      "Epoch 4066, Loss 29.836884, Params tensor([2.1845, 0.0848])\n",
      "Epoch 4067, Loss 29.836351, Params tensor([2.1846, 0.0848])\n",
      "Epoch 4068, Loss 29.835821, Params tensor([2.1847, 0.0848])\n",
      "Epoch 4069, Loss 29.835295, Params tensor([2.1848, 0.0848])\n",
      "Epoch 4070, Loss 29.834764, Params tensor([2.1848, 0.0848])\n",
      "Epoch 4071, Loss 29.834229, Params tensor([2.1849, 0.0847])\n",
      "Epoch 4072, Loss 29.833696, Params tensor([2.1850, 0.0847])\n",
      "Epoch 4073, Loss 29.833174, Params tensor([2.1850, 0.0847])\n",
      "Epoch 4074, Loss 29.832642, Params tensor([2.1851, 0.0847])\n",
      "Epoch 4075, Loss 29.832117, Params tensor([2.1852, 0.0847])\n",
      "Epoch 4076, Loss 29.831591, Params tensor([2.1853, 0.0846])\n",
      "Epoch 4077, Loss 29.831062, Params tensor([2.1853, 0.0846])\n",
      "Epoch 4078, Loss 29.830536, Params tensor([2.1854, 0.0846])\n",
      "Epoch 4079, Loss 29.830011, Params tensor([2.1855, 0.0846])\n",
      "Epoch 4080, Loss 29.829485, Params tensor([2.1855, 0.0846])\n",
      "Epoch 4081, Loss 29.828966, Params tensor([2.1856, 0.0846])\n",
      "Epoch 4082, Loss 29.828436, Params tensor([2.1857, 0.0845])\n",
      "Epoch 4083, Loss 29.827913, Params tensor([2.1857, 0.0845])\n",
      "Epoch 4084, Loss 29.827391, Params tensor([2.1858, 0.0845])\n",
      "Epoch 4085, Loss 29.826866, Params tensor([2.1859, 0.0845])\n",
      "Epoch 4086, Loss 29.826344, Params tensor([2.1860, 0.0845])\n",
      "Epoch 4087, Loss 29.825825, Params tensor([2.1860, 0.0844])\n",
      "Epoch 4088, Loss 29.825300, Params tensor([2.1861, 0.0844])\n",
      "Epoch 4089, Loss 29.824785, Params tensor([2.1862, 0.0844])\n",
      "Epoch 4090, Loss 29.824263, Params tensor([2.1862, 0.0844])\n",
      "Epoch 4091, Loss 29.823748, Params tensor([2.1863, 0.0844])\n",
      "Epoch 4092, Loss 29.823225, Params tensor([2.1864, 0.0844])\n",
      "Epoch 4093, Loss 29.822706, Params tensor([2.1864, 0.0843])\n",
      "Epoch 4094, Loss 29.822191, Params tensor([2.1865, 0.0843])\n",
      "Epoch 4095, Loss 29.821672, Params tensor([2.1866, 0.0843])\n",
      "Epoch 4096, Loss 29.821159, Params tensor([2.1866, 0.0843])\n",
      "Epoch 4097, Loss 29.820637, Params tensor([2.1867, 0.0843])\n",
      "Epoch 4098, Loss 29.820124, Params tensor([2.1868, 0.0842])\n",
      "Epoch 4099, Loss 29.819609, Params tensor([2.1869, 0.0842])\n",
      "Epoch 4100, Loss 29.819092, Params tensor([2.1869, 0.0842])\n",
      "Epoch 4101, Loss 29.818575, Params tensor([2.1870, 0.0842])\n",
      "Epoch 4102, Loss 29.818062, Params tensor([2.1871, 0.0842])\n",
      "Epoch 4103, Loss 29.817553, Params tensor([2.1871, 0.0842])\n",
      "Epoch 4104, Loss 29.817039, Params tensor([2.1872, 0.0841])\n",
      "Epoch 4105, Loss 29.816528, Params tensor([2.1873, 0.0841])\n",
      "Epoch 4106, Loss 29.816015, Params tensor([2.1873, 0.0841])\n",
      "Epoch 4107, Loss 29.815508, Params tensor([2.1874, 0.0841])\n",
      "Epoch 4108, Loss 29.814995, Params tensor([2.1875, 0.0841])\n",
      "Epoch 4109, Loss 29.814482, Params tensor([2.1875, 0.0840])\n",
      "Epoch 4110, Loss 29.813976, Params tensor([2.1876, 0.0840])\n",
      "Epoch 4111, Loss 29.813463, Params tensor([2.1877, 0.0840])\n",
      "Epoch 4112, Loss 29.812960, Params tensor([2.1878, 0.0840])\n",
      "Epoch 4113, Loss 29.812447, Params tensor([2.1878, 0.0840])\n",
      "Epoch 4114, Loss 29.811945, Params tensor([2.1879, 0.0840])\n",
      "Epoch 4115, Loss 29.811434, Params tensor([2.1880, 0.0839])\n",
      "Epoch 4116, Loss 29.810925, Params tensor([2.1880, 0.0839])\n",
      "Epoch 4117, Loss 29.810419, Params tensor([2.1881, 0.0839])\n",
      "Epoch 4118, Loss 29.809919, Params tensor([2.1882, 0.0839])\n",
      "Epoch 4119, Loss 29.809412, Params tensor([2.1882, 0.0839])\n",
      "Epoch 4120, Loss 29.808907, Params tensor([2.1883, 0.0838])\n",
      "Epoch 4121, Loss 29.808399, Params tensor([2.1884, 0.0838])\n",
      "Epoch 4122, Loss 29.807899, Params tensor([2.1884, 0.0838])\n",
      "Epoch 4123, Loss 29.807396, Params tensor([2.1885, 0.0838])\n",
      "Epoch 4124, Loss 29.806892, Params tensor([2.1886, 0.0838])\n",
      "Epoch 4125, Loss 29.806395, Params tensor([2.1886, 0.0838])\n",
      "Epoch 4126, Loss 29.805891, Params tensor([2.1887, 0.0837])\n",
      "Epoch 4127, Loss 29.805391, Params tensor([2.1888, 0.0837])\n",
      "Epoch 4128, Loss 29.804888, Params tensor([2.1889, 0.0837])\n",
      "Epoch 4129, Loss 29.804388, Params tensor([2.1889, 0.0837])\n",
      "Epoch 4130, Loss 29.803892, Params tensor([2.1890, 0.0837])\n",
      "Epoch 4131, Loss 29.803392, Params tensor([2.1891, 0.0836])\n",
      "Epoch 4132, Loss 29.802893, Params tensor([2.1891, 0.0836])\n",
      "Epoch 4133, Loss 29.802397, Params tensor([2.1892, 0.0836])\n",
      "Epoch 4134, Loss 29.801897, Params tensor([2.1893, 0.0836])\n",
      "Epoch 4135, Loss 29.801403, Params tensor([2.1893, 0.0836])\n",
      "Epoch 4136, Loss 29.800903, Params tensor([2.1894, 0.0835])\n",
      "Epoch 4137, Loss 29.800409, Params tensor([2.1895, 0.0835])\n",
      "Epoch 4138, Loss 29.799913, Params tensor([2.1895, 0.0835])\n",
      "Epoch 4139, Loss 29.799416, Params tensor([2.1896, 0.0835])\n",
      "Epoch 4140, Loss 29.798920, Params tensor([2.1897, 0.0835])\n",
      "Epoch 4141, Loss 29.798429, Params tensor([2.1897, 0.0835])\n",
      "Epoch 4142, Loss 29.797935, Params tensor([2.1898, 0.0834])\n",
      "Epoch 4143, Loss 29.797447, Params tensor([2.1899, 0.0834])\n",
      "Epoch 4144, Loss 29.796949, Params tensor([2.1899, 0.0834])\n",
      "Epoch 4145, Loss 29.796459, Params tensor([2.1900, 0.0834])\n",
      "Epoch 4146, Loss 29.795965, Params tensor([2.1901, 0.0834])\n",
      "Epoch 4147, Loss 29.795477, Params tensor([2.1901, 0.0833])\n",
      "Epoch 4148, Loss 29.794983, Params tensor([2.1902, 0.0833])\n",
      "Epoch 4149, Loss 29.794495, Params tensor([2.1903, 0.0833])\n",
      "Epoch 4150, Loss 29.794001, Params tensor([2.1903, 0.0833])\n",
      "Epoch 4151, Loss 29.793516, Params tensor([2.1904, 0.0833])\n",
      "Epoch 4152, Loss 29.793024, Params tensor([2.1905, 0.0833])\n",
      "Epoch 4153, Loss 29.792540, Params tensor([2.1905, 0.0832])\n",
      "Epoch 4154, Loss 29.792051, Params tensor([2.1906, 0.0832])\n",
      "Epoch 4155, Loss 29.791563, Params tensor([2.1907, 0.0832])\n",
      "Epoch 4156, Loss 29.791077, Params tensor([2.1907, 0.0832])\n",
      "Epoch 4157, Loss 29.790594, Params tensor([2.1908, 0.0832])\n",
      "Epoch 4158, Loss 29.790102, Params tensor([2.1909, 0.0831])\n",
      "Epoch 4159, Loss 29.789618, Params tensor([2.1910, 0.0831])\n",
      "Epoch 4160, Loss 29.789131, Params tensor([2.1910, 0.0831])\n",
      "Epoch 4161, Loss 29.788652, Params tensor([2.1911, 0.0831])\n",
      "Epoch 4162, Loss 29.788170, Params tensor([2.1912, 0.0831])\n",
      "Epoch 4163, Loss 29.787678, Params tensor([2.1912, 0.0830])\n",
      "Epoch 4164, Loss 29.787201, Params tensor([2.1913, 0.0830])\n",
      "Epoch 4165, Loss 29.786715, Params tensor([2.1914, 0.0830])\n",
      "Epoch 4166, Loss 29.786236, Params tensor([2.1914, 0.0830])\n",
      "Epoch 4167, Loss 29.785753, Params tensor([2.1915, 0.0830])\n",
      "Epoch 4168, Loss 29.785271, Params tensor([2.1916, 0.0830])\n",
      "Epoch 4169, Loss 29.784792, Params tensor([2.1916, 0.0829])\n",
      "Epoch 4170, Loss 29.784313, Params tensor([2.1917, 0.0829])\n",
      "Epoch 4171, Loss 29.783831, Params tensor([2.1918, 0.0829])\n",
      "Epoch 4172, Loss 29.783354, Params tensor([2.1918, 0.0829])\n",
      "Epoch 4173, Loss 29.782875, Params tensor([2.1919, 0.0829])\n",
      "Epoch 4174, Loss 29.782396, Params tensor([2.1920, 0.0828])\n",
      "Epoch 4175, Loss 29.781923, Params tensor([2.1920, 0.0828])\n",
      "Epoch 4176, Loss 29.781445, Params tensor([2.1921, 0.0828])\n",
      "Epoch 4177, Loss 29.780968, Params tensor([2.1922, 0.0828])\n",
      "Epoch 4178, Loss 29.780487, Params tensor([2.1922, 0.0828])\n",
      "Epoch 4179, Loss 29.780012, Params tensor([2.1923, 0.0827])\n",
      "Epoch 4180, Loss 29.779539, Params tensor([2.1924, 0.0827])\n",
      "Epoch 4181, Loss 29.779064, Params tensor([2.1924, 0.0827])\n",
      "Epoch 4182, Loss 29.778589, Params tensor([2.1925, 0.0827])\n",
      "Epoch 4183, Loss 29.778114, Params tensor([2.1925, 0.0827])\n",
      "Epoch 4184, Loss 29.777643, Params tensor([2.1926, 0.0827])\n",
      "Epoch 4185, Loss 29.777168, Params tensor([2.1927, 0.0826])\n",
      "Epoch 4186, Loss 29.776695, Params tensor([2.1927, 0.0826])\n",
      "Epoch 4187, Loss 29.776222, Params tensor([2.1928, 0.0826])\n",
      "Epoch 4188, Loss 29.775751, Params tensor([2.1929, 0.0826])\n",
      "Epoch 4189, Loss 29.775282, Params tensor([2.1929, 0.0826])\n",
      "Epoch 4190, Loss 29.774813, Params tensor([2.1930, 0.0825])\n",
      "Epoch 4191, Loss 29.774342, Params tensor([2.1931, 0.0825])\n",
      "Epoch 4192, Loss 29.773870, Params tensor([2.1931, 0.0825])\n",
      "Epoch 4193, Loss 29.773399, Params tensor([2.1932, 0.0825])\n",
      "Epoch 4194, Loss 29.772930, Params tensor([2.1933, 0.0825])\n",
      "Epoch 4195, Loss 29.772463, Params tensor([2.1933, 0.0824])\n",
      "Epoch 4196, Loss 29.771996, Params tensor([2.1934, 0.0824])\n",
      "Epoch 4197, Loss 29.771532, Params tensor([2.1935, 0.0824])\n",
      "Epoch 4198, Loss 29.771063, Params tensor([2.1935, 0.0824])\n",
      "Epoch 4199, Loss 29.770594, Params tensor([2.1936, 0.0824])\n",
      "Epoch 4200, Loss 29.770124, Params tensor([2.1937, 0.0824])\n",
      "Epoch 4201, Loss 29.769665, Params tensor([2.1937, 0.0823])\n",
      "Epoch 4202, Loss 29.769196, Params tensor([2.1938, 0.0823])\n",
      "Epoch 4203, Loss 29.768730, Params tensor([2.1939, 0.0823])\n",
      "Epoch 4204, Loss 29.768267, Params tensor([2.1939, 0.0823])\n",
      "Epoch 4205, Loss 29.767799, Params tensor([2.1940, 0.0823])\n",
      "Epoch 4206, Loss 29.767340, Params tensor([2.1941, 0.0822])\n",
      "Epoch 4207, Loss 29.766874, Params tensor([2.1941, 0.0822])\n",
      "Epoch 4208, Loss 29.766417, Params tensor([2.1942, 0.0822])\n",
      "Epoch 4209, Loss 29.765947, Params tensor([2.1943, 0.0822])\n",
      "Epoch 4210, Loss 29.765491, Params tensor([2.1943, 0.0822])\n",
      "Epoch 4211, Loss 29.765026, Params tensor([2.1944, 0.0821])\n",
      "Epoch 4212, Loss 29.764570, Params tensor([2.1945, 0.0821])\n",
      "Epoch 4213, Loss 29.764111, Params tensor([2.1945, 0.0821])\n",
      "Epoch 4214, Loss 29.763653, Params tensor([2.1946, 0.0821])\n",
      "Epoch 4215, Loss 29.763189, Params tensor([2.1946, 0.0821])\n",
      "Epoch 4216, Loss 29.762733, Params tensor([2.1947, 0.0820])\n",
      "Epoch 4217, Loss 29.762274, Params tensor([2.1948, 0.0820])\n",
      "Epoch 4218, Loss 29.761818, Params tensor([2.1948, 0.0820])\n",
      "Epoch 4219, Loss 29.761360, Params tensor([2.1949, 0.0820])\n",
      "Epoch 4220, Loss 29.760900, Params tensor([2.1950, 0.0820])\n",
      "Epoch 4221, Loss 29.760443, Params tensor([2.1950, 0.0820])\n",
      "Epoch 4222, Loss 29.759985, Params tensor([2.1951, 0.0819])\n",
      "Epoch 4223, Loss 29.759533, Params tensor([2.1952, 0.0819])\n",
      "Epoch 4224, Loss 29.759071, Params tensor([2.1952, 0.0819])\n",
      "Epoch 4225, Loss 29.758619, Params tensor([2.1953, 0.0819])\n",
      "Epoch 4226, Loss 29.758162, Params tensor([2.1954, 0.0819])\n",
      "Epoch 4227, Loss 29.757713, Params tensor([2.1954, 0.0818])\n",
      "Epoch 4228, Loss 29.757261, Params tensor([2.1955, 0.0818])\n",
      "Epoch 4229, Loss 29.756805, Params tensor([2.1956, 0.0818])\n",
      "Epoch 4230, Loss 29.756350, Params tensor([2.1956, 0.0818])\n",
      "Epoch 4231, Loss 29.755898, Params tensor([2.1957, 0.0818])\n",
      "Epoch 4232, Loss 29.755449, Params tensor([2.1957, 0.0817])\n",
      "Epoch 4233, Loss 29.754993, Params tensor([2.1958, 0.0817])\n",
      "Epoch 4234, Loss 29.754549, Params tensor([2.1959, 0.0817])\n",
      "Epoch 4235, Loss 29.754101, Params tensor([2.1959, 0.0817])\n",
      "Epoch 4236, Loss 29.753649, Params tensor([2.1960, 0.0817])\n",
      "Epoch 4237, Loss 29.753202, Params tensor([2.1961, 0.0816])\n",
      "Epoch 4238, Loss 29.752747, Params tensor([2.1961, 0.0816])\n",
      "Epoch 4239, Loss 29.752300, Params tensor([2.1962, 0.0816])\n",
      "Epoch 4240, Loss 29.751854, Params tensor([2.1963, 0.0816])\n",
      "Epoch 4241, Loss 29.751404, Params tensor([2.1963, 0.0816])\n",
      "Epoch 4242, Loss 29.750959, Params tensor([2.1964, 0.0816])\n",
      "Epoch 4243, Loss 29.750507, Params tensor([2.1965, 0.0815])\n",
      "Epoch 4244, Loss 29.750061, Params tensor([2.1965, 0.0815])\n",
      "Epoch 4245, Loss 29.749617, Params tensor([2.1966, 0.0815])\n",
      "Epoch 4246, Loss 29.749170, Params tensor([2.1966, 0.0815])\n",
      "Epoch 4247, Loss 29.748724, Params tensor([2.1967, 0.0815])\n",
      "Epoch 4248, Loss 29.748280, Params tensor([2.1968, 0.0814])\n",
      "Epoch 4249, Loss 29.747833, Params tensor([2.1968, 0.0814])\n",
      "Epoch 4250, Loss 29.747389, Params tensor([2.1969, 0.0814])\n",
      "Epoch 4251, Loss 29.746948, Params tensor([2.1970, 0.0814])\n",
      "Epoch 4252, Loss 29.746502, Params tensor([2.1970, 0.0814])\n",
      "Epoch 4253, Loss 29.746065, Params tensor([2.1971, 0.0813])\n",
      "Epoch 4254, Loss 29.745623, Params tensor([2.1972, 0.0813])\n",
      "Epoch 4255, Loss 29.745180, Params tensor([2.1972, 0.0813])\n",
      "Epoch 4256, Loss 29.744738, Params tensor([2.1973, 0.0813])\n",
      "Epoch 4257, Loss 29.744295, Params tensor([2.1973, 0.0813])\n",
      "Epoch 4258, Loss 29.743855, Params tensor([2.1974, 0.0812])\n",
      "Epoch 4259, Loss 29.743420, Params tensor([2.1975, 0.0812])\n",
      "Epoch 4260, Loss 29.742979, Params tensor([2.1975, 0.0812])\n",
      "Epoch 4261, Loss 29.742531, Params tensor([2.1976, 0.0812])\n",
      "Epoch 4262, Loss 29.742094, Params tensor([2.1977, 0.0812])\n",
      "Epoch 4263, Loss 29.741663, Params tensor([2.1977, 0.0811])\n",
      "Epoch 4264, Loss 29.741217, Params tensor([2.1978, 0.0811])\n",
      "Epoch 4265, Loss 29.740784, Params tensor([2.1979, 0.0811])\n",
      "Epoch 4266, Loss 29.740349, Params tensor([2.1979, 0.0811])\n",
      "Epoch 4267, Loss 29.739910, Params tensor([2.1980, 0.0811])\n",
      "Epoch 4268, Loss 29.739473, Params tensor([2.1980, 0.0811])\n",
      "Epoch 4269, Loss 29.739042, Params tensor([2.1981, 0.0810])\n",
      "Epoch 4270, Loss 29.738604, Params tensor([2.1982, 0.0810])\n",
      "Epoch 4271, Loss 29.738167, Params tensor([2.1982, 0.0810])\n",
      "Epoch 4272, Loss 29.737734, Params tensor([2.1983, 0.0810])\n",
      "Epoch 4273, Loss 29.737297, Params tensor([2.1984, 0.0810])\n",
      "Epoch 4274, Loss 29.736864, Params tensor([2.1984, 0.0809])\n",
      "Epoch 4275, Loss 29.736431, Params tensor([2.1985, 0.0809])\n",
      "Epoch 4276, Loss 29.735998, Params tensor([2.1985, 0.0809])\n",
      "Epoch 4277, Loss 29.735567, Params tensor([2.1986, 0.0809])\n",
      "Epoch 4278, Loss 29.735132, Params tensor([2.1987, 0.0809])\n",
      "Epoch 4279, Loss 29.734703, Params tensor([2.1987, 0.0808])\n",
      "Epoch 4280, Loss 29.734270, Params tensor([2.1988, 0.0808])\n",
      "Epoch 4281, Loss 29.733839, Params tensor([2.1989, 0.0808])\n",
      "Epoch 4282, Loss 29.733406, Params tensor([2.1989, 0.0808])\n",
      "Epoch 4283, Loss 29.732985, Params tensor([2.1990, 0.0808])\n",
      "Epoch 4284, Loss 29.732550, Params tensor([2.1990, 0.0807])\n",
      "Epoch 4285, Loss 29.732119, Params tensor([2.1991, 0.0807])\n",
      "Epoch 4286, Loss 29.731691, Params tensor([2.1992, 0.0807])\n",
      "Epoch 4287, Loss 29.731262, Params tensor([2.1992, 0.0807])\n",
      "Epoch 4288, Loss 29.730841, Params tensor([2.1993, 0.0807])\n",
      "Epoch 4289, Loss 29.730410, Params tensor([2.1994, 0.0806])\n",
      "Epoch 4290, Loss 29.729980, Params tensor([2.1994, 0.0806])\n",
      "Epoch 4291, Loss 29.729553, Params tensor([2.1995, 0.0806])\n",
      "Epoch 4292, Loss 29.729126, Params tensor([2.1995, 0.0806])\n",
      "Epoch 4293, Loss 29.728704, Params tensor([2.1996, 0.0806])\n",
      "Epoch 4294, Loss 29.728277, Params tensor([2.1997, 0.0805])\n",
      "Epoch 4295, Loss 29.727856, Params tensor([2.1997, 0.0805])\n",
      "Epoch 4296, Loss 29.727425, Params tensor([2.1998, 0.0805])\n",
      "Epoch 4297, Loss 29.727001, Params tensor([2.1999, 0.0805])\n",
      "Epoch 4298, Loss 29.726580, Params tensor([2.1999, 0.0805])\n",
      "Epoch 4299, Loss 29.726154, Params tensor([2.2000, 0.0804])\n",
      "Epoch 4300, Loss 29.725733, Params tensor([2.2000, 0.0804])\n",
      "Epoch 4301, Loss 29.725309, Params tensor([2.2001, 0.0804])\n",
      "Epoch 4302, Loss 29.724886, Params tensor([2.2002, 0.0804])\n",
      "Epoch 4303, Loss 29.724464, Params tensor([2.2002, 0.0804])\n",
      "Epoch 4304, Loss 29.724043, Params tensor([2.2003, 0.0804])\n",
      "Epoch 4305, Loss 29.723621, Params tensor([2.2004, 0.0803])\n",
      "Epoch 4306, Loss 29.723206, Params tensor([2.2004, 0.0803])\n",
      "Epoch 4307, Loss 29.722780, Params tensor([2.2005, 0.0803])\n",
      "Epoch 4308, Loss 29.722363, Params tensor([2.2005, 0.0803])\n",
      "Epoch 4309, Loss 29.721941, Params tensor([2.2006, 0.0803])\n",
      "Epoch 4310, Loss 29.721525, Params tensor([2.2007, 0.0802])\n",
      "Epoch 4311, Loss 29.721106, Params tensor([2.2007, 0.0802])\n",
      "Epoch 4312, Loss 29.720684, Params tensor([2.2008, 0.0802])\n",
      "Epoch 4313, Loss 29.720264, Params tensor([2.2008, 0.0802])\n",
      "Epoch 4314, Loss 29.719849, Params tensor([2.2009, 0.0802])\n",
      "Epoch 4315, Loss 29.719433, Params tensor([2.2010, 0.0801])\n",
      "Epoch 4316, Loss 29.719017, Params tensor([2.2010, 0.0801])\n",
      "Epoch 4317, Loss 29.718599, Params tensor([2.2011, 0.0801])\n",
      "Epoch 4318, Loss 29.718182, Params tensor([2.2012, 0.0801])\n",
      "Epoch 4319, Loss 29.717766, Params tensor([2.2012, 0.0801])\n",
      "Epoch 4320, Loss 29.717352, Params tensor([2.2013, 0.0800])\n",
      "Epoch 4321, Loss 29.716942, Params tensor([2.2013, 0.0800])\n",
      "Epoch 4322, Loss 29.716524, Params tensor([2.2014, 0.0800])\n",
      "Epoch 4323, Loss 29.716106, Params tensor([2.2015, 0.0800])\n",
      "Epoch 4324, Loss 29.715698, Params tensor([2.2015, 0.0800])\n",
      "Epoch 4325, Loss 29.715282, Params tensor([2.2016, 0.0799])\n",
      "Epoch 4326, Loss 29.714869, Params tensor([2.2016, 0.0799])\n",
      "Epoch 4327, Loss 29.714458, Params tensor([2.2017, 0.0799])\n",
      "Epoch 4328, Loss 29.714045, Params tensor([2.2018, 0.0799])\n",
      "Epoch 4329, Loss 29.713634, Params tensor([2.2018, 0.0799])\n",
      "Epoch 4330, Loss 29.713224, Params tensor([2.2019, 0.0798])\n",
      "Epoch 4331, Loss 29.712812, Params tensor([2.2020, 0.0798])\n",
      "Epoch 4332, Loss 29.712402, Params tensor([2.2020, 0.0798])\n",
      "Epoch 4333, Loss 29.711987, Params tensor([2.2021, 0.0798])\n",
      "Epoch 4334, Loss 29.711580, Params tensor([2.2021, 0.0798])\n",
      "Epoch 4335, Loss 29.711170, Params tensor([2.2022, 0.0797])\n",
      "Epoch 4336, Loss 29.710762, Params tensor([2.2023, 0.0797])\n",
      "Epoch 4337, Loss 29.710356, Params tensor([2.2023, 0.0797])\n",
      "Epoch 4338, Loss 29.709944, Params tensor([2.2024, 0.0797])\n",
      "Epoch 4339, Loss 29.709539, Params tensor([2.2024, 0.0797])\n",
      "Epoch 4340, Loss 29.709135, Params tensor([2.2025, 0.0796])\n",
      "Epoch 4341, Loss 29.708723, Params tensor([2.2026, 0.0796])\n",
      "Epoch 4342, Loss 29.708319, Params tensor([2.2026, 0.0796])\n",
      "Epoch 4343, Loss 29.707914, Params tensor([2.2027, 0.0796])\n",
      "Epoch 4344, Loss 29.707508, Params tensor([2.2027, 0.0796])\n",
      "Epoch 4345, Loss 29.707100, Params tensor([2.2028, 0.0795])\n",
      "Epoch 4346, Loss 29.706696, Params tensor([2.2029, 0.0795])\n",
      "Epoch 4347, Loss 29.706293, Params tensor([2.2029, 0.0795])\n",
      "Epoch 4348, Loss 29.705885, Params tensor([2.2030, 0.0795])\n",
      "Epoch 4349, Loss 29.705482, Params tensor([2.2030, 0.0795])\n",
      "Epoch 4350, Loss 29.705080, Params tensor([2.2031, 0.0794])\n",
      "Epoch 4351, Loss 29.704679, Params tensor([2.2032, 0.0794])\n",
      "Epoch 4352, Loss 29.704277, Params tensor([2.2032, 0.0794])\n",
      "Epoch 4353, Loss 29.703875, Params tensor([2.2033, 0.0794])\n",
      "Epoch 4354, Loss 29.703468, Params tensor([2.2033, 0.0794])\n",
      "Epoch 4355, Loss 29.703070, Params tensor([2.2034, 0.0793])\n",
      "Epoch 4356, Loss 29.702665, Params tensor([2.2035, 0.0793])\n",
      "Epoch 4357, Loss 29.702271, Params tensor([2.2035, 0.0793])\n",
      "Epoch 4358, Loss 29.701866, Params tensor([2.2036, 0.0793])\n",
      "Epoch 4359, Loss 29.701466, Params tensor([2.2036, 0.0793])\n",
      "Epoch 4360, Loss 29.701063, Params tensor([2.2037, 0.0792])\n",
      "Epoch 4361, Loss 29.700666, Params tensor([2.2038, 0.0792])\n",
      "Epoch 4362, Loss 29.700268, Params tensor([2.2038, 0.0792])\n",
      "Epoch 4363, Loss 29.699867, Params tensor([2.2039, 0.0792])\n",
      "Epoch 4364, Loss 29.699474, Params tensor([2.2039, 0.0792])\n",
      "Epoch 4365, Loss 29.699078, Params tensor([2.2040, 0.0791])\n",
      "Epoch 4366, Loss 29.698677, Params tensor([2.2041, 0.0791])\n",
      "Epoch 4367, Loss 29.698280, Params tensor([2.2041, 0.0791])\n",
      "Epoch 4368, Loss 29.697878, Params tensor([2.2042, 0.0791])\n",
      "Epoch 4369, Loss 29.697487, Params tensor([2.2042, 0.0791])\n",
      "Epoch 4370, Loss 29.697088, Params tensor([2.2043, 0.0790])\n",
      "Epoch 4371, Loss 29.696693, Params tensor([2.2044, 0.0790])\n",
      "Epoch 4372, Loss 29.696295, Params tensor([2.2044, 0.0790])\n",
      "Epoch 4373, Loss 29.695904, Params tensor([2.2045, 0.0790])\n",
      "Epoch 4374, Loss 29.695509, Params tensor([2.2045, 0.0790])\n",
      "Epoch 4375, Loss 29.695118, Params tensor([2.2046, 0.0789])\n",
      "Epoch 4376, Loss 29.694719, Params tensor([2.2047, 0.0789])\n",
      "Epoch 4377, Loss 29.694330, Params tensor([2.2047, 0.0789])\n",
      "Epoch 4378, Loss 29.693937, Params tensor([2.2048, 0.0789])\n",
      "Epoch 4379, Loss 29.693542, Params tensor([2.2048, 0.0789])\n",
      "Epoch 4380, Loss 29.693148, Params tensor([2.2049, 0.0788])\n",
      "Epoch 4381, Loss 29.692757, Params tensor([2.2050, 0.0788])\n",
      "Epoch 4382, Loss 29.692366, Params tensor([2.2050, 0.0788])\n",
      "Epoch 4383, Loss 29.691973, Params tensor([2.2051, 0.0788])\n",
      "Epoch 4384, Loss 29.691584, Params tensor([2.2051, 0.0788])\n",
      "Epoch 4385, Loss 29.691191, Params tensor([2.2052, 0.0787])\n",
      "Epoch 4386, Loss 29.690807, Params tensor([2.2053, 0.0787])\n",
      "Epoch 4387, Loss 29.690416, Params tensor([2.2053, 0.0787])\n",
      "Epoch 4388, Loss 29.690025, Params tensor([2.2054, 0.0787])\n",
      "Epoch 4389, Loss 29.689634, Params tensor([2.2054, 0.0787])\n",
      "Epoch 4390, Loss 29.689245, Params tensor([2.2055, 0.0786])\n",
      "Epoch 4391, Loss 29.688860, Params tensor([2.2055, 0.0786])\n",
      "Epoch 4392, Loss 29.688469, Params tensor([2.2056, 0.0786])\n",
      "Epoch 4393, Loss 29.688086, Params tensor([2.2057, 0.0786])\n",
      "Epoch 4394, Loss 29.687700, Params tensor([2.2057, 0.0786])\n",
      "Epoch 4395, Loss 29.687315, Params tensor([2.2058, 0.0785])\n",
      "Epoch 4396, Loss 29.686922, Params tensor([2.2058, 0.0785])\n",
      "Epoch 4397, Loss 29.686537, Params tensor([2.2059, 0.0785])\n",
      "Epoch 4398, Loss 29.686146, Params tensor([2.2060, 0.0785])\n",
      "Epoch 4399, Loss 29.685762, Params tensor([2.2060, 0.0785])\n",
      "Epoch 4400, Loss 29.685381, Params tensor([2.2061, 0.0784])\n",
      "Epoch 4401, Loss 29.684998, Params tensor([2.2061, 0.0784])\n",
      "Epoch 4402, Loss 29.684614, Params tensor([2.2062, 0.0784])\n",
      "Epoch 4403, Loss 29.684227, Params tensor([2.2063, 0.0784])\n",
      "Epoch 4404, Loss 29.683844, Params tensor([2.2063, 0.0784])\n",
      "Epoch 4405, Loss 29.683460, Params tensor([2.2064, 0.0783])\n",
      "Epoch 4406, Loss 29.683075, Params tensor([2.2064, 0.0783])\n",
      "Epoch 4407, Loss 29.682695, Params tensor([2.2065, 0.0783])\n",
      "Epoch 4408, Loss 29.682318, Params tensor([2.2065, 0.0783])\n",
      "Epoch 4409, Loss 29.681932, Params tensor([2.2066, 0.0783])\n",
      "Epoch 4410, Loss 29.681551, Params tensor([2.2067, 0.0782])\n",
      "Epoch 4411, Loss 29.681164, Params tensor([2.2067, 0.0782])\n",
      "Epoch 4412, Loss 29.680786, Params tensor([2.2068, 0.0782])\n",
      "Epoch 4413, Loss 29.680408, Params tensor([2.2068, 0.0782])\n",
      "Epoch 4414, Loss 29.680025, Params tensor([2.2069, 0.0782])\n",
      "Epoch 4415, Loss 29.679649, Params tensor([2.2070, 0.0781])\n",
      "Epoch 4416, Loss 29.679266, Params tensor([2.2070, 0.0781])\n",
      "Epoch 4417, Loss 29.678888, Params tensor([2.2071, 0.0781])\n",
      "Epoch 4418, Loss 29.678511, Params tensor([2.2071, 0.0781])\n",
      "Epoch 4419, Loss 29.678133, Params tensor([2.2072, 0.0781])\n",
      "Epoch 4420, Loss 29.677753, Params tensor([2.2072, 0.0780])\n",
      "Epoch 4421, Loss 29.677374, Params tensor([2.2073, 0.0780])\n",
      "Epoch 4422, Loss 29.677002, Params tensor([2.2074, 0.0780])\n",
      "Epoch 4423, Loss 29.676624, Params tensor([2.2074, 0.0780])\n",
      "Epoch 4424, Loss 29.676245, Params tensor([2.2075, 0.0780])\n",
      "Epoch 4425, Loss 29.675873, Params tensor([2.2075, 0.0779])\n",
      "Epoch 4426, Loss 29.675489, Params tensor([2.2076, 0.0779])\n",
      "Epoch 4427, Loss 29.675117, Params tensor([2.2076, 0.0779])\n",
      "Epoch 4428, Loss 29.674744, Params tensor([2.2077, 0.0779])\n",
      "Epoch 4429, Loss 29.674366, Params tensor([2.2078, 0.0779])\n",
      "Epoch 4430, Loss 29.673994, Params tensor([2.2078, 0.0778])\n",
      "Epoch 4431, Loss 29.673622, Params tensor([2.2079, 0.0778])\n",
      "Epoch 4432, Loss 29.673246, Params tensor([2.2079, 0.0778])\n",
      "Epoch 4433, Loss 29.672874, Params tensor([2.2080, 0.0778])\n",
      "Epoch 4434, Loss 29.672497, Params tensor([2.2081, 0.0778])\n",
      "Epoch 4435, Loss 29.672131, Params tensor([2.2081, 0.0777])\n",
      "Epoch 4436, Loss 29.671753, Params tensor([2.2082, 0.0777])\n",
      "Epoch 4437, Loss 29.671381, Params tensor([2.2082, 0.0777])\n",
      "Epoch 4438, Loss 29.671013, Params tensor([2.2083, 0.0777])\n",
      "Epoch 4439, Loss 29.670637, Params tensor([2.2083, 0.0777])\n",
      "Epoch 4440, Loss 29.670269, Params tensor([2.2084, 0.0776])\n",
      "Epoch 4441, Loss 29.669893, Params tensor([2.2085, 0.0776])\n",
      "Epoch 4442, Loss 29.669527, Params tensor([2.2085, 0.0776])\n",
      "Epoch 4443, Loss 29.669157, Params tensor([2.2086, 0.0776])\n",
      "Epoch 4444, Loss 29.668785, Params tensor([2.2086, 0.0776])\n",
      "Epoch 4445, Loss 29.668421, Params tensor([2.2087, 0.0775])\n",
      "Epoch 4446, Loss 29.668049, Params tensor([2.2087, 0.0775])\n",
      "Epoch 4447, Loss 29.667681, Params tensor([2.2088, 0.0775])\n",
      "Epoch 4448, Loss 29.667311, Params tensor([2.2089, 0.0775])\n",
      "Epoch 4449, Loss 29.666943, Params tensor([2.2089, 0.0775])\n",
      "Epoch 4450, Loss 29.666573, Params tensor([2.2090, 0.0774])\n",
      "Epoch 4451, Loss 29.666206, Params tensor([2.2090, 0.0774])\n",
      "Epoch 4452, Loss 29.665844, Params tensor([2.2091, 0.0774])\n",
      "Epoch 4453, Loss 29.665478, Params tensor([2.2091, 0.0774])\n",
      "Epoch 4454, Loss 29.665108, Params tensor([2.2092, 0.0774])\n",
      "Epoch 4455, Loss 29.664747, Params tensor([2.2093, 0.0773])\n",
      "Epoch 4456, Loss 29.664379, Params tensor([2.2093, 0.0773])\n",
      "Epoch 4457, Loss 29.664007, Params tensor([2.2094, 0.0773])\n",
      "Epoch 4458, Loss 29.663649, Params tensor([2.2094, 0.0773])\n",
      "Epoch 4459, Loss 29.663280, Params tensor([2.2095, 0.0773])\n",
      "Epoch 4460, Loss 29.662920, Params tensor([2.2095, 0.0772])\n",
      "Epoch 4461, Loss 29.662560, Params tensor([2.2096, 0.0772])\n",
      "Epoch 4462, Loss 29.662193, Params tensor([2.2097, 0.0772])\n",
      "Epoch 4463, Loss 29.661827, Params tensor([2.2097, 0.0772])\n",
      "Epoch 4464, Loss 29.661467, Params tensor([2.2098, 0.0771])\n",
      "Epoch 4465, Loss 29.661100, Params tensor([2.2098, 0.0771])\n",
      "Epoch 4466, Loss 29.660742, Params tensor([2.2099, 0.0771])\n",
      "Epoch 4467, Loss 29.660378, Params tensor([2.2099, 0.0771])\n",
      "Epoch 4468, Loss 29.660017, Params tensor([2.2100, 0.0771])\n",
      "Epoch 4469, Loss 29.659657, Params tensor([2.2100, 0.0770])\n",
      "Epoch 4470, Loss 29.659296, Params tensor([2.2101, 0.0770])\n",
      "Epoch 4471, Loss 29.658930, Params tensor([2.2102, 0.0770])\n",
      "Epoch 4472, Loss 29.658571, Params tensor([2.2102, 0.0770])\n",
      "Epoch 4473, Loss 29.658211, Params tensor([2.2103, 0.0770])\n",
      "Epoch 4474, Loss 29.657850, Params tensor([2.2103, 0.0769])\n",
      "Epoch 4475, Loss 29.657494, Params tensor([2.2104, 0.0769])\n",
      "Epoch 4476, Loss 29.657135, Params tensor([2.2104, 0.0769])\n",
      "Epoch 4477, Loss 29.656776, Params tensor([2.2105, 0.0769])\n",
      "Epoch 4478, Loss 29.656422, Params tensor([2.2106, 0.0769])\n",
      "Epoch 4479, Loss 29.656059, Params tensor([2.2106, 0.0768])\n",
      "Epoch 4480, Loss 29.655701, Params tensor([2.2107, 0.0768])\n",
      "Epoch 4481, Loss 29.655342, Params tensor([2.2107, 0.0768])\n",
      "Epoch 4482, Loss 29.654991, Params tensor([2.2108, 0.0768])\n",
      "Epoch 4483, Loss 29.654627, Params tensor([2.2108, 0.0768])\n",
      "Epoch 4484, Loss 29.654278, Params tensor([2.2109, 0.0767])\n",
      "Epoch 4485, Loss 29.653917, Params tensor([2.2109, 0.0767])\n",
      "Epoch 4486, Loss 29.653559, Params tensor([2.2110, 0.0767])\n",
      "Epoch 4487, Loss 29.653210, Params tensor([2.2111, 0.0767])\n",
      "Epoch 4488, Loss 29.652849, Params tensor([2.2111, 0.0767])\n",
      "Epoch 4489, Loss 29.652498, Params tensor([2.2112, 0.0766])\n",
      "Epoch 4490, Loss 29.652143, Params tensor([2.2112, 0.0766])\n",
      "Epoch 4491, Loss 29.651794, Params tensor([2.2113, 0.0766])\n",
      "Epoch 4492, Loss 29.651434, Params tensor([2.2113, 0.0766])\n",
      "Epoch 4493, Loss 29.651079, Params tensor([2.2114, 0.0766])\n",
      "Epoch 4494, Loss 29.650726, Params tensor([2.2115, 0.0765])\n",
      "Epoch 4495, Loss 29.650373, Params tensor([2.2115, 0.0765])\n",
      "Epoch 4496, Loss 29.650019, Params tensor([2.2116, 0.0765])\n",
      "Epoch 4497, Loss 29.649670, Params tensor([2.2116, 0.0765])\n",
      "Epoch 4498, Loss 29.649324, Params tensor([2.2117, 0.0764])\n",
      "Epoch 4499, Loss 29.648964, Params tensor([2.2117, 0.0764])\n",
      "Epoch 4500, Loss 29.648619, Params tensor([2.2118, 0.0764])\n",
      "Epoch 4501, Loss 29.648266, Params tensor([2.2118, 0.0764])\n",
      "Epoch 4502, Loss 29.647917, Params tensor([2.2119, 0.0764])\n",
      "Epoch 4503, Loss 29.647564, Params tensor([2.2120, 0.0763])\n",
      "Epoch 4504, Loss 29.647211, Params tensor([2.2120, 0.0763])\n",
      "Epoch 4505, Loss 29.646862, Params tensor([2.2121, 0.0763])\n",
      "Epoch 4506, Loss 29.646513, Params tensor([2.2121, 0.0763])\n",
      "Epoch 4507, Loss 29.646168, Params tensor([2.2122, 0.0763])\n",
      "Epoch 4508, Loss 29.645815, Params tensor([2.2122, 0.0762])\n",
      "Epoch 4509, Loss 29.645470, Params tensor([2.2123, 0.0762])\n",
      "Epoch 4510, Loss 29.645119, Params tensor([2.2123, 0.0762])\n",
      "Epoch 4511, Loss 29.644775, Params tensor([2.2124, 0.0762])\n",
      "Epoch 4512, Loss 29.644417, Params tensor([2.2124, 0.0762])\n",
      "Epoch 4513, Loss 29.644073, Params tensor([2.2125, 0.0761])\n",
      "Epoch 4514, Loss 29.643730, Params tensor([2.2126, 0.0761])\n",
      "Epoch 4515, Loss 29.643383, Params tensor([2.2126, 0.0761])\n",
      "Epoch 4516, Loss 29.643036, Params tensor([2.2127, 0.0761])\n",
      "Epoch 4517, Loss 29.642693, Params tensor([2.2127, 0.0761])\n",
      "Epoch 4518, Loss 29.642345, Params tensor([2.2128, 0.0760])\n",
      "Epoch 4519, Loss 29.641998, Params tensor([2.2128, 0.0760])\n",
      "Epoch 4520, Loss 29.641655, Params tensor([2.2129, 0.0760])\n",
      "Epoch 4521, Loss 29.641308, Params tensor([2.2129, 0.0760])\n",
      "Epoch 4522, Loss 29.640966, Params tensor([2.2130, 0.0760])\n",
      "Epoch 4523, Loss 29.640623, Params tensor([2.2131, 0.0759])\n",
      "Epoch 4524, Loss 29.640282, Params tensor([2.2131, 0.0759])\n",
      "Epoch 4525, Loss 29.639935, Params tensor([2.2132, 0.0759])\n",
      "Epoch 4526, Loss 29.639595, Params tensor([2.2132, 0.0759])\n",
      "Epoch 4527, Loss 29.639250, Params tensor([2.2133, 0.0758])\n",
      "Epoch 4528, Loss 29.638908, Params tensor([2.2133, 0.0758])\n",
      "Epoch 4529, Loss 29.638561, Params tensor([2.2134, 0.0758])\n",
      "Epoch 4530, Loss 29.638222, Params tensor([2.2134, 0.0758])\n",
      "Epoch 4531, Loss 29.637880, Params tensor([2.2135, 0.0758])\n",
      "Epoch 4532, Loss 29.637541, Params tensor([2.2135, 0.0757])\n",
      "Epoch 4533, Loss 29.637199, Params tensor([2.2136, 0.0757])\n",
      "Epoch 4534, Loss 29.636858, Params tensor([2.2137, 0.0757])\n",
      "Epoch 4535, Loss 29.636517, Params tensor([2.2137, 0.0757])\n",
      "Epoch 4536, Loss 29.636175, Params tensor([2.2138, 0.0757])\n",
      "Epoch 4537, Loss 29.635836, Params tensor([2.2138, 0.0756])\n",
      "Epoch 4538, Loss 29.635500, Params tensor([2.2139, 0.0756])\n",
      "Epoch 4539, Loss 29.635160, Params tensor([2.2139, 0.0756])\n",
      "Epoch 4540, Loss 29.634825, Params tensor([2.2140, 0.0756])\n",
      "Epoch 4541, Loss 29.634480, Params tensor([2.2140, 0.0756])\n",
      "Epoch 4542, Loss 29.634144, Params tensor([2.2141, 0.0755])\n",
      "Epoch 4543, Loss 29.633806, Params tensor([2.2141, 0.0755])\n",
      "Epoch 4544, Loss 29.633467, Params tensor([2.2142, 0.0755])\n",
      "Epoch 4545, Loss 29.633129, Params tensor([2.2143, 0.0755])\n",
      "Epoch 4546, Loss 29.632790, Params tensor([2.2143, 0.0755])\n",
      "Epoch 4547, Loss 29.632458, Params tensor([2.2144, 0.0754])\n",
      "Epoch 4548, Loss 29.632118, Params tensor([2.2144, 0.0754])\n",
      "Epoch 4549, Loss 29.631781, Params tensor([2.2145, 0.0754])\n",
      "Epoch 4550, Loss 29.631447, Params tensor([2.2145, 0.0754])\n",
      "Epoch 4551, Loss 29.631109, Params tensor([2.2146, 0.0753])\n",
      "Epoch 4552, Loss 29.630775, Params tensor([2.2146, 0.0753])\n",
      "Epoch 4553, Loss 29.630440, Params tensor([2.2147, 0.0753])\n",
      "Epoch 4554, Loss 29.630108, Params tensor([2.2147, 0.0753])\n",
      "Epoch 4555, Loss 29.629772, Params tensor([2.2148, 0.0753])\n",
      "Epoch 4556, Loss 29.629436, Params tensor([2.2148, 0.0752])\n",
      "Epoch 4557, Loss 29.629103, Params tensor([2.2149, 0.0752])\n",
      "Epoch 4558, Loss 29.628771, Params tensor([2.2150, 0.0752])\n",
      "Epoch 4559, Loss 29.628431, Params tensor([2.2150, 0.0752])\n",
      "Epoch 4560, Loss 29.628105, Params tensor([2.2151, 0.0752])\n",
      "Epoch 4561, Loss 29.627771, Params tensor([2.2151, 0.0751])\n",
      "Epoch 4562, Loss 29.627439, Params tensor([2.2152, 0.0751])\n",
      "Epoch 4563, Loss 29.627108, Params tensor([2.2152, 0.0751])\n",
      "Epoch 4564, Loss 29.626776, Params tensor([2.2153, 0.0751])\n",
      "Epoch 4565, Loss 29.626442, Params tensor([2.2153, 0.0751])\n",
      "Epoch 4566, Loss 29.626116, Params tensor([2.2154, 0.0750])\n",
      "Epoch 4567, Loss 29.625786, Params tensor([2.2154, 0.0750])\n",
      "Epoch 4568, Loss 29.625450, Params tensor([2.2155, 0.0750])\n",
      "Epoch 4569, Loss 29.625122, Params tensor([2.2155, 0.0750])\n",
      "Epoch 4570, Loss 29.624792, Params tensor([2.2156, 0.0749])\n",
      "Epoch 4571, Loss 29.624458, Params tensor([2.2157, 0.0749])\n",
      "Epoch 4572, Loss 29.624134, Params tensor([2.2157, 0.0749])\n",
      "Epoch 4573, Loss 29.623804, Params tensor([2.2158, 0.0749])\n",
      "Epoch 4574, Loss 29.623474, Params tensor([2.2158, 0.0749])\n",
      "Epoch 4575, Loss 29.623144, Params tensor([2.2159, 0.0748])\n",
      "Epoch 4576, Loss 29.622816, Params tensor([2.2159, 0.0748])\n",
      "Epoch 4577, Loss 29.622484, Params tensor([2.2160, 0.0748])\n",
      "Epoch 4578, Loss 29.622162, Params tensor([2.2160, 0.0748])\n",
      "Epoch 4579, Loss 29.621838, Params tensor([2.2161, 0.0748])\n",
      "Epoch 4580, Loss 29.621513, Params tensor([2.2161, 0.0747])\n",
      "Epoch 4581, Loss 29.621180, Params tensor([2.2162, 0.0747])\n",
      "Epoch 4582, Loss 29.620855, Params tensor([2.2162, 0.0747])\n",
      "Epoch 4583, Loss 29.620527, Params tensor([2.2163, 0.0747])\n",
      "Epoch 4584, Loss 29.620201, Params tensor([2.2163, 0.0747])\n",
      "Epoch 4585, Loss 29.619873, Params tensor([2.2164, 0.0746])\n",
      "Epoch 4586, Loss 29.619551, Params tensor([2.2164, 0.0746])\n",
      "Epoch 4587, Loss 29.619230, Params tensor([2.2165, 0.0746])\n",
      "Epoch 4588, Loss 29.618902, Params tensor([2.2166, 0.0746])\n",
      "Epoch 4589, Loss 29.618572, Params tensor([2.2166, 0.0745])\n",
      "Epoch 4590, Loss 29.618254, Params tensor([2.2167, 0.0745])\n",
      "Epoch 4591, Loss 29.617926, Params tensor([2.2167, 0.0745])\n",
      "Epoch 4592, Loss 29.617601, Params tensor([2.2168, 0.0745])\n",
      "Epoch 4593, Loss 29.617281, Params tensor([2.2168, 0.0745])\n",
      "Epoch 4594, Loss 29.616962, Params tensor([2.2169, 0.0744])\n",
      "Epoch 4595, Loss 29.616632, Params tensor([2.2169, 0.0744])\n",
      "Epoch 4596, Loss 29.616310, Params tensor([2.2170, 0.0744])\n",
      "Epoch 4597, Loss 29.615992, Params tensor([2.2170, 0.0744])\n",
      "Epoch 4598, Loss 29.615667, Params tensor([2.2171, 0.0744])\n",
      "Epoch 4599, Loss 29.615345, Params tensor([2.2171, 0.0743])\n",
      "Epoch 4600, Loss 29.615023, Params tensor([2.2172, 0.0743])\n",
      "Epoch 4601, Loss 29.614702, Params tensor([2.2172, 0.0743])\n",
      "Epoch 4602, Loss 29.614380, Params tensor([2.2173, 0.0743])\n",
      "Epoch 4603, Loss 29.614061, Params tensor([2.2173, 0.0743])\n",
      "Epoch 4604, Loss 29.613745, Params tensor([2.2174, 0.0742])\n",
      "Epoch 4605, Loss 29.613426, Params tensor([2.2174, 0.0742])\n",
      "Epoch 4606, Loss 29.613106, Params tensor([2.2175, 0.0742])\n",
      "Epoch 4607, Loss 29.612782, Params tensor([2.2176, 0.0742])\n",
      "Epoch 4608, Loss 29.612459, Params tensor([2.2176, 0.0741])\n",
      "Epoch 4609, Loss 29.612141, Params tensor([2.2177, 0.0741])\n",
      "Epoch 4610, Loss 29.611828, Params tensor([2.2177, 0.0741])\n",
      "Epoch 4611, Loss 29.611506, Params tensor([2.2178, 0.0741])\n",
      "Epoch 4612, Loss 29.611193, Params tensor([2.2178, 0.0741])\n",
      "Epoch 4613, Loss 29.610872, Params tensor([2.2179, 0.0740])\n",
      "Epoch 4614, Loss 29.610558, Params tensor([2.2179, 0.0740])\n",
      "Epoch 4615, Loss 29.610237, Params tensor([2.2180, 0.0740])\n",
      "Epoch 4616, Loss 29.609919, Params tensor([2.2180, 0.0740])\n",
      "Epoch 4617, Loss 29.609602, Params tensor([2.2181, 0.0740])\n",
      "Epoch 4618, Loss 29.609283, Params tensor([2.2181, 0.0739])\n",
      "Epoch 4619, Loss 29.608971, Params tensor([2.2182, 0.0739])\n",
      "Epoch 4620, Loss 29.608656, Params tensor([2.2182, 0.0739])\n",
      "Epoch 4621, Loss 29.608337, Params tensor([2.2183, 0.0739])\n",
      "Epoch 4622, Loss 29.608027, Params tensor([2.2183, 0.0738])\n",
      "Epoch 4623, Loss 29.607708, Params tensor([2.2184, 0.0738])\n",
      "Epoch 4624, Loss 29.607391, Params tensor([2.2184, 0.0738])\n",
      "Epoch 4625, Loss 29.607080, Params tensor([2.2185, 0.0738])\n",
      "Epoch 4626, Loss 29.606768, Params tensor([2.2185, 0.0738])\n",
      "Epoch 4627, Loss 29.606451, Params tensor([2.2186, 0.0737])\n",
      "Epoch 4628, Loss 29.606140, Params tensor([2.2186, 0.0737])\n",
      "Epoch 4629, Loss 29.605824, Params tensor([2.2187, 0.0737])\n",
      "Epoch 4630, Loss 29.605507, Params tensor([2.2188, 0.0737])\n",
      "Epoch 4631, Loss 29.605196, Params tensor([2.2188, 0.0737])\n",
      "Epoch 4632, Loss 29.604889, Params tensor([2.2189, 0.0736])\n",
      "Epoch 4633, Loss 29.604572, Params tensor([2.2189, 0.0736])\n",
      "Epoch 4634, Loss 29.604259, Params tensor([2.2190, 0.0736])\n",
      "Epoch 4635, Loss 29.603949, Params tensor([2.2190, 0.0736])\n",
      "Epoch 4636, Loss 29.603638, Params tensor([2.2191, 0.0735])\n",
      "Epoch 4637, Loss 29.603325, Params tensor([2.2191, 0.0735])\n",
      "Epoch 4638, Loss 29.603014, Params tensor([2.2192, 0.0735])\n",
      "Epoch 4639, Loss 29.602703, Params tensor([2.2192, 0.0735])\n",
      "Epoch 4640, Loss 29.602388, Params tensor([2.2193, 0.0735])\n",
      "Epoch 4641, Loss 29.602087, Params tensor([2.2193, 0.0734])\n",
      "Epoch 4642, Loss 29.601776, Params tensor([2.2194, 0.0734])\n",
      "Epoch 4643, Loss 29.601465, Params tensor([2.2194, 0.0734])\n",
      "Epoch 4644, Loss 29.601152, Params tensor([2.2195, 0.0734])\n",
      "Epoch 4645, Loss 29.600843, Params tensor([2.2195, 0.0734])\n",
      "Epoch 4646, Loss 29.600536, Params tensor([2.2196, 0.0733])\n",
      "Epoch 4647, Loss 29.600225, Params tensor([2.2196, 0.0733])\n",
      "Epoch 4648, Loss 29.599920, Params tensor([2.2197, 0.0733])\n",
      "Epoch 4649, Loss 29.599609, Params tensor([2.2197, 0.0733])\n",
      "Epoch 4650, Loss 29.599304, Params tensor([2.2198, 0.0733])\n",
      "Epoch 4651, Loss 29.598999, Params tensor([2.2198, 0.0732])\n",
      "Epoch 4652, Loss 29.598688, Params tensor([2.2199, 0.0732])\n",
      "Epoch 4653, Loss 29.598383, Params tensor([2.2199, 0.0732])\n",
      "Epoch 4654, Loss 29.598078, Params tensor([2.2200, 0.0732])\n",
      "Epoch 4655, Loss 29.597767, Params tensor([2.2200, 0.0731])\n",
      "Epoch 4656, Loss 29.597462, Params tensor([2.2201, 0.0731])\n",
      "Epoch 4657, Loss 29.597157, Params tensor([2.2201, 0.0731])\n",
      "Epoch 4658, Loss 29.596855, Params tensor([2.2202, 0.0731])\n",
      "Epoch 4659, Loss 29.596546, Params tensor([2.2202, 0.0731])\n",
      "Epoch 4660, Loss 29.596241, Params tensor([2.2203, 0.0730])\n",
      "Epoch 4661, Loss 29.595936, Params tensor([2.2203, 0.0730])\n",
      "Epoch 4662, Loss 29.595634, Params tensor([2.2204, 0.0730])\n",
      "Epoch 4663, Loss 29.595329, Params tensor([2.2204, 0.0730])\n",
      "Epoch 4664, Loss 29.595024, Params tensor([2.2205, 0.0729])\n",
      "Epoch 4665, Loss 29.594715, Params tensor([2.2205, 0.0729])\n",
      "Epoch 4666, Loss 29.594419, Params tensor([2.2206, 0.0729])\n",
      "Epoch 4667, Loss 29.594114, Params tensor([2.2206, 0.0729])\n",
      "Epoch 4668, Loss 29.593809, Params tensor([2.2207, 0.0729])\n",
      "Epoch 4669, Loss 29.593506, Params tensor([2.2207, 0.0728])\n",
      "Epoch 4670, Loss 29.593203, Params tensor([2.2208, 0.0728])\n",
      "Epoch 4671, Loss 29.592901, Params tensor([2.2208, 0.0728])\n",
      "Epoch 4672, Loss 29.592596, Params tensor([2.2209, 0.0728])\n",
      "Epoch 4673, Loss 29.592297, Params tensor([2.2209, 0.0728])\n",
      "Epoch 4674, Loss 29.591993, Params tensor([2.2210, 0.0727])\n",
      "Epoch 4675, Loss 29.591694, Params tensor([2.2210, 0.0727])\n",
      "Epoch 4676, Loss 29.591394, Params tensor([2.2211, 0.0727])\n",
      "Epoch 4677, Loss 29.591093, Params tensor([2.2211, 0.0727])\n",
      "Epoch 4678, Loss 29.590792, Params tensor([2.2212, 0.0726])\n",
      "Epoch 4679, Loss 29.590487, Params tensor([2.2213, 0.0726])\n",
      "Epoch 4680, Loss 29.590191, Params tensor([2.2213, 0.0726])\n",
      "Epoch 4681, Loss 29.589893, Params tensor([2.2214, 0.0726])\n",
      "Epoch 4682, Loss 29.589592, Params tensor([2.2214, 0.0726])\n",
      "Epoch 4683, Loss 29.589294, Params tensor([2.2215, 0.0725])\n",
      "Epoch 4684, Loss 29.588995, Params tensor([2.2215, 0.0725])\n",
      "Epoch 4685, Loss 29.588696, Params tensor([2.2216, 0.0725])\n",
      "Epoch 4686, Loss 29.588396, Params tensor([2.2216, 0.0725])\n",
      "Epoch 4687, Loss 29.588097, Params tensor([2.2217, 0.0725])\n",
      "Epoch 4688, Loss 29.587799, Params tensor([2.2217, 0.0724])\n",
      "Epoch 4689, Loss 29.587502, Params tensor([2.2218, 0.0724])\n",
      "Epoch 4690, Loss 29.587202, Params tensor([2.2218, 0.0724])\n",
      "Epoch 4691, Loss 29.586906, Params tensor([2.2219, 0.0724])\n",
      "Epoch 4692, Loss 29.586615, Params tensor([2.2219, 0.0723])\n",
      "Epoch 4693, Loss 29.586311, Params tensor([2.2220, 0.0723])\n",
      "Epoch 4694, Loss 29.586018, Params tensor([2.2220, 0.0723])\n",
      "Epoch 4695, Loss 29.585722, Params tensor([2.2221, 0.0723])\n",
      "Epoch 4696, Loss 29.585424, Params tensor([2.2221, 0.0723])\n",
      "Epoch 4697, Loss 29.585127, Params tensor([2.2222, 0.0722])\n",
      "Epoch 4698, Loss 29.584833, Params tensor([2.2222, 0.0722])\n",
      "Epoch 4699, Loss 29.584539, Params tensor([2.2223, 0.0722])\n",
      "Epoch 4700, Loss 29.584242, Params tensor([2.2223, 0.0722])\n",
      "Epoch 4701, Loss 29.583948, Params tensor([2.2224, 0.0722])\n",
      "Epoch 4702, Loss 29.583651, Params tensor([2.2224, 0.0721])\n",
      "Epoch 4703, Loss 29.583363, Params tensor([2.2225, 0.0721])\n",
      "Epoch 4704, Loss 29.583067, Params tensor([2.2225, 0.0721])\n",
      "Epoch 4705, Loss 29.582775, Params tensor([2.2225, 0.0721])\n",
      "Epoch 4706, Loss 29.582483, Params tensor([2.2226, 0.0720])\n",
      "Epoch 4707, Loss 29.582186, Params tensor([2.2226, 0.0720])\n",
      "Epoch 4708, Loss 29.581892, Params tensor([2.2227, 0.0720])\n",
      "Epoch 4709, Loss 29.581602, Params tensor([2.2227, 0.0720])\n",
      "Epoch 4710, Loss 29.581305, Params tensor([2.2228, 0.0720])\n",
      "Epoch 4711, Loss 29.581018, Params tensor([2.2228, 0.0719])\n",
      "Epoch 4712, Loss 29.580721, Params tensor([2.2229, 0.0719])\n",
      "Epoch 4713, Loss 29.580433, Params tensor([2.2229, 0.0719])\n",
      "Epoch 4714, Loss 29.580141, Params tensor([2.2230, 0.0719])\n",
      "Epoch 4715, Loss 29.579847, Params tensor([2.2230, 0.0718])\n",
      "Epoch 4716, Loss 29.579561, Params tensor([2.2231, 0.0718])\n",
      "Epoch 4717, Loss 29.579268, Params tensor([2.2231, 0.0718])\n",
      "Epoch 4718, Loss 29.578978, Params tensor([2.2232, 0.0718])\n",
      "Epoch 4719, Loss 29.578691, Params tensor([2.2232, 0.0718])\n",
      "Epoch 4720, Loss 29.578398, Params tensor([2.2233, 0.0717])\n",
      "Epoch 4721, Loss 29.578108, Params tensor([2.2233, 0.0717])\n",
      "Epoch 4722, Loss 29.577820, Params tensor([2.2234, 0.0717])\n",
      "Epoch 4723, Loss 29.577526, Params tensor([2.2234, 0.0717])\n",
      "Epoch 4724, Loss 29.577240, Params tensor([2.2235, 0.0717])\n",
      "Epoch 4725, Loss 29.576948, Params tensor([2.2235, 0.0716])\n",
      "Epoch 4726, Loss 29.576662, Params tensor([2.2236, 0.0716])\n",
      "Epoch 4727, Loss 29.576372, Params tensor([2.2236, 0.0716])\n",
      "Epoch 4728, Loss 29.576088, Params tensor([2.2237, 0.0716])\n",
      "Epoch 4729, Loss 29.575800, Params tensor([2.2237, 0.0715])\n",
      "Epoch 4730, Loss 29.575508, Params tensor([2.2238, 0.0715])\n",
      "Epoch 4731, Loss 29.575226, Params tensor([2.2238, 0.0715])\n",
      "Epoch 4732, Loss 29.574934, Params tensor([2.2239, 0.0715])\n",
      "Epoch 4733, Loss 29.574648, Params tensor([2.2239, 0.0715])\n",
      "Epoch 4734, Loss 29.574360, Params tensor([2.2240, 0.0714])\n",
      "Epoch 4735, Loss 29.574074, Params tensor([2.2240, 0.0714])\n",
      "Epoch 4736, Loss 29.573792, Params tensor([2.2241, 0.0714])\n",
      "Epoch 4737, Loss 29.573503, Params tensor([2.2241, 0.0714])\n",
      "Epoch 4738, Loss 29.573217, Params tensor([2.2242, 0.0713])\n",
      "Epoch 4739, Loss 29.572931, Params tensor([2.2242, 0.0713])\n",
      "Epoch 4740, Loss 29.572643, Params tensor([2.2243, 0.0713])\n",
      "Epoch 4741, Loss 29.572359, Params tensor([2.2243, 0.0713])\n",
      "Epoch 4742, Loss 29.572077, Params tensor([2.2244, 0.0713])\n",
      "Epoch 4743, Loss 29.571791, Params tensor([2.2244, 0.0712])\n",
      "Epoch 4744, Loss 29.571510, Params tensor([2.2245, 0.0712])\n",
      "Epoch 4745, Loss 29.571222, Params tensor([2.2245, 0.0712])\n",
      "Epoch 4746, Loss 29.570942, Params tensor([2.2246, 0.0712])\n",
      "Epoch 4747, Loss 29.570654, Params tensor([2.2246, 0.0711])\n",
      "Epoch 4748, Loss 29.570372, Params tensor([2.2247, 0.0711])\n",
      "Epoch 4749, Loss 29.570091, Params tensor([2.2247, 0.0711])\n",
      "Epoch 4750, Loss 29.569811, Params tensor([2.2248, 0.0711])\n",
      "Epoch 4751, Loss 29.569521, Params tensor([2.2248, 0.0711])\n",
      "Epoch 4752, Loss 29.569239, Params tensor([2.2249, 0.0710])\n",
      "Epoch 4753, Loss 29.568958, Params tensor([2.2249, 0.0710])\n",
      "Epoch 4754, Loss 29.568676, Params tensor([2.2250, 0.0710])\n",
      "Epoch 4755, Loss 29.568398, Params tensor([2.2250, 0.0710])\n",
      "Epoch 4756, Loss 29.568113, Params tensor([2.2250, 0.0710])\n",
      "Epoch 4757, Loss 29.567833, Params tensor([2.2251, 0.0709])\n",
      "Epoch 4758, Loss 29.567549, Params tensor([2.2251, 0.0709])\n",
      "Epoch 4759, Loss 29.567272, Params tensor([2.2252, 0.0709])\n",
      "Epoch 4760, Loss 29.566988, Params tensor([2.2252, 0.0709])\n",
      "Epoch 4761, Loss 29.566713, Params tensor([2.2253, 0.0708])\n",
      "Epoch 4762, Loss 29.566431, Params tensor([2.2253, 0.0708])\n",
      "Epoch 4763, Loss 29.566151, Params tensor([2.2254, 0.0708])\n",
      "Epoch 4764, Loss 29.565870, Params tensor([2.2254, 0.0708])\n",
      "Epoch 4765, Loss 29.565594, Params tensor([2.2255, 0.0708])\n",
      "Epoch 4766, Loss 29.565313, Params tensor([2.2255, 0.0707])\n",
      "Epoch 4767, Loss 29.565033, Params tensor([2.2256, 0.0707])\n",
      "Epoch 4768, Loss 29.564756, Params tensor([2.2256, 0.0707])\n",
      "Epoch 4769, Loss 29.564476, Params tensor([2.2257, 0.0707])\n",
      "Epoch 4770, Loss 29.564201, Params tensor([2.2257, 0.0706])\n",
      "Epoch 4771, Loss 29.563921, Params tensor([2.2258, 0.0706])\n",
      "Epoch 4772, Loss 29.563643, Params tensor([2.2258, 0.0706])\n",
      "Epoch 4773, Loss 29.563360, Params tensor([2.2259, 0.0706])\n",
      "Epoch 4774, Loss 29.563091, Params tensor([2.2259, 0.0706])\n",
      "Epoch 4775, Loss 29.562811, Params tensor([2.2260, 0.0705])\n",
      "Epoch 4776, Loss 29.562536, Params tensor([2.2260, 0.0705])\n",
      "Epoch 4777, Loss 29.562256, Params tensor([2.2261, 0.0705])\n",
      "Epoch 4778, Loss 29.561983, Params tensor([2.2261, 0.0705])\n",
      "Epoch 4779, Loss 29.561705, Params tensor([2.2262, 0.0704])\n",
      "Epoch 4780, Loss 29.561430, Params tensor([2.2262, 0.0704])\n",
      "Epoch 4781, Loss 29.561157, Params tensor([2.2262, 0.0704])\n",
      "Epoch 4782, Loss 29.560881, Params tensor([2.2263, 0.0704])\n",
      "Epoch 4783, Loss 29.560602, Params tensor([2.2263, 0.0704])\n",
      "Epoch 4784, Loss 29.560326, Params tensor([2.2264, 0.0703])\n",
      "Epoch 4785, Loss 29.560051, Params tensor([2.2264, 0.0703])\n",
      "Epoch 4786, Loss 29.559778, Params tensor([2.2265, 0.0703])\n",
      "Epoch 4787, Loss 29.559504, Params tensor([2.2265, 0.0703])\n",
      "Epoch 4788, Loss 29.559233, Params tensor([2.2266, 0.0702])\n",
      "Epoch 4789, Loss 29.558949, Params tensor([2.2266, 0.0702])\n",
      "Epoch 4790, Loss 29.558683, Params tensor([2.2267, 0.0702])\n",
      "Epoch 4791, Loss 29.558405, Params tensor([2.2267, 0.0702])\n",
      "Epoch 4792, Loss 29.558136, Params tensor([2.2268, 0.0702])\n",
      "Epoch 4793, Loss 29.557859, Params tensor([2.2268, 0.0701])\n",
      "Epoch 4794, Loss 29.557585, Params tensor([2.2269, 0.0701])\n",
      "Epoch 4795, Loss 29.557318, Params tensor([2.2269, 0.0701])\n",
      "Epoch 4796, Loss 29.557039, Params tensor([2.2270, 0.0701])\n",
      "Epoch 4797, Loss 29.556774, Params tensor([2.2270, 0.0700])\n",
      "Epoch 4798, Loss 29.556496, Params tensor([2.2271, 0.0700])\n",
      "Epoch 4799, Loss 29.556231, Params tensor([2.2271, 0.0700])\n",
      "Epoch 4800, Loss 29.555956, Params tensor([2.2271, 0.0700])\n",
      "Epoch 4801, Loss 29.555683, Params tensor([2.2272, 0.0700])\n",
      "Epoch 4802, Loss 29.555414, Params tensor([2.2272, 0.0699])\n",
      "Epoch 4803, Loss 29.555138, Params tensor([2.2273, 0.0699])\n",
      "Epoch 4804, Loss 29.554871, Params tensor([2.2273, 0.0699])\n",
      "Epoch 4805, Loss 29.554604, Params tensor([2.2274, 0.0699])\n",
      "Epoch 4806, Loss 29.554329, Params tensor([2.2274, 0.0698])\n",
      "Epoch 4807, Loss 29.554064, Params tensor([2.2275, 0.0698])\n",
      "Epoch 4808, Loss 29.553791, Params tensor([2.2275, 0.0698])\n",
      "Epoch 4809, Loss 29.553522, Params tensor([2.2276, 0.0698])\n",
      "Epoch 4810, Loss 29.553255, Params tensor([2.2276, 0.0698])\n",
      "Epoch 4811, Loss 29.552984, Params tensor([2.2277, 0.0697])\n",
      "Epoch 4812, Loss 29.552715, Params tensor([2.2277, 0.0697])\n",
      "Epoch 4813, Loss 29.552448, Params tensor([2.2278, 0.0697])\n",
      "Epoch 4814, Loss 29.552177, Params tensor([2.2278, 0.0697])\n",
      "Epoch 4815, Loss 29.551908, Params tensor([2.2279, 0.0696])\n",
      "Epoch 4816, Loss 29.551638, Params tensor([2.2279, 0.0696])\n",
      "Epoch 4817, Loss 29.551374, Params tensor([2.2279, 0.0696])\n",
      "Epoch 4818, Loss 29.551105, Params tensor([2.2280, 0.0696])\n",
      "Epoch 4819, Loss 29.550837, Params tensor([2.2280, 0.0696])\n",
      "Epoch 4820, Loss 29.550570, Params tensor([2.2281, 0.0695])\n",
      "Epoch 4821, Loss 29.550304, Params tensor([2.2281, 0.0695])\n",
      "Epoch 4822, Loss 29.550037, Params tensor([2.2282, 0.0695])\n",
      "Epoch 4823, Loss 29.549772, Params tensor([2.2282, 0.0695])\n",
      "Epoch 4824, Loss 29.549511, Params tensor([2.2283, 0.0694])\n",
      "Epoch 4825, Loss 29.549236, Params tensor([2.2283, 0.0694])\n",
      "Epoch 4826, Loss 29.548973, Params tensor([2.2284, 0.0694])\n",
      "Epoch 4827, Loss 29.548708, Params tensor([2.2284, 0.0694])\n",
      "Epoch 4828, Loss 29.548443, Params tensor([2.2285, 0.0694])\n",
      "Epoch 4829, Loss 29.548174, Params tensor([2.2285, 0.0693])\n",
      "Epoch 4830, Loss 29.547915, Params tensor([2.2285, 0.0693])\n",
      "Epoch 4831, Loss 29.547640, Params tensor([2.2286, 0.0693])\n",
      "Epoch 4832, Loss 29.547380, Params tensor([2.2286, 0.0693])\n",
      "Epoch 4833, Loss 29.547117, Params tensor([2.2287, 0.0692])\n",
      "Epoch 4834, Loss 29.546850, Params tensor([2.2287, 0.0692])\n",
      "Epoch 4835, Loss 29.546589, Params tensor([2.2288, 0.0692])\n",
      "Epoch 4836, Loss 29.546326, Params tensor([2.2288, 0.0692])\n",
      "Epoch 4837, Loss 29.546059, Params tensor([2.2289, 0.0692])\n",
      "Epoch 4838, Loss 29.545799, Params tensor([2.2289, 0.0691])\n",
      "Epoch 4839, Loss 29.545538, Params tensor([2.2290, 0.0691])\n",
      "Epoch 4840, Loss 29.545271, Params tensor([2.2290, 0.0691])\n",
      "Epoch 4841, Loss 29.545006, Params tensor([2.2291, 0.0691])\n",
      "Epoch 4842, Loss 29.544746, Params tensor([2.2291, 0.0690])\n",
      "Epoch 4843, Loss 29.544487, Params tensor([2.2291, 0.0690])\n",
      "Epoch 4844, Loss 29.544222, Params tensor([2.2292, 0.0690])\n",
      "Epoch 4845, Loss 29.543964, Params tensor([2.2292, 0.0690])\n",
      "Epoch 4846, Loss 29.543701, Params tensor([2.2293, 0.0690])\n",
      "Epoch 4847, Loss 29.543438, Params tensor([2.2293, 0.0689])\n",
      "Epoch 4848, Loss 29.543177, Params tensor([2.2294, 0.0689])\n",
      "Epoch 4849, Loss 29.542913, Params tensor([2.2294, 0.0689])\n",
      "Epoch 4850, Loss 29.542652, Params tensor([2.2295, 0.0689])\n",
      "Epoch 4851, Loss 29.542395, Params tensor([2.2295, 0.0688])\n",
      "Epoch 4852, Loss 29.542137, Params tensor([2.2296, 0.0688])\n",
      "Epoch 4853, Loss 29.541872, Params tensor([2.2296, 0.0688])\n",
      "Epoch 4854, Loss 29.541613, Params tensor([2.2297, 0.0688])\n",
      "Epoch 4855, Loss 29.541357, Params tensor([2.2297, 0.0688])\n",
      "Epoch 4856, Loss 29.541094, Params tensor([2.2297, 0.0687])\n",
      "Epoch 4857, Loss 29.540838, Params tensor([2.2298, 0.0687])\n",
      "Epoch 4858, Loss 29.540571, Params tensor([2.2298, 0.0687])\n",
      "Epoch 4859, Loss 29.540319, Params tensor([2.2299, 0.0687])\n",
      "Epoch 4860, Loss 29.540058, Params tensor([2.2299, 0.0686])\n",
      "Epoch 4861, Loss 29.539797, Params tensor([2.2300, 0.0686])\n",
      "Epoch 4862, Loss 29.539539, Params tensor([2.2300, 0.0686])\n",
      "Epoch 4863, Loss 29.539282, Params tensor([2.2301, 0.0686])\n",
      "Epoch 4864, Loss 29.539026, Params tensor([2.2301, 0.0686])\n",
      "Epoch 4865, Loss 29.538765, Params tensor([2.2302, 0.0685])\n",
      "Epoch 4866, Loss 29.538511, Params tensor([2.2302, 0.0685])\n",
      "Epoch 4867, Loss 29.538252, Params tensor([2.2302, 0.0685])\n",
      "Epoch 4868, Loss 29.537996, Params tensor([2.2303, 0.0685])\n",
      "Epoch 4869, Loss 29.537737, Params tensor([2.2303, 0.0684])\n",
      "Epoch 4870, Loss 29.537481, Params tensor([2.2304, 0.0684])\n",
      "Epoch 4871, Loss 29.537226, Params tensor([2.2304, 0.0684])\n",
      "Epoch 4872, Loss 29.536970, Params tensor([2.2305, 0.0684])\n",
      "Epoch 4873, Loss 29.536713, Params tensor([2.2305, 0.0684])\n",
      "Epoch 4874, Loss 29.536461, Params tensor([2.2306, 0.0683])\n",
      "Epoch 4875, Loss 29.536201, Params tensor([2.2306, 0.0683])\n",
      "Epoch 4876, Loss 29.535948, Params tensor([2.2307, 0.0683])\n",
      "Epoch 4877, Loss 29.535694, Params tensor([2.2307, 0.0683])\n",
      "Epoch 4878, Loss 29.535433, Params tensor([2.2307, 0.0682])\n",
      "Epoch 4879, Loss 29.535179, Params tensor([2.2308, 0.0682])\n",
      "Epoch 4880, Loss 29.534925, Params tensor([2.2308, 0.0682])\n",
      "Epoch 4881, Loss 29.534670, Params tensor([2.2309, 0.0682])\n",
      "Epoch 4882, Loss 29.534418, Params tensor([2.2309, 0.0682])\n",
      "Epoch 4883, Loss 29.534163, Params tensor([2.2310, 0.0681])\n",
      "Epoch 4884, Loss 29.533911, Params tensor([2.2310, 0.0681])\n",
      "Epoch 4885, Loss 29.533655, Params tensor([2.2311, 0.0681])\n",
      "Epoch 4886, Loss 29.533405, Params tensor([2.2311, 0.0681])\n",
      "Epoch 4887, Loss 29.533148, Params tensor([2.2312, 0.0680])\n",
      "Epoch 4888, Loss 29.532896, Params tensor([2.2312, 0.0680])\n",
      "Epoch 4889, Loss 29.532640, Params tensor([2.2312, 0.0680])\n",
      "Epoch 4890, Loss 29.532393, Params tensor([2.2313, 0.0680])\n",
      "Epoch 4891, Loss 29.532137, Params tensor([2.2313, 0.0680])\n",
      "Epoch 4892, Loss 29.531883, Params tensor([2.2314, 0.0679])\n",
      "Epoch 4893, Loss 29.531633, Params tensor([2.2314, 0.0679])\n",
      "Epoch 4894, Loss 29.531380, Params tensor([2.2315, 0.0679])\n",
      "Epoch 4895, Loss 29.531130, Params tensor([2.2315, 0.0679])\n",
      "Epoch 4896, Loss 29.530878, Params tensor([2.2316, 0.0678])\n",
      "Epoch 4897, Loss 29.530628, Params tensor([2.2316, 0.0678])\n",
      "Epoch 4898, Loss 29.530373, Params tensor([2.2316, 0.0678])\n",
      "Epoch 4899, Loss 29.530123, Params tensor([2.2317, 0.0678])\n",
      "Epoch 4900, Loss 29.529875, Params tensor([2.2317, 0.0677])\n",
      "Epoch 4901, Loss 29.529625, Params tensor([2.2318, 0.0677])\n",
      "Epoch 4902, Loss 29.529371, Params tensor([2.2318, 0.0677])\n",
      "Epoch 4903, Loss 29.529119, Params tensor([2.2319, 0.0677])\n",
      "Epoch 4904, Loss 29.528870, Params tensor([2.2319, 0.0677])\n",
      "Epoch 4905, Loss 29.528624, Params tensor([2.2320, 0.0676])\n",
      "Epoch 4906, Loss 29.528376, Params tensor([2.2320, 0.0676])\n",
      "Epoch 4907, Loss 29.528126, Params tensor([2.2320, 0.0676])\n",
      "Epoch 4908, Loss 29.527876, Params tensor([2.2321, 0.0676])\n",
      "Epoch 4909, Loss 29.527626, Params tensor([2.2321, 0.0675])\n",
      "Epoch 4910, Loss 29.527374, Params tensor([2.2322, 0.0675])\n",
      "Epoch 4911, Loss 29.527128, Params tensor([2.2322, 0.0675])\n",
      "Epoch 4912, Loss 29.526880, Params tensor([2.2323, 0.0675])\n",
      "Epoch 4913, Loss 29.526630, Params tensor([2.2323, 0.0675])\n",
      "Epoch 4914, Loss 29.526384, Params tensor([2.2324, 0.0674])\n",
      "Epoch 4915, Loss 29.526136, Params tensor([2.2324, 0.0674])\n",
      "Epoch 4916, Loss 29.525887, Params tensor([2.2324, 0.0674])\n",
      "Epoch 4917, Loss 29.525642, Params tensor([2.2325, 0.0674])\n",
      "Epoch 4918, Loss 29.525391, Params tensor([2.2325, 0.0673])\n",
      "Epoch 4919, Loss 29.525146, Params tensor([2.2326, 0.0673])\n",
      "Epoch 4920, Loss 29.524897, Params tensor([2.2326, 0.0673])\n",
      "Epoch 4921, Loss 29.524652, Params tensor([2.2327, 0.0673])\n",
      "Epoch 4922, Loss 29.524408, Params tensor([2.2327, 0.0673])\n",
      "Epoch 4923, Loss 29.524158, Params tensor([2.2328, 0.0672])\n",
      "Epoch 4924, Loss 29.523914, Params tensor([2.2328, 0.0672])\n",
      "Epoch 4925, Loss 29.523668, Params tensor([2.2328, 0.0672])\n",
      "Epoch 4926, Loss 29.523420, Params tensor([2.2329, 0.0672])\n",
      "Epoch 4927, Loss 29.523176, Params tensor([2.2329, 0.0671])\n",
      "Epoch 4928, Loss 29.522930, Params tensor([2.2330, 0.0671])\n",
      "Epoch 4929, Loss 29.522686, Params tensor([2.2330, 0.0671])\n",
      "Epoch 4930, Loss 29.522444, Params tensor([2.2331, 0.0671])\n",
      "Epoch 4931, Loss 29.522198, Params tensor([2.2331, 0.0670])\n",
      "Epoch 4932, Loss 29.521954, Params tensor([2.2332, 0.0670])\n",
      "Epoch 4933, Loss 29.521700, Params tensor([2.2332, 0.0670])\n",
      "Epoch 4934, Loss 29.521460, Params tensor([2.2332, 0.0670])\n",
      "Epoch 4935, Loss 29.521217, Params tensor([2.2333, 0.0670])\n",
      "Epoch 4936, Loss 29.520973, Params tensor([2.2333, 0.0669])\n",
      "Epoch 4937, Loss 29.520733, Params tensor([2.2334, 0.0669])\n",
      "Epoch 4938, Loss 29.520489, Params tensor([2.2334, 0.0669])\n",
      "Epoch 4939, Loss 29.520247, Params tensor([2.2335, 0.0669])\n",
      "Epoch 4940, Loss 29.520000, Params tensor([2.2335, 0.0668])\n",
      "Epoch 4941, Loss 29.519758, Params tensor([2.2335, 0.0668])\n",
      "Epoch 4942, Loss 29.519518, Params tensor([2.2336, 0.0668])\n",
      "Epoch 4943, Loss 29.519276, Params tensor([2.2336, 0.0668])\n",
      "Epoch 4944, Loss 29.519030, Params tensor([2.2337, 0.0668])\n",
      "Epoch 4945, Loss 29.518787, Params tensor([2.2337, 0.0667])\n",
      "Epoch 4946, Loss 29.518547, Params tensor([2.2338, 0.0667])\n",
      "Epoch 4947, Loss 29.518305, Params tensor([2.2338, 0.0667])\n",
      "Epoch 4948, Loss 29.518064, Params tensor([2.2339, 0.0667])\n",
      "Epoch 4949, Loss 29.517824, Params tensor([2.2339, 0.0666])\n",
      "Epoch 4950, Loss 29.517578, Params tensor([2.2339, 0.0666])\n",
      "Epoch 4951, Loss 29.517340, Params tensor([2.2340, 0.0666])\n",
      "Epoch 4952, Loss 29.517101, Params tensor([2.2340, 0.0666])\n",
      "Epoch 4953, Loss 29.516857, Params tensor([2.2341, 0.0665])\n",
      "Epoch 4954, Loss 29.516619, Params tensor([2.2341, 0.0665])\n",
      "Epoch 4955, Loss 29.516380, Params tensor([2.2342, 0.0665])\n",
      "Epoch 4956, Loss 29.516136, Params tensor([2.2342, 0.0665])\n",
      "Epoch 4957, Loss 29.515900, Params tensor([2.2342, 0.0665])\n",
      "Epoch 4958, Loss 29.515661, Params tensor([2.2343, 0.0664])\n",
      "Epoch 4959, Loss 29.515419, Params tensor([2.2343, 0.0664])\n",
      "Epoch 4960, Loss 29.515175, Params tensor([2.2344, 0.0664])\n",
      "Epoch 4961, Loss 29.514936, Params tensor([2.2344, 0.0664])\n",
      "Epoch 4962, Loss 29.514698, Params tensor([2.2345, 0.0663])\n",
      "Epoch 4963, Loss 29.514460, Params tensor([2.2345, 0.0663])\n",
      "Epoch 4964, Loss 29.514221, Params tensor([2.2345, 0.0663])\n",
      "Epoch 4965, Loss 29.513985, Params tensor([2.2346, 0.0663])\n",
      "Epoch 4966, Loss 29.513744, Params tensor([2.2346, 0.0662])\n",
      "Epoch 4967, Loss 29.513508, Params tensor([2.2347, 0.0662])\n",
      "Epoch 4968, Loss 29.513269, Params tensor([2.2347, 0.0662])\n",
      "Epoch 4969, Loss 29.513029, Params tensor([2.2348, 0.0662])\n",
      "Epoch 4970, Loss 29.512793, Params tensor([2.2348, 0.0662])\n",
      "Epoch 4971, Loss 29.512554, Params tensor([2.2348, 0.0661])\n",
      "Epoch 4972, Loss 29.512318, Params tensor([2.2349, 0.0661])\n",
      "Epoch 4973, Loss 29.512083, Params tensor([2.2349, 0.0661])\n",
      "Epoch 4974, Loss 29.511847, Params tensor([2.2350, 0.0661])\n",
      "Epoch 4975, Loss 29.511608, Params tensor([2.2350, 0.0660])\n",
      "Epoch 4976, Loss 29.511372, Params tensor([2.2351, 0.0660])\n",
      "Epoch 4977, Loss 29.511137, Params tensor([2.2351, 0.0660])\n",
      "Epoch 4978, Loss 29.510900, Params tensor([2.2351, 0.0660])\n",
      "Epoch 4979, Loss 29.510664, Params tensor([2.2352, 0.0660])\n",
      "Epoch 4980, Loss 29.510426, Params tensor([2.2352, 0.0659])\n",
      "Epoch 4981, Loss 29.510191, Params tensor([2.2353, 0.0659])\n",
      "Epoch 4982, Loss 29.509956, Params tensor([2.2353, 0.0659])\n",
      "Epoch 4983, Loss 29.509722, Params tensor([2.2354, 0.0659])\n",
      "Epoch 4984, Loss 29.509485, Params tensor([2.2354, 0.0658])\n",
      "Epoch 4985, Loss 29.509249, Params tensor([2.2354, 0.0658])\n",
      "Epoch 4986, Loss 29.509016, Params tensor([2.2355, 0.0658])\n",
      "Epoch 4987, Loss 29.508783, Params tensor([2.2355, 0.0658])\n",
      "Epoch 4988, Loss 29.508545, Params tensor([2.2356, 0.0657])\n",
      "Epoch 4989, Loss 29.508308, Params tensor([2.2356, 0.0657])\n",
      "Epoch 4990, Loss 29.508080, Params tensor([2.2357, 0.0657])\n",
      "Epoch 4991, Loss 29.507845, Params tensor([2.2357, 0.0657])\n",
      "Epoch 4992, Loss 29.507610, Params tensor([2.2357, 0.0657])\n",
      "Epoch 4993, Loss 29.507374, Params tensor([2.2358, 0.0656])\n",
      "Epoch 4994, Loss 29.507143, Params tensor([2.2358, 0.0656])\n",
      "Epoch 4995, Loss 29.506910, Params tensor([2.2359, 0.0656])\n",
      "Epoch 4996, Loss 29.506676, Params tensor([2.2359, 0.0656])\n",
      "Epoch 4997, Loss 29.506445, Params tensor([2.2360, 0.0655])\n",
      "Epoch 4998, Loss 29.506208, Params tensor([2.2360, 0.0655])\n",
      "Epoch 4999, Loss 29.505981, Params tensor([2.2360, 0.0655])\n",
      "Epoch 5000, Loss 29.505749, Params tensor([2.2361, 0.0655])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.2361, 0.0655])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dmodel_dw(t_u, w, b):\n",
    "    # model is t_u * w + b\n",
    "    return t_u\n",
    "\n",
    "def dmodel_db(t_u, w, b):\n",
    "    # model is t_u * w + b\n",
    "    return 1.0\n",
    "\n",
    "def dloss_fn(t_p, t_c):\n",
    "    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)   # 这个除法来自均值的导数    \n",
    "    return dsq_diffs\n",
    "\n",
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
    "    dloss_db = dloss_dtp * dmodel_db(t_u, w, b) \n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()]) \n",
    "\n",
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "        t_p = model(t_u, w, b)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b)\n",
    "        \n",
    "        params = params - learning_rate * grad\n",
    "        print('Epoch %d, Loss %f, Params %s' % (epoch, float(loss), params))\n",
    "    return params\n",
    "\n",
    "params = training_loop(\n",
    "    n_epochs = 5000,\n",
    "    learning_rate = 1e-5,\n",
    "    params = torch.tensor([1.0, 0.0]), \n",
    "    t_u = t_u * 0.1, \n",
    "    t_c = t_c\n",
    ")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feae9938df0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3840x2880 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "t_p = model(t_u * 0.1, *params)\n",
    "fig = plt.figure(dpi=600)\n",
    "plt.xlabel(\"Temperature (°Fahrenheit)\")\n",
    "plt.ylabel(\"Temperature (°Celsius)\")\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy()) #   ⇽---  但是我们画的是原始的未知数\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1763.8848, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch自动计算梯度\n",
    "\n",
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "loss = loss_fn(model(t_u, *params), t_c)\n",
    "loss.backward()\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 57.373318\n",
      "Epoch 1000, Loss 44.784958\n",
      "Epoch 1500, Loss 37.901421\n",
      "Epoch 2000, Loss 34.128048\n",
      "Epoch 2500, Loss 32.050251\n",
      "Epoch 3000, Loss 30.896940\n",
      "Epoch 3500, Loss 30.247673\n",
      "Epoch 4000, Loss 29.873213\n",
      "Epoch 4500, Loss 29.648615\n",
      "Epoch 5000, Loss 29.505749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.2361, 0.0655], requires_grad=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for i in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_c, t_p)\n",
    "        loss.backward()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "             print('Epoch %d, Loss %f' % (i, float(loss)))\n",
    "\n",
    "    return params\n",
    "\n",
    "params = training_loop(\n",
    "    n_epochs = 5000,\n",
    "    learning_rate = 1e-5,\n",
    "    params = torch.tensor([1.0, 0.0], requires_grad=True), \n",
    "    t_u = t_u * 0.1, \n",
    "    t_c = t_c\n",
    ")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'NAdam',\n",
       " 'Optimizer',\n",
       " 'RAdam',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functional',\n",
       " '_multi_tensor',\n",
       " 'lr_scheduler',\n",
       " 'swa_utils']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "dir(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p = model(t_u, *params)\n",
    "loss = loss_fn(t_p, t_c)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9123, -0.0016], requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p = model(t_u, *params)\n",
    "loss = loss_fn(t_p, t_c)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 57.373318\n",
      "Epoch 1000, Loss 44.784958\n",
      "Epoch 1500, Loss 37.901421\n",
      "Epoch 2000, Loss 34.128048\n",
      "Epoch 2500, Loss 32.050251\n",
      "Epoch 3000, Loss 30.896940\n",
      "Epoch 3500, Loss 30.247673\n",
      "Epoch 4000, Loss 29.873213\n",
      "Epoch 4500, Loss 29.648615\n",
      "Epoch 5000, Loss 29.505749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.2361, 0.0655], requires_grad=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for i in range(1, n_epochs + 1):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_c, t_p)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "             print('Epoch %d, Loss %f' % (i, float(loss)))\n",
    "\n",
    "    return params\n",
    "\n",
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "params = training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params, \n",
    "    t_u = t_u * 0.1, \n",
    "    t_c = t_c\n",
    ")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 示例数据：[身高(cm), 体重(kg)]\n",
    "inputs = torch.tensor([[180, 80], [165, 60], [170, 64], [160, 52], [175, 75]], dtype=torch.float32)\n",
    "# 目标性别：男(1), 女(0)\n",
    "labels = torch.tensor([[1], [0], [1], [0], [1]], dtype=torch.float32)\n",
    "\n",
    "# 创建TensorDataset和DataLoader\n",
    "# 主要用于降数据拆分成小批量，按照小批量计算损失和梯度\n",
    "# 核心功能是：\n",
    "# 1. 提供shuffle能力，为了使模型学习到更泛化的特征，而不是记住数据的顺序\n",
    "# 2. 提升训练效率，批量处理 + 并行化\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 4),  # 输入层到隐藏层\n",
    "    nn.ReLU(),        # 激活函数\n",
    "    nn.Linear(4, 1)   # 隐藏层到输出层\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "# 优化器概念此处先忽略，后续文章重点介绍\n",
    "# 你只需要知道，它是用来优化计算梯度，更新参数就可以\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.6926\n",
      "Epoch [200/1000], Loss: 0.6849\n",
      "Epoch [300/1000], Loss: 0.6803\n",
      "Epoch [400/1000], Loss: 0.6775\n",
      "Epoch [500/1000], Loss: 0.6757\n",
      "Epoch [600/1000], Loss: 0.6747\n",
      "Epoch [700/1000], Loss: 0.6740\n",
      "Epoch [800/1000], Loss: 0.6736\n",
      "Epoch [900/1000], Loss: 0.6734\n",
      "Epoch [1000/1000], Loss: 0.6733\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, labels)\n",
    "\n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 打印训练进度\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = torch.sigmoid(model(inputs))\n",
    "    predicted_classes = predictions.round()\n",
    "    accuracy = (predicted_classes.eq(labels).sum() / float(labels.size(0))).item()\n",
    "https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/    print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grad fn for a is None\n",
      "The grad fn for d is <AddBackward0 object at 0x7fe19a2b4700>\n"
     ]
    }
   ],
   "source": [
    "# https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/\n",
    "\n",
    "import torch \n",
    "\n",
    "a = torch.randn((3,3), requires_grad = True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad = True)\n",
    "w2 = torch.randn((3,3), requires_grad = True)\n",
    "w3 = torch.randn((3,3), requires_grad = True)\n",
    "w4 = torch.randn((3,3), requires_grad = True)\n",
    "\n",
    "b = w1*a \n",
    "c = w2*a\n",
    "\n",
    "d = w3*b + w4*c \n",
    "\n",
    "L = 10 - d\n",
    "\n",
    "print(\"The grad fn for a is\", a.grad_fn)\n",
    "print(\"The grad fn for d is\", d.grad_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
