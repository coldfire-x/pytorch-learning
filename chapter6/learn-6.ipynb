{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c).unsqueeze(1) # <1>\n",
    "t_u = torch.tensor(t_u).unsqueeze(1) # <1>\n",
    "\n",
    "t_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4,  5,  3,  1,  2,  9,  0, 10,  6]), tensor([7, 8]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_u_train = t_u[train_indices]\n",
    "t_c_train = t_c[train_indices]\n",
    "\n",
    "t_u_val = t_u[val_indices]\n",
    "t_c_val = t_c[val_indices]\n",
    "\n",
    "t_un_train = 0.1 * t_u_train\n",
    "t_un_val = 0.1 * t_u_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3735],\n",
       "        [2.8091]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "linear_model = nn.Linear(1, 1) # <1>\n",
    "linear_model(t_un_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, when you initialize a neural network layer such as nn.Linear (linear model), the input parameters represent the dimensions of the input and output tensors. Specifically, the nn.Linear layer takes two arguments: in_features and out_features.\n",
    "\n",
    "    in_features (int): This is the size of each input sample. For example, if you have a batch of input vectors, each with d features, then in_features should be set to d.\n",
    "    \n",
    "    out_features (int): This is the size of each output sample. For example, if you want the linear layer to produce output vectors of size k, then out_features should be set to k.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.5397]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1969], requires_grad=True))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.weight, linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7366],\n",
       "        [0.7366],\n",
       "        [0.7366],\n",
       "        [0.7366],\n",
       "        [0.7366],\n",
       "        [0.7366],\n",
       "        [0.7366],\n",
       "        [0.7366],\n",
       "        [0.7366],\n",
       "        [0.7366]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(10, 1)\n",
    "linear_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opitmizer = optim.SGD(linear_model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(n_epochs):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_c_train, t_p_train)\n",
    "\n",
    "        t_p_val = model(t_u_val)\n",
    "        loss_val = loss_fn(t_c_val, t_p_val)\n",
    "\n",
    "        opitmizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        opitmizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f}, Validation loss {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 133.5405, Validation loss 20.6322\n",
      "Epoch 1, Training loss 133.5405, Validation loss 20.6322\n",
      "Epoch 1000, Training loss 133.5405, Validation loss 20.6322\n",
      "Epoch 2000, Training loss 133.5405, Validation loss 20.6322\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.5410]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.6209], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(1, 1) # <1>\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=3000,\n",
    "    optimizer=optimizer,\n",
    "    model=linear_model,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    t_u_train=t_un_train,\n",
    "    t_u_val=t_un_val,\n",
    "    t_c_train=t_c_train,\n",
    "    t_c_val=t_c_val\n",
    ")\n",
    "\n",
    "print()\n",
    "print(linear_model.weight)\n",
    "print(linear_model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss 211.5442, Validation loss 24.4654\n",
      "Epoch 1, Training loss 211.5442, Validation loss 24.4654\n",
      "Epoch 1000, Training loss 211.5442, Validation loss 24.4654\n",
      "Epoch 2000, Training loss 211.5442, Validation loss 24.4654\n",
      "output tensor([[0.2077],\n",
      "        [0.4120]], grad_fn=<AddmmBackward0>)\n",
      "answer tensor([[-4.],\n",
      "        [ 6.]])\n",
      "hidden tensor([[-3.6773e+04],\n",
      "        [ 5.1166e+01],\n",
      "        [ 4.7368e+04],\n",
      "        [-1.4234e+01],\n",
      "        [ 8.9447e+01],\n",
      "        [ 3.4089e+03],\n",
      "        [-1.4378e+00],\n",
      "        [-2.6385e+01],\n",
      "        [-5.0987e+01],\n",
      "        [ 9.1511e+02],\n",
      "        [-1.2216e+03],\n",
      "        [-1.0343e+02],\n",
      "        [-1.2994e+02]])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(1, 13)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(13, 1))\n",
    "]))\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=3000,\n",
    "    optimizer=optimizer,\n",
    "    model=seq_model,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    t_u_train=t_un_train,\n",
    "    t_u_val=t_un_val,\n",
    "    t_c_train=t_c_train,\n",
    "    t_c_val=t_c_val\n",
    ")\n",
    "\n",
    "print('output', seq_model(t_un_val))\n",
    "print('answer', t_c_val)\n",
    "print('hidden', seq_model.hidden_linear.weight.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
